{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"KuboCD","text":""},{"location":"#why-kubocd","title":"Why KuboCD ?","text":"<p>Most applications that can be deployed on Kubernetes come with a Helm chart. Moreover, this Helm chart is generally highly flexible, designed to accommodate as many contexts as possible. This can make its configuration quite complex.</p> <p>Furthermore, deploying an application on Kubernetes using an Helm Chart requires a deep understanding of the Kubernetes ecosystem. As a result, application deployment is typically the responsibility of platform administrators or platform engineers.</p> <p>And even for experienced administrators, the verbosity of Helm configurations, especially the repetition of variables, can quickly become tedious and error-prone. Therefore, industrializing these configurations is crucial to improve efficiency and reliability.</p> <p>KuboCD is a tool that enables Platform Engineers to package applications in a way that simplifies deployment for other  technical users (such as Developers, AppOps, etc.) by abstracting most of the underlying infrastructure and environment complexities.</p> <p>In addition to user applications, KuboCD can also provision core system components (e.g., ingress controllers,  load balancers, Kubernetes operators, etc.), enabling fully automated bootstrapping of a production-ready cluster  from the ground up.</p>"},{"location":"#when-to-use-kubocd","title":"When to Use KuboCD","text":"<p>KuboCD is particularly useful when:</p> <ul> <li>You want to standardize application deployment workflows across teams and environments, without requiring everyone to master Helm or Kubernetes internals.</li> <li>You are already using GitOps tools like FluxCD or ArgoCD, and need a structured way to package and manage applications as versioned, portable artifacts.</li> <li>You want to encapsulate application configuration and logic into reusable, declarative units (Packages), decoupled from cluster-specific deployment scripts.</li> <li>You need to simplify access to existing Helm charts for developers, while enforcing consistency and best practices through curated Releases.</li> <li>You want to bootstrap entire environments (including base system components like ingress controllers, operators, etc.) in a fully automated way.</li> </ul>"},{"location":"#main-concepts","title":"Main concepts","text":"<p>KuboCD introduces two core concepts that form the foundation of its deployment model:</p> <ul> <li> <p>Package:   A Package is an OCI-compliant container image that bundles an application descriptor along with one or more Helm charts.    It serves as the standardized unit of deployment, encapsulating everything needed to describe and install an application.</p> </li> <li> <p>Release   A Release is a custom Kubernetes resource that represents the deployment of a specific Package within a Kubernetes cluster.    It defines how and where the application is deployed, and manages the lifecycle of that deployment.</p> </li> </ul>"},{"location":"#kubocd-flux-helm-and-gitops","title":"KuboCD, Flux, Helm and GitOps","text":"<p>KuboCD is designed to seamlessly integrate with Flux, enabling a fully automated GitOps workflow.  While Flux handles the continuous delivery aspect (tracking changes in Git and applying them to the cluster),  KuboCD simplifies application packaging and deployment logic, making the overall delivery pipeline more modular, maintainable, and user-friendly.</p> <p>KuboCD is not a replacement for Helm. It is quite the opposite. It builds on top of Helm\u2019s proven capabilities and  leverages the rich ecosystem of existing Helm charts.</p> <p>Most production-grade applications already provide an official or community-maintained Helm chart.  KuboCD makes these charts more accessible by abstracting the complexity of Helm-based deployments.</p> <p>By encapsulating Helm charts within standardized Packages and managing them via declarative Releases,  KuboCD allows a broader audience (including less Helm-savvy users) to safely and efficiently deploy applications to Kubernetes.</p>"},{"location":"#feature-comparison-kubocd-vs-helm-vs-fluxcd","title":"Feature Comparison: KuboCD vs Helm vs FluxCD","text":"Feature / Tool KuboCD Helm FluxCD Primary Role Application packaging &amp; deployment abstraction Templating and deploying Kubernetes manifests GitOps continuous delivery User Audience Platform Engineers, AppOps, Developers DevOps, Kubernetes Experts DevOps, SREs Ease of Use High (abstracts deployment logic) Medium (requires Helm knowledge) Medium (requires GitOps understanding) Supports GitOps \u2705 (via integration with FluxCD) \u26a0\ufe0f (manual integration needed) \u2705 (native GitOps controller) Uses Helm charts \u2705 (packages &amp; manages them) \u2705 (core functionality) \u2705 (can deploy HelmReleases) Custom Resources Release, Context None (CLI and chart format) HelmRelease, Kustomization, etc. Deployment Abstraction \u2705 (encapsulates values, logic) \u274c (user-defined values needed at deploy) \u274c (relies on raw manifests or Helm) OCI Image Support \u2705 (Packages are OCI images) \u2705 (since Helm v3.8+) \u2705 (via Helm OCI support) Ideal Use Case Standardizing deployments across teams Managing complex app deployments manually Automating deployments from Git"},{"location":"tips-and-tricks/","title":"Tips and Tricks","text":""},{"location":"tips-and-tricks/#create-a-private-certificate-authority","title":"Create a private Certificate authority","text":""},{"location":"tips-and-tricks/#use-dnsmasq","title":"Use dnsmasq","text":""},{"location":"tips-and-tricks/#use-docker-mac-net-connect-and-metallb","title":"Use docker mac net connect and metallb","text":"<p>https://github.com/chipmk/docker-mac-net-connect https://medium.com/@tylerauerbeck/making-your-docker-network-reachable-in-osx-e68f998f8249</p>"},{"location":"todo/","title":"Todo","text":"<ul> <li> <p>context</p> </li> <li> <p>kubocd CLI</p> </li> <li>Flux object</li> <li>cert manager</li> <li>source type</li> <li>Oci repo authentication</li> <li>schema</li> <li>data model</li> <li>Templating (Helm+spring+DNS resolve)</li> <li>config</li> <li>package redirection</li> <li>image redirection</li> <li>Release templating</li> <li>Reference</li> </ul>"},{"location":"getting-started/110-kind/","title":"Installing KuboCD on a Local Kind Cluster","text":"<p>This section walks you through setting up a local Kubernetes cluster using Docker and Kind, then installing FluxCD and KuboCD on top of it.</p> <p>Already have a Kubernetes cluster? You can skip the cluster creation and follow the instructions in Installation on an existing cluster.</p>"},{"location":"getting-started/110-kind/#prerequisites","title":"Prerequisites","text":"<p>Ensure the following tools are installed on your workstation:</p> <ul> <li>Docker</li> <li>kubectl</li> <li>Helm</li> <li>Kind</li> <li>Flux CLI</li> </ul> <p>Make sure:</p> <ul> <li>Docker is running</li> <li>You have an active internet connection</li> <li>Ports 80 and 443 are available on your local machine</li> </ul> <p>You also need an access to an OCI-compatible container registry with permissions to push images. This is will be necessary for uploading and storing KuboCD Packages as OCI artifacts.</p>"},{"location":"getting-started/110-kind/#create-the-kind-cluster","title":"Create the Kind Cluster","text":"<p>Create a configuration file with ingress-compatible port mappings:</p> <pre><code>cat &gt;/tmp/kubodoc-config.yaml &lt;&lt;EOF\nkind: Cluster\napiVersion: kind.x-k8s.io/v1alpha4\nname: kubodoc\nnodes:\n- role: control-plane\n  extraPortMappings:\n  - containerPort: 30080\n    hostPort: 80\n    protocol: TCP\n  - containerPort: 30443\n    hostPort: 443\n    protocol: TCP\nEOF\n</code></pre> <p>Then create the cluster:</p> <pre><code>kind create cluster --config /tmp/kubodoc-config.yaml\n</code></pre> <p>This will create a single-node cluster acting as both control plane and worker node.</p> <p>The <code>extraPortMappings</code> allow direct access to services like the ingress controller from your local machine.</p> <p>Example output:</p> <pre><code>Creating cluster \"kubodoc\" ...\n \u2713 Ensuring node image (kindest/node:v1.32.2)\n \u2713 Preparing nodes\n \u2713 Writing configuration\n \u2713 Starting control-plane\n \u2713 Installing CNI\n \u2713 Installing StorageClass\nSet kubectl context to \"kind-kubodoc\"\nYou can now use your cluster with:\n\nkubectl cluster-info --context kind-kubodoc\n</code></pre> <p>Verify everything is running:</p> <pre><code>kubectl get pods -A\n</code></pre> <p>Should output:</p> <pre><code>NAMESPACE            NAME                                            READY   STATUS    RESTARTS   AGE\nkube-system          coredns-668d6bf9bc-nwzqj                        1/1     Running   0          52s\nkube-system          coredns-668d6bf9bc-xgv9f                        1/1     Running   0          52s\nkube-system          etcd-kubodoc-control-plane                      1/1     Running   0          59s\nkube-system          kindnet-xwfp8                                   1/1     Running   0          52s\nkube-system          kube-apiserver-kubodoc-control-plane            1/1     Running   0          59s\nkube-system          kube-controller-manager-kubodoc-control-plane   1/1     Running   0          58s\nkube-system          kube-proxy-6hv6w                                1/1     Running   0          52s\nkube-system          kube-scheduler-kubodoc-control-plane            1/1     Running   0          59s\nlocal-path-storage   local-path-provisioner-7dc846544d-k8bhb         1/1     Running   0          52s\n</code></pre>"},{"location":"getting-started/110-kind/#install-flux","title":"Install Flux","text":""},{"location":"getting-started/110-kind/#install-the-flux-cli","title":"Install the Flux CLI","text":"<p>If not already installed, follow the Flux CLI installation guide.</p>"},{"location":"getting-started/110-kind/#deploy-flux-basic-mode","title":"Deploy Flux (Basic Mode)","text":"<p>We\u2019ll begin with a basic installation of Flux (no Git repository linked for now):</p> <p>A full GitOps deployment will be described later in this documentation.</p> <pre><code>flux install\n</code></pre> <p>Expected output:</p> <pre><code>\u271a generating manifests\n\u2714 manifests build completed\n\u25ba installing components in flux-system namespace\n...\n\u2714 notification-controller: deployment ready\n\u2714 source-controller: deployment ready\n\u2714 install finished\n</code></pre> <p>Verify deployment:</p> <pre><code>kubectl -n flux-system get pods\n</code></pre> <p>Expected output:</p> <pre><code>NAME                                       READY   STATUS    RESTARTS   AGE\nhelm-controller-b6767d66-q27gd             1/1     Running   0          14m\nkustomize-controller-5b56686fbc-hpkhl      1/1     Running   0          14m\nnotification-controller-58ffd586f7-bbvwv   1/1     Running   0          14m\nsource-controller-6ff87cb475-hnmxv         1/1     Running   0          14m\n</code></pre> <p>\ud83d\udca1 Want a minimal install? You can limit Flux to the required components for KuboCD: <code>flux install --components source-controller,helm-controller</code></p>"},{"location":"getting-started/110-kind/#install-kubocd","title":"Install KuboCD","text":"<p>Deploy KuboCD using Helm:</p> <pre><code>helm -n kubocd install kubocd-ctrl --create-namespace oci://quay.io/kubocd/charts/kubocd-ctrl:v0.2.0\n</code></pre>"},{"location":"getting-started/110-kind/#install-the-kubocd-cli","title":"Install the KuboCD CLI","text":"<p>Download the KuboCD CLI from the GitHub releases page. and rename it to <code>kubocd</code>. Then make it executable and move it to your path:</p> <pre><code>mv kubocd_*_* kubocd\nchmod +x kubocd\nsudo mv kubocd /usr/local/bin/\n</code></pre> <p>Verify the installation:</p> <pre><code>kubocd version\n</code></pre> <p>You can now move to your first deployment with KuboCD</p>"},{"location":"getting-started/120-existing-cluster/","title":"Installing KuboCD on an existing cluster.","text":"<p>If you have an existing cluster, you can use it to test KuboCD</p>"},{"location":"getting-started/120-existing-cluster/#prerequisites","title":"Prerequisites","text":"<p>Ensure the following tools are installed on your workstation:</p> <ul> <li>Docker</li> <li>kubectl</li> <li>Helm</li> <li>Flux CLI</li> </ul> <p>Make sure:</p> <ul> <li>Docker is running</li> <li>You have an active internet connection</li> <li>You have full admin rights on the target cluster.</li> </ul> <p>You also need an access to an OCI-compatible container registry with permissions to push images. This is will be necessary for uploading and storing KuboCD Packages as OCI artifacts.</p>"},{"location":"getting-started/120-existing-cluster/#install-flux","title":"Install Flux","text":""},{"location":"getting-started/120-existing-cluster/#install-the-flux-cli","title":"Install the Flux CLI","text":"<p>If not already installed, follow the Flux CLI installation guide.</p>"},{"location":"getting-started/120-existing-cluster/#deploy-flux-basic-mode","title":"Deploy Flux (Basic Mode)","text":"<p>If Flux is not already installed on your cluster, we\u2019ll begin with a basic installation (no Git repository linked for now):</p> <p>A full GitOps deployment will be described later in this documentation.</p> <pre><code>flux install\n</code></pre> <p>Expected output:</p> <pre><code>\u271a generating manifests\n\u2714 manifests build completed\n\u25ba installing components in flux-system namespace\n...\n\u2714 notification-controller: deployment ready\n\u2714 source-controller: deployment ready\n\u2714 install finished\n</code></pre> <p>Verify deployment:</p> <pre><code>kubectl -n flux-system get pods\n</code></pre> <p>Expected output:</p> <pre><code>NAME                                       READY   STATUS    RESTARTS   AGE\nhelm-controller-b6767d66-q27gd             1/1     Running   0          14m\nkustomize-controller-5b56686fbc-hpkhl      1/1     Running   0          14m\nnotification-controller-58ffd586f7-bbvwv   1/1     Running   0          14m\nsource-controller-6ff87cb475-hnmxv         1/1     Running   0          14m\n</code></pre> <p>\ud83d\udca1 Want a minimal install? You can limit Flux to the required components for KuboCD: <code>flux install --components source-controller,helm-controller</code></p>"},{"location":"getting-started/120-existing-cluster/#install-kubocd","title":"Install KuboCD","text":"<p>Deploy the KuboCD controller using Helm:</p> <pre><code>helm -n kubocd install kubocd-ctrl --create-namespace oci://quay.io/kubocd/charts/kubocd-ctrl:v0.2.0\n</code></pre>"},{"location":"getting-started/120-existing-cluster/#enabling-webhook-based-features","title":"Enabling Webhook-Based Features","text":"<p>Some advanced features in KuboCD such as Release protection rely on a Kubernetes validating webhook.</p> <p>To enable these features, you need to deploy a webhook component alongside the controller. This webhook requires  cert-manager to be installed in your cluster to handle TLS certificate provisioning.</p> <p>If you already have <code>cert-manager</code> installed, you can deploy the webhook with the following command:</p> <pre><code>helm -n kubocd install kubocd-wh oci://quay.io/kubocd/charts/kubocd-wh:v0.2.0\n</code></pre> <p>\ud83d\udca1 Don\u2019t have <code>cert-manager</code> yet? No problem \u2014 we\u2019ll show you how to package and install it with KuboCD in a later section.</p>"},{"location":"getting-started/120-existing-cluster/#install-the-kubocd-cli","title":"Install the KuboCD CLI","text":"<p>Download the KuboCD CLI from the GitHub releases page. and rename it to <code>kubocd</code>. Then make it executable and move it to your path:</p> <pre><code>mv kubocd_*_* kubocd\nchmod +x kubocd\nsudo mv kubocd /usr/local/bin/\n</code></pre> <p>Verify the installation:</p> <pre><code>kubocd version\n</code></pre> <p>You can now move to your first deployment with KuboCD</p>"},{"location":"getting-started/130-a-first-deployment/","title":"A first deployment with KuboCD","text":""},{"location":"getting-started/130-a-first-deployment/#package-definition","title":"Package definition","text":"<p>For this first deployment, we will take a simple use case: A tiny web application: podinfo</p> <p>A Package is defined by a YAML manifest. Here is a first version to wrap up the 'podinfo' application:</p> podinfo-p01.yaml <pre><code>apiVersion: v1alpha1\ntype: Package\nname: podinfo\ntag: 6.7.1-p02\nschema:\n  parameters:\n    $schema: http://json-schema.org/schema#\n    additionalProperties: false\n    properties:\n      fqdn:\n        type: string\n      ingressClassName:\n        default: nginx\n        type: string\n    required:\n      - fqdn\n    type: object\nmodules:\n  - name: main\n    specPatch:\n      timeout: 2m\n    source:\n      helmRepository:\n        url: https://stefanprodan.github.io/podinfo\n        chart: podinfo\n        version: 6.7.1\n    values: |\n      ingress:\n        enabled: true\n        className: {{ .Parameters.ingressClassName  }}\n        hosts:\n          - host: {{ .Parameters.fqdn }}\n            paths:\n              - path: /\n                pathType: ImplementationSpecific\n</code></pre> <p>A KuboCD Package is NOT a Kubernetes resources.</p> <p>Here is a description of the attributes used in this sample: </p> <ul> <li><code>apiVersion</code>: (R) The version of this YAML format. Currently only allowed value is <code>v1alpha1</code>.</li> <li><code>type</code>: The type of resource described. <code>Package</code> is the default and the only allowed value. It could be omitted.</li> <li><code>name</code>: The name of the package. Will be used also in the image name.</li> <li><code>tag</code>: (R) The tag of the OCI image and is used to record the version of the package. Technically, it could be whatever you want, but we suggest the following convention:<ul> <li>Use the version of the main module Helm chart and add a <code>-pXX</code> suffix where XX allow versioning of the packaging. (The same Helm chart can be packaged in different ways). </li> </ul> </li> <li><code>schema.parameters</code>: When the package will be deployed, some parameters will be provided. This schema allow validation     (And documentation) of these parameters. It is a standard OpenAPI/json schema.    If not defined, this means the Release will not accept parameters.</li> <li><code>modules</code>: (R) A package include one or several Helm charts, each one being referenced by a <code>module</code> entry.</li> <li><code>modules[X].name</code>: (R) Each module must have a name. As there is only one here, we call it <code>main</code>.</li> <li><code>modules[X].source</code>: (R) Where to find the Helm chart. In this example in an Helm Repository provided by the authors of   <code>podinfo</code>. The <code>source</code> can also be an OCI Repository, a GIT repository or a local Helm Chart.</li> <li><code>values</code>: Defines a template that will be rendered to generate the <code>values.yaml</code> file used for deploying   the Helm chart.<ul> <li>The templating engine used is the same as Helm's. More on this here</li> <li>However, the data model is different. It includes, in particular, a root object <code>.Parameters</code> that contains values   which will be defined during deployment, by the <code>Release</code> object.</li> <li>Although it may look like a <code>yaml</code> snippet, it is in fact a string, to allow insertion of template directive.</li> </ul> </li> </ul> <p>(R) means Required</p> <p>Of course, there is more attributes than the ones of this sample. There wil be described later in the documentation.</p>"},{"location":"getting-started/130-a-first-deployment/#package-build","title":"Package build","text":"<p>Maintenant, il convient de g\u00e9n\u00e9rer l'image OCI correspondante.</p> <p>As stated earlier, you need an access to an OCI-compatible container registry with permissions to push images. This is will be necessary for uploading and storing KuboCD Packages as OCI artifacts.</p> <p>Currently, <code>quay.io</code> (redhat), <code>ghcr.io</code> (Github) and the distribution registry  has been testes an known to work. Although not tested, other should also works, except Docker Hub.</p> <p>You must be logged on this repo with appropriate permissions. (i.e <code>docker login quay.io</code>, or <code>docker login ghcr.io</code>, ...)</p> <p>Depending of the registry, you may have a concept of 'organisation'. In this sample, we will use quay.io with a <code>kubodoc</code> organization.</p> <p>To build the package, save the package file <code>podinfo-p01.yaml</code> in some place and enter a command like:</p> <pre><code>kubocd package podinfo-p01.yaml --ociRepoPrefix quay.io/kubodoc/packages\n</code></pre> <p>Of course, you must adjust the value of <code>--ociRepoPrefix</code> to your environment. Note the sub-path <code>package</code> is arbitrary and could be anything you want, or empty.</p> <p>The repository name will be build by concatenating the value of <code>--ociRepoPrefix</code> and the name of the package (Provided in the file). And obviously, the tag will be taken from the definition.</p> <p>The output should look like:</p> <pre><code>====================================== Packaging package 'podinfo-p01.yaml'\n--- Handling module 'main':\nFetching chart podinfo:6.7.1...\nChart: podinfo:6.7.1\n--- Packaging\nGenerating index file\nWrap all in assembly.tgz\n--- push OCI image: quay.io/kubodoc/packages/podinfo:6.7.1-p01\nSuccessfully pushed\n</code></pre> <p>Instead of providing the <code>--ociRepoPrefix</code> on each run, you may also define an environment variable:</p> <pre><code>export OCI_REPO_PREFIX=quay.io/kubodoc/packages\n</code></pre> <p>or:</p> <pre><code>export OCI_REPO_PREFIX=ghcr.io/kubodoc/packages\n</code></pre> <p>or</p> <pre><code>export OCI_REPO_PREFIX=localhost:5000/packages\n</code></pre> <p>Last step: ensure your image is <code>public</code> (Initial default may be <code>private</code>).</p> <p>If you want the image to stay <code>private</code>, you will have to provide authentication information on the <code>Release</code>. This will be described later in this doc.</p>"},{"location":"getting-started/130-a-first-deployment/#releasing-the-application","title":"Releasing the application","text":"<p>To deploy our application, a <code>Release</code> custom resource is used:</p> podinfo1.yaml <pre><code>---\napiVersion: kubocd.kubotal.io/v1alpha1\nkind: Release\nmetadata:\n  name: podinfo1\n  namespace: default\nspec:\n  description: A first sample release of podinfo\n  package:\n    repository: quay.io/kubodoc/packages/podinfo\n    tag: 6.7.1-p01\n    interval: 30m\n  parameters:\n    fqdn: podinfo1.ingress.kubodoc.local\n</code></pre> <p>The attributes in the 'spec' part:</p> <ul> <li><code>description</code>: Optional. A short description of the release.</li> <li><code>package.repository</code>: The OCI repository to fetch the package image. See the packaging step above.</li> <li><code>package.tag</code>: The tag/version of the package. See the packaging step above.</li> <li><code>package.interval</code>: Interval between OCI image reconciliation. In other word, the maximum duration to wait for a package modification to be taken in account.</li> <li><code>parameters</code>: An object which comply the the <code>parameter.schema</code> defined in the Package. Just a single value in this first sample.</li> </ul> <p>To deploy our application, save the above file in some place, and execute:</p> <pre><code>kubectl apply -f podinfo1.yaml\n</code></pre> <pre><code>kubectl get releases\n</code></pre> <pre><code>NAME       REPOSITORY                         TAG         CONTEXTS   STATUS   READY   WAIT   PRT   AGE     DESCRIPTION\npodinfo1   quay.io/kubodoc/packages/podinfo   6.7.1-p01              READY    1/1            -     6m40s   A first sample release of podinfo\n</code></pre> <p>kubectl apply -f podinfo1.yaml </p> <p>kubectl get pods NAME                             READY   STATUS    RESTARTS   AGE podinfo1-main-779b6b9fd4-zbgbx   1/1     Running   0          8h</p> <p>kubectl get ingresses NAME            CLASS   HOSTS                            ADDRESS   PORTS   AGE podinfo1-main   nginx   podinfo1.ingress.kubodoc.local             80      6m33s</p> <p>kubectl get OCIRepository NAME           URL                                      READY   STATUS                                                                                                           AGE kcd-podinfo1   oci://quay.io/kubodoc/packages/podinfo   True    stored artifact for digest '6.7.1-p01@sha256:985e4e2f89a4b17bd5cc2936a0b305df914ae479e0b8c96e61cb22725b61cd24'   9m1s</p> <p>kubectl get HelmRelease NAME            AGE     READY   STATUS podinfo1-main   7m59s   True    Helm install succeeded for release default/podinfo1-main.v1 with chart podinfo@6.7.1</p> <p>These flux CD resource are owned by the Release object. This means: - They will be deleted with the parent Release object. - If they are manually deleted, the Release object will recreate them. (For OCIRepository, this is a method to reload a modified version of a package without waiting for the configured interval).</p> <p>$ kubocd pack ingress-nginx.yaml</p> <p>====================================== Packaging package 'ingress-nginx.yaml' --- Handling module 'main': Fetching chart ingress-nginx:4.12.1... Chart: ingress-nginx:4.12.1 --- Packaging Generating index file Wrap all in assembly.tgz --- push OCI image: quay.io/kubodoc/packages/ingress-nginx:4.12.1-p01 Successfully pushed</p> <p>127.0.0.1 localhost podinfo1.ingress.kubodoc.local</p>"},{"location":"getting-started/130-a-first-deployment/#alternate-kubocd-schema","title":"Alternate KuboCD Schema.","text":"<p>In this first sample, the <code>schema.parameters</code> has been defined using a standard OpenAPI schema. But this definition turn out to be quite verbose. So a new, simplified version has been introduced for KuboCD.</p> <p>Here is the same package, using he KuboCD definition:</p> podinfo-p02.yaml <pre><code>apiVersion: v1alpha1\ntype: Package\nname: podinfo\ntag: 6.7.1-p01\nschema:\n  parameters:\n    properties:\n      fqdn: { type: string, required: true }\n      ingressClassName: { type: string, default: \"nginx\"}\nmodules:\n  - name: main\n    source:\n      helmRepository:\n        url: https://stefanprodan.github.io/podinfo\n        chart: podinfo\n        version: 6.7.1\n    values: |\n      ingress:\n        enabled: true\n        className: {{ .Parameters.ingressClassName  }}\n        hosts:\n          - host: {{ .Parameters.fqdn }}\n            paths:\n              - path: /\n                pathType: ImplementationSpecific\n</code></pre> <p>A bit shorter isn't it.</p> <p>Cette d\u00e9finition n'est pas directement compatible avec le standard. Mais elle est facilement convertible vers celui-ci. C'est d'ailleurs ce que fait KuboCD en interne.</p> <p>A noter que c'est le token <code>$schema:</code> qui permet de distinguer un format standard d'un format KuboCD</p> <p>Cette definition sp\u00e9cifique de schema fait l'objet d'un chapitre d\u00e9di\u00e9.</p>"},{"location":"user-guide/schemas/","title":"Parameters and Context schemas","text":""}]}