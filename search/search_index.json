{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"KuboCD","text":""},{"location":"#why-kubocd","title":"Why KuboCD ?","text":"<p>Most applications that can be deployed on Kubernetes come with a Helm chart. Moreover, this Helm chart is generally highly flexible, designed to accommodate as many contexts as possible. This can make its configuration quite complex.</p> <p>Furthermore, deploying an application on Kubernetes using an Helm Chart requires a deep understanding of the Kubernetes ecosystem. As a result, application deployment is typically the responsibility of platform administrators or platform engineers.</p> <p>And even for experienced administrators, the verbosity of Helm configurations, especially the repetition of variables, can quickly become tedious and error-prone. Therefore, industrializing these configurations is crucial to improve efficiency and reliability.</p> <p>KuboCD is a tool that enables Platform Engineers to package applications in a way that simplifies deployment for other  technical users (such as Developers, AppOps, etc.) by abstracting most of the underlying infrastructure and environment complexities.</p> <p>In addition to usual applications, KuboCD can also provision core system components (e.g., ingress controllers,  load balancers, Kubernetes operators, etc.), enabling fully automated bootstrapping of a production-ready cluster  from the ground up.</p>"},{"location":"#when-to-use-kubocd","title":"When to Use KuboCD","text":"<p>KuboCD is particularly useful when:</p> <ul> <li>You want to standardize application deployment workflows across teams and environments, without requiring everyone to master Helm or Kubernetes internals.</li> <li>You are already using GitOps tools like FluxCD or ArgoCD, and need a structured way to package and manage applications as versioned, portable artifacts.</li> <li>You want to encapsulate application configuration and logic into reusable, declarative units (Packages), decoupled from cluster-specific deployment scripts.</li> <li>You need to simplify access to existing Helm charts for developers, while enforcing consistency and best practices through curated Releases.</li> <li>You want to bootstrap entire environments (including base system components like ingress controllers, operators, etc.) in a fully automated way.</li> </ul>"},{"location":"#main-concepts","title":"Main concepts","text":"<p>KuboCD introduces two core concepts that form the foundation of its deployment model:</p> <ul> <li> <p>Package:   A Package is an OCI-compliant container image that bundles an application descriptor along with one or more Helm charts.    It serves as the standardized unit of deployment, encapsulating everything needed to describe and install an application.</p> </li> <li> <p>Release   A Release is a custom Kubernetes resource that represents the deployment of a specific Package within a Kubernetes cluster.    It defines how and where the application is deployed, and manages the lifecycle of that deployment.</p> </li> </ul>"},{"location":"#kubocd-flux-helm-and-gitops","title":"KuboCD, Flux, Helm and GitOps","text":"<p>KuboCD is designed to seamlessly integrate with Flux, enabling a fully automated GitOps workflow.  While Flux handles the continuous delivery aspect (tracking changes in Git and applying them to the cluster),  KuboCD simplifies application packaging and deployment logic, making the overall delivery pipeline more modular, maintainable, and user-friendly.</p> <p>KuboCD is not a replacement for Helm. It is quite the opposite. It builds on top of Helm\u2019s proven capabilities and  leverages the rich ecosystem of existing Helm charts.</p> <p>Most production-grade applications already provide an official or community-maintained Helm chart.  KuboCD makes these charts more accessible by abstracting the complexity of Helm-based deployments.</p> <p>By encapsulating Helm charts within standardized Packages and managing them via declarative Releases,  KuboCD allows a broader audience (including less Helm-savvy users) to safely and efficiently deploy applications to Kubernetes.</p>"},{"location":"#feature-comparison-kubocd-vs-helm-vs-fluxcd","title":"Feature Comparison: KuboCD vs Helm vs FluxCD","text":"Feature / Tool KuboCD Helm FluxCD Primary Role Application packaging &amp; deployment abstraction Templating and deploying Kubernetes manifests GitOps continuous delivery User Audience Platform Engineers, AppOps, Developers DevOps, Kubernetes Experts DevOps, SREs Ease of Use High (abstracts deployment logic) Medium (requires Helm knowledge) Medium (requires GitOps understanding) Supports GitOps \u2705 (via integration with FluxCD) \u26a0\ufe0f (manual integration needed) \u2705 (native GitOps controller) Uses Helm charts \u2705 (packages &amp; manages them) \u2705 (core functionality) \u2705 (can deploy HelmReleases) Custom Resources Release, Context None (CLI and chart format) HelmRelease, Kustomization, etc. Deployment Abstraction \u2705 (encapsulates values, logic) \u274c (user-defined values needed at deploy) \u274c (relies on raw manifests or Helm) OCI Image Support \u2705 (Packages are OCI images) \u2705 (since Helm v3.8+) \u2705 (via Helm OCI support) Ideal Use Case Standardizing deployments across teams Managing complex app deployments manually Automating deployments from Git"},{"location":"getting-started/","title":"Getting started","text":""},{"location":"getting-started/#how-this-manual-is-structured","title":"How This Manual Is Structured","text":"<p>The User Guide is organized as a step-by-step tutorial, designed to gradually introduce the various features of KuboCD.</p> <p>It is complemented by a 'Reference' section.</p> <p>As a starting point, we recommend installing KuboCD:</p> <ul> <li>If you have a test cluster available: Installing KuboCD on an Existing Cluster.</li> <li>If you prefer to test locally on your workstation: Installing KuboCD on a Local Kind Cluster</li> </ul> <p>Then continue with A First Deployment.</p>"},{"location":"reference/500-package/","title":"The KuboCD Package","text":"<p>A <code>Package</code> is an OCI-compliant container image that bundles an application descriptor along with one or more Helm charts.  It serves as the standardized unit of deployment, encapsulating everything needed to describe and install an application.</p> <p>Refer to A first deployment for an introductory example.</p> <p>The OCI image is built from a manifest, whose structure is described below.</p>"},{"location":"reference/500-package/#templating","title":"Templating","text":"<p>Some attributes can accept a template, rendering the final value. There are noted as the following:</p> <ul> <li>template(string): A template which must render a string.</li> <li>template(bool): A template that must render a string convertible to a boolean value. (1, t, T, TRUE, true, True, 0, f, F, FALSE, false, False)</li> <li>template(list(string)): A template which must render a list of string</li> <li>template(map): A template which must render a map/object. </li> <li>template(duration): A template that must render a string convertible to a duration value.</li> </ul>"},{"location":"reference/500-package/#package","title":"Package","text":""},{"location":"reference/500-package/#apiversion","title":"apiVersion","text":"<p>String, required | The manifest version. Only allowed value is currently <code>v1alpha1</code></p>"},{"location":"reference/500-package/#type","title":"type","text":"<p>String, optional: The manifest type. Only allowed value is <code>Package</code>. May be omitted.</p>"},{"location":"reference/500-package/#name","title":"name","text":"<p>String, required: The name of the package. Will be used in the OCI repository name. Must be a valid DNS Subdomain name (RFC 1123).</p>"},{"location":"reference/500-package/#tag","title":"tag","text":"<p>String, required: The tag for the OCI image.</p>"},{"location":"reference/500-package/#description","title":"description","text":"<p>Template(string), optional: A short description of the package. Will act as default for its <code>Release</code> counterpart. </p>"},{"location":"reference/500-package/#protected","title":"protected","text":"<p>Bool, Default: false: Prevent deletion. Will act as default for its <code>Release</code> counterpart</p>"},{"location":"reference/500-package/#schemaparameters","title":"schema.parameters","text":"<p>Map, Optional: Allow validation or the <code>Parameters</code> defined in the <code>Release</code> object. It could be a JSON/OpenAPI  schema or a KuboCD specific format.</p> <p>If none is provided, this means the <code>Release</code> will not accept any parameters.</p>"},{"location":"reference/500-package/#schemacontext","title":"schema.context","text":"<p>Map, Optional: Allow validation or the <code>Context</code> of the deployment. It could be a JSON/OpenAPI schema or a KuboCD specific format.</p> <p>If none is provided, there will be no control on provided <code>Context</code></p>"},{"location":"reference/500-package/#modules","title":"modules","text":"<p>List(Modules), Required: The list of modules included in this package.</p>"},{"location":"reference/500-package/#roles","title":"roles","text":"<p>Template(List(string)), optional: The roles this package aims to fulfill. See Release Dependencies and Roles</p>"},{"location":"reference/500-package/#dependencies","title":"dependencies","text":"<p>Template(List(string)), optional: The roles this package depends on. See Release Dependencies and Roles</p>"},{"location":"reference/500-package/#packagemodule","title":"Package.module","text":"<p>A <code>Module</code> embed an Helm Chart</p>"},{"location":"reference/500-package/#name_1","title":"name","text":"<p>String, required: The module name. Must be unique for a package. Used in the name of several Kubernetes ressources,  so it must be a valid DNS Subdomain name (RFC 1123) </p>"},{"location":"reference/500-package/#source","title":"source","text":"<p>Map, required:: Provide the location from which to fetch the Helm chart. Must contain of the following sub-elements:</p> <ul> <li>helmRepository </li> <li>git</li> <li>oci</li> <li>local</li> </ul>"},{"location":"reference/500-package/#values","title":"values","text":"<p>Template(map), Optional: The template rendering the 'values file' used to deploy the Helm Chart. Refer to A first deployment for an simple first example.</p>"},{"location":"reference/500-package/#timeout","title":"timeout","text":"<p>Template(duration), default: 2m: Timeout is the time to wait for any individual Kubernetes operation (like Jobs for hooks)  during the performance of a Helm action.</p>"},{"location":"reference/500-package/#enabled","title":"enabled","text":"<p>Template(bool), default: true: When set to false, the module is not deployed at all. See  for an example.</p>"},{"location":"reference/500-package/#targetnamespace","title":"targetNamespace","text":"<p>Template(string), default: {{ .Release.spec.targetNamespace }}: The namespace to deploy the application into.</p>"},{"location":"reference/500-package/#dependson","title":"dependsOn","text":"<p>Template(list(string)), optional: A list of other modules of this package we depends on.</p>"},{"location":"reference/500-package/#specpatch","title":"specPatch","text":"<p>Template(map), optional: A patch applied to the <code>spec</code> section of the Flux <code>HelmRelease</code> resource.  It allows you to set any parameters that are not exposed by KuboCD.</p>"},{"location":"reference/500-package/#packagemodulesourcehelmrepository","title":"Package.module.source.helmRepository","text":"<p>Use this section to fetch an Helm Chart stored on an Helm Repository.</p>"},{"location":"reference/500-package/#url","title":"url","text":"<p>String, required: The URL of the Helm repository</p>"},{"location":"reference/500-package/#chart","title":"chart","text":"<p>String, required: The Chart name</p>"},{"location":"reference/500-package/#version","title":"version","text":"<p>String, required: The Chart version</p>"},{"location":"reference/500-package/#packagemodulesourcegit","title":"Package.module.source.git","text":"<p>Use this section to fetch an Helm Chart stored on an Git Repository.</p>"},{"location":"reference/500-package/#url_1","title":"url","text":"<p>String, required: The URL of the Git repository</p>"},{"location":"reference/500-package/#branch","title":"branch","text":"<p>String, required if tag is not defined: The branch to fetch</p>"},{"location":"reference/500-package/#tag_1","title":"tag","text":"<p>String, required if branch is not defined: The tag to fetch</p>"},{"location":"reference/500-package/#path","title":"path","text":"<p>String, required: The folder inside the Git repository of the Chart (Where is <code>Chart.yaml</code> is located)</p>"},{"location":"reference/500-package/#packagemodulesourceoci","title":"Package.module.source.oci","text":"<p>Use this section to fetch an Helm Chart stored as an OCI image.</p>"},{"location":"reference/500-package/#repository","title":"repository","text":"<p>String, required: The repository URL without <code>oci://</code> and <code>tag</code>.</p>"},{"location":"reference/500-package/#tag_2","title":"tag","text":"<p>String, required: The image tag.</p>"},{"location":"reference/500-package/#insecure","title":"insecure","text":"<p>Bool, default: false: Repository access is in clear text (non encrypted) </p>"},{"location":"reference/500-package/#packagemodulesourcelocal","title":"Package.module.source.local","text":"<p>Use this section to fetch an Helm Chart stored on your workstation, alongside the <code>Package</code> manifest.</p>"},{"location":"reference/500-package/#path_1","title":"path","text":"<p>String, required: The local folder of the Chart (Where is <code>Chart.yaml</code> is located). Relative to the <code>Package</code> manifest location</p>"},{"location":"reference/510-release/","title":"The Release Kubernetes resources","text":""},{"location":"reference/510-release/#release","title":"Release","text":""},{"location":"reference/510-release/#apiversion","title":"apiVersion","text":"<p>String, required: Always <code>kubocd.kubotal.io/v1alpha1</code></p>"},{"location":"reference/510-release/#kind","title":"kind","text":"<p>String, required: Always `Release'</p>"},{"location":"reference/510-release/#metadata","title":"metadata","text":"<p>Map, required: Refer to the Kubernetes API documentation for the fields of the metadata field.</p>"},{"location":"reference/510-release/#spec","title":"spec","text":"<p>Release.spec, required: See Release.spec below</p>"},{"location":"reference/510-release/#releasespec","title":"Release.spec","text":""},{"location":"reference/510-release/#description","title":"description","text":"<p>String, default: {Package.description}: A short description. </p>"},{"location":"reference/510-release/#package","title":"package","text":"<p>Release.spec.package, required: Where to fetch the <code>Package</code> OCI image. Description in Release.spec.package</p>"},{"location":"reference/510-release/#contexts","title":"contexts","text":"<p>List(CrossNamespaceReference): A list of supplementary contexts merged with the default ones.  If the <code>namespace</code> of the context is not defined, it will take the <code>Release.metadata.namespace</code>.</p>"},{"location":"reference/510-release/#protected","title":"protected","text":"<p>Bool, Default: {Package.protected}: If true, prevent deletion. Need the KuboCD webhook to be effective</p>"},{"location":"reference/510-release/#parameters","title":"parameters","text":"<p>Template(Map), optional: The deployments parameters. Must comply to the <code>Package.parameters.schema</code>.  It is a template, thus allowing variable substitution. But, only the root elements <code>.Context</code> is present in the data model. </p>"},{"location":"reference/510-release/#specpatchbymodule","title":"specPatchByModule","text":"<p>Map(Map), optional: A patch applied to the <code>spec</code> section of the Flux <code>HelmRelease</code> resource of the specified module. It allows you to set any parameters that are not exposed by KuboCD at the <code>Release</code> level</p> <p>You will find an example here  (Modification of the <code>helmRelease</code> timeout for the <code>redis</code> module.)</p>"},{"location":"reference/510-release/#targetnamespace","title":"targetNamespace","text":"<p>String, default: {Release.metadata.namespace}: The namespace to deploy the application into</p>"},{"location":"reference/510-release/#createnamespace","title":"createNamespace","text":"<p>Bool, default: false: Allow <code>targetNamespace</code> creation if it does not exists.</p>"},{"location":"reference/510-release/#roles","title":"roles","text":"<p>List(string), default: []: This list is appended to the <code>Package.roles</code> list</p>"},{"location":"reference/510-release/#dependencies","title":"dependencies","text":"<p>List(string), default: []: This list is appended to the <code>Package.dependencies</code> list</p>"},{"location":"reference/510-release/#skipdefaultcontext","title":"skipDefaultContext","text":"<p>Bool, default: false: If set, this <code>Release</code> will ignore the global default contexts as well as those defined at the namespace level. Only the contexts explicitly listed in the <code>Release</code> resource will be taken into account.</p>"},{"location":"reference/510-release/#debug","title":"debug","text":"<p>Release.spec.debug, optional: Refer to Release.spec.debug below</p>"},{"location":"reference/510-release/#releasespecpackage","title":"Release.spec.package","text":""},{"location":"reference/510-release/#repository","title":"repository","text":"<p>String, required: Part of OCI url oci://:"},{"location":"reference/510-release/#tag","title":"tag","text":"<p>String, required: Part of OCI url oci://:"},{"location":"reference/510-release/#other-attributes","title":"Other attributes","text":"<p>When a <code>Release</code> resource is created, a Flux <code>OCIRepository</code> resource is also created to reference the Package's OCI image. This object supports many configuration attributes. These attributes can be overridden at the Release level and will be passed through as-is.</p> <p>Refer to the Flux documentation for OCIRepositorySpec for full details.</p> <p>Here is the list of supported forwarded attributes:</p> <ul> <li>interval</li> <li>timeout</li> <li>secretRef</li> <li>certSecretRef</li> <li>proxySecretRef</li> <li>provider</li> <li>verify </li> <li>serviceAccountName</li> <li>insecure</li> <li>suspend</li> </ul>"},{"location":"reference/510-release/#releasespecdebug","title":"Release.spec.debug","text":""},{"location":"reference/510-release/#dumpcontext","title":"dumpContext","text":"<p>Bool, default: false: If set, the computed context is saved in the <code>status</code> field. This can be useful for debugging.  Anyway, the context may become quite large. Use this debug mode sparingly. You may prefer to use the \u2019render` CLI command.</p>"},{"location":"reference/510-release/#dumpparameters","title":"dumpParameters","text":"<p>Bool, default: false: If set, the computed parameters are saved in the <code>status</code> field. Useful in case <code>Release.spec.parameters</code> is a template.</p>"},{"location":"reference/510-release/#crossnamespacereference","title":"CrossNamespaceReference","text":""},{"location":"reference/510-release/#name","title":"name","text":"<p>String, required:</p>"},{"location":"reference/510-release/#namespace","title":"namespace","text":"<p>String, optional:</p>"},{"location":"reference/520-context/","title":"The Context Kubernetes resource.","text":"<p>You can refer to The context resource for some example of usage.</p>"},{"location":"reference/520-context/#release","title":"Release","text":""},{"location":"reference/520-context/#apiversion","title":"apiVersion","text":"<p>String, required: Always <code>kubocd.kubotal.io/v1alpha1</code></p>"},{"location":"reference/520-context/#kind","title":"kind","text":"<p>String, required: Always `Context'</p>"},{"location":"reference/520-context/#metadata","title":"metadata","text":"<p>Map, required: Refer to the Kubernetes API documentation for the fields of the metadata field.</p>"},{"location":"reference/520-context/#spec","title":"spec","text":"<p>Context.spec, required: See Context.spec below</p>"},{"location":"reference/520-context/#contextspec","title":"Context.spec","text":""},{"location":"reference/520-context/#description","title":"description","text":"<p>String, optional: A short description. </p>"},{"location":"reference/520-context/#protected","title":"protected","text":"<p>Bool, Default: false: If true, prevent deletion. Need the KuboCD webhook to be effective</p>"},{"location":"reference/520-context/#context","title":"context","text":"<p>Map, required: The context map value itself. Refer to The Context resource</p>"},{"location":"reference/530-config/","title":"The Config Kubernetes resource.","text":""},{"location":"reference/530-config/#config","title":"Config","text":""},{"location":"reference/530-config/#apiversion","title":"apiVersion","text":"<p>String, required: Always <code>kubocd.kubotal.io/v1alpha1</code></p>"},{"location":"reference/530-config/#kind","title":"kind","text":"<p>String, required: Always `Config'</p>"},{"location":"reference/530-config/#metadata","title":"metadata","text":"<p>Map, required: Refer to the Kubernetes API documentation for the fields of the metadata field.</p>"},{"location":"reference/530-config/#spec","title":"spec","text":"<p>Config.spec, required: See Config.spec below</p>"},{"location":"reference/530-config/#configspec","title":"Config.spec","text":""},{"location":"reference/530-config/#clusterroles","title":"clusterRoles","text":"<p>List(string), default: []: List of roles fulfilled by non-KuboCD application.  See Cluster roles</p>"},{"location":"reference/530-config/#defaultcontexts","title":"defaultContexts","text":"<p>List(CrossNamespaceReference), default[]: A list of context which will be used by all <code>Release</code>, except the one with the  <code>skipDefaultContext</code> flag. Refer to The Context Resource for more explanation. </p>"},{"location":"reference/530-config/#defaultnamespacecontexts","title":"defaultNamespaceContexts","text":"<p>List(string), default: []: A list of context name. When a <code>Release</code> is deployed in a namespace, if a context of  this name exists in the namespace, it will be used, merged with default one(s) if existing. This can be skipped with the <code>Release.skipDefautContext</code> flag</p> <p>Refer to The Context Resource for more explanation. </p>"},{"location":"reference/530-config/#packageredirects","title":"packageRedirects","text":"<p>For future extension</p>"},{"location":"reference/530-config/#imageredirects","title":"imageRedirects","text":"<p>For future extension</p>"},{"location":"user-guide/110-kind/","title":"Installing KuboCD on a Local Kind Cluster","text":"<p>This section walks you through setting up a local Kubernetes cluster using Docker and Kind, then installing FluxCD and KuboCD on top of it.</p> <p>Tip</p> <p>Already have a Kubernetes cluster? You can skip the cluster creation and follow the instructions in Installation on an existing cluster.</p>"},{"location":"user-guide/110-kind/#prerequisites","title":"Prerequisites","text":"<p>Ensure the following tools are installed on your workstation:</p> <ul> <li>Docker.</li> <li>kubectl.</li> <li>Helm.</li> <li>Kind.</li> <li>Flux CLI.</li> </ul> <p>Make sure:</p> <ul> <li>Docker is running</li> <li>You have an active internet connection</li> <li>Ports 80 and 443 are available on your local machine</li> </ul> <p>You also need an access to an OCI-compatible container registry with permissions to push images. This is will be necessary for uploading and storing KuboCD Packages as OCI artifacts.</p>"},{"location":"user-guide/110-kind/#create-the-kind-cluster","title":"Create the Kind Cluster","text":"<p>Create a configuration file with ingress-compatible port mappings:</p> <pre><code>cat &gt;/tmp/kubodoc-config.yaml &lt;&lt;EOF\nkind: Cluster\napiVersion: kind.x-k8s.io/v1alpha4\nname: kubodoc\nnodes:\n- role: control-plane\n  extraPortMappings:\n  - containerPort: 30080\n    hostPort: 80\n    protocol: TCP\n  - containerPort: 30443\n    hostPort: 443\n    protocol: TCP\nEOF\n</code></pre> <p>Note</p> <p>The <code>extraPortMappings</code> allow direct access to services like the ingress controller from your local machine.</p> <p>Then create the cluster:</p> <pre><code>kind create cluster --config /tmp/kubodoc-config.yaml\n</code></pre> <p>This will create a single-node cluster acting as both control plane and worker node.</p> <p>Example output:</p> <pre><code>Creating cluster \"kubodoc\" ...\n \u2713 Ensuring node image (kindest/node:v1.32.2)\n \u2713 Preparing nodes\n \u2713 Writing configuration\n \u2713 Starting control-plane\n \u2713 Installing CNI\n \u2713 Installing StorageClass\nSet kubectl context to \"kind-kubodoc\"\nYou can now use your cluster with:\n\nkubectl cluster-info --context kind-kubodoc\n</code></pre> <p>Verify everything is running:</p> <pre><code>kubectl get pods -A\n</code></pre> <pre><code>NAMESPACE            NAME                                            READY   STATUS    RESTARTS   AGE\nkube-system          coredns-668d6bf9bc-nwzqj                        1/1     Running   0          52s\nkube-system          coredns-668d6bf9bc-xgv9f                        1/1     Running   0          52s\nkube-system          etcd-kubodoc-control-plane                      1/1     Running   0          59s\nkube-system          kindnet-xwfp8                                   1/1     Running   0          52s\nkube-system          kube-apiserver-kubodoc-control-plane            1/1     Running   0          59s\nkube-system          kube-controller-manager-kubodoc-control-plane   1/1     Running   0          58s\nkube-system          kube-proxy-6hv6w                                1/1     Running   0          52s\nkube-system          kube-scheduler-kubodoc-control-plane            1/1     Running   0          59s\nlocal-path-storage   local-path-provisioner-7dc846544d-k8bhb         1/1     Running   0          52s\n</code></pre>"},{"location":"user-guide/110-kind/#install-flux","title":"Install Flux","text":""},{"location":"user-guide/110-kind/#install-the-flux-cli","title":"Install the Flux CLI","text":"<p>If not already installed, follow the Flux CLI installation guide..</p>"},{"location":"user-guide/110-kind/#deploy-flux-basic-mode","title":"Deploy Flux (Basic Mode)","text":"<p>We\u2019ll begin with a basic installation of Flux (no Git repository linked for now):</p> <p>Note</p> <p>A full GitOps deployment will be described later in this documentation.</p> <pre><code>flux install\n</code></pre> <pre><code>\u271a generating manifests\n\u2714 manifests build completed\n\u25ba installing components in flux-system namespace\n...\n\u2714 notification-controller: deployment ready\n\u2714 source-controller: deployment ready\n\u2714 install finished\n</code></pre> <p>Verify deployment:</p> <pre><code>kubectl -n flux-system get pods\n</code></pre> <pre><code>NAME                                       READY   STATUS    RESTARTS   AGE\nhelm-controller-b6767d66-q27gd             1/1     Running   0          14m\nkustomize-controller-5b56686fbc-hpkhl      1/1     Running   0          14m\nnotification-controller-58ffd586f7-bbvwv   1/1     Running   0          14m\nsource-controller-6ff87cb475-hnmxv         1/1     Running   0          14m\n</code></pre> <p>Tip</p> <p>\ud83d\udca1 Want a minimal install? You can limit Flux to the required components for KuboCD: <code>flux install --components source-controller,helm-controller</code></p>"},{"location":"user-guide/110-kind/#install-kubocd","title":"Install KuboCD","text":"<p>Deploy KuboCD using Helm:</p> <pre><code>helm -n kubocd install kubocd-ctrl --create-namespace oci://quay.io/kubocd/charts/kubocd-ctrl --version v0.2.2\n</code></pre>"},{"location":"user-guide/110-kind/#install-the-kubocd-cli","title":"Install the KuboCD CLI","text":"<p>Download the KuboCD CLI from the GitHub releases page and rename it to <code>kubocd</code>. Then make it executable and move it to your path:</p> <pre><code>mv kubocd_*_* kubocd\nchmod +x kubocd\nsudo mv kubocd /usr/local/bin/\n</code></pre> <p>Verify the installation:</p> <pre><code>kubocd version\n</code></pre> <p>You can now move to your first deployment with KuboCD</p>"},{"location":"user-guide/120-existing-cluster/","title":"Installing KuboCD on an existing cluster.","text":"<p>If you have an existing cluster, you can use it to test KuboCD</p> <p>Tip</p> <p>If you don't have one, you can use a Kind cluster on your local workstation</p>"},{"location":"user-guide/120-existing-cluster/#prerequisites","title":"Prerequisites","text":"<p>Ensure the following tools are installed on your workstation:</p> <ul> <li>Docker.</li> <li>kubectl.</li> <li>Helm.</li> <li>Flux CLI.</li> </ul> <p>Make sure:</p> <ul> <li>Docker is running</li> <li>You have an active internet connection</li> <li>You have full admin rights on the target cluster.</li> </ul> <p>You also need an access to an OCI-compatible container registry with permissions to push images. This is will be necessary for uploading and storing KuboCD Packages as OCI artifacts.</p>"},{"location":"user-guide/120-existing-cluster/#install-flux","title":"Install Flux","text":""},{"location":"user-guide/120-existing-cluster/#install-the-flux-cli","title":"Install the Flux CLI","text":"<p>If not already installed, follow the Flux CLI installation guide..</p>"},{"location":"user-guide/120-existing-cluster/#deploy-flux-basic-mode","title":"Deploy Flux (Basic Mode)","text":"<p>If Flux is not already installed on your cluster, we\u2019ll begin with a basic installation (no Git repository linked for now):</p> <pre><code>flux install\n</code></pre> <pre><code>\u271a generating manifests\n\u2714 manifests build completed\n\u25ba installing components in flux-system namespace\n...\n\u2714 notification-controller: deployment ready\n\u2714 source-controller: deployment ready\n\u2714 install finished\n</code></pre> <p>Verify deployment:</p> <pre><code>kubectl -n flux-system get pods\n</code></pre> <pre><code>NAME                                       READY   STATUS    RESTARTS   AGE\nhelm-controller-b6767d66-q27gd             1/1     Running   0          14m\nkustomize-controller-5b56686fbc-hpkhl      1/1     Running   0          14m\nnotification-controller-58ffd586f7-bbvwv   1/1     Running   0          14m\nsource-controller-6ff87cb475-hnmxv         1/1     Running   0          14m\n</code></pre> <p>Tip</p> <p>\ud83d\udca1 Want a minimal install? You can limit Flux to the required components for KuboCD: <code>flux install --components source-controller,helm-controller</code></p>"},{"location":"user-guide/120-existing-cluster/#install-kubocd","title":"Install KuboCD","text":"<p>Deploy the KuboCD controller using Helm:</p> <pre><code>helm -n kubocd install kubocd-ctrl --create-namespace oci://quay.io/kubocd/charts/kubocd-ctrl --version v0.2.2\n</code></pre>"},{"location":"user-guide/120-existing-cluster/#enabling-webhook-based-features","title":"Enabling Webhook-Based Features","text":"<p>Some advanced features in KuboCD such as Release protection rely on a Kubernetes validating webhook.</p> <p>To enable these features, you need to deploy a webhook component alongside the controller. This webhook requires  cert-manager. to be installed in your cluster to handle TLS certificate provisioning.</p> <p>If you already have <code>cert-manager</code> installed, you can deploy the webhook with the following command:</p> <pre><code>helm -n kubocd install kubocd-wh oci://quay.io/kubocd/charts/kubocd-wh --version v0.2.2\n</code></pre> <p>Note</p> <p>Don\u2019t have <code>cert-manager</code> yet? No problem ! We\u2019ll show you how to package and install it with KuboCD in a later section.</p>"},{"location":"user-guide/120-existing-cluster/#install-the-kubocd-cli","title":"Install the KuboCD CLI","text":"<p>Download the KuboCD CLI from the GitHub releases page and rename it to <code>kubocd</code>. Then make it executable and move it to your path:</p> <pre><code>mv kubocd_*_* kubocd\nchmod +x kubocd\nsudo mv kubocd /usr/local/bin/\n</code></pre> <p>Verify the installation:</p> <pre><code>kubocd version\n</code></pre> <p>You can now move to your first deployment with KuboCD</p>"},{"location":"user-guide/130-a-first-deployment/","title":"A First Deployment with KuboCD","text":""},{"location":"user-guide/130-a-first-deployment/#package-definition","title":"Package Definition","text":"<p>For this initial deployment, we\u2019ll use a simple and illustrative example: a tiny web application called podinfo.</p> <p>A Package in KuboCD is defined using a YAML manifest. Below is an example that wraps the <code>podinfo</code> application:</p> podinfo-p01.yaml <pre><code>apiVersion: v1alpha1\ntype: Package\nname: podinfo\ntag: 6.7.1-p01\nschema:\n  parameters:\n    $schema: http://json-schema.org/schema#\n    additionalProperties: false\n    properties:\n      fqdn:\n        type: string\n      ingressClassName:\n        default: nginx\n        type: string\n    required:\n      - fqdn\n    type: object\nmodules:\n  - name: main\n    source:\n      helmRepository:\n        url: https://stefanprodan.github.io/podinfo\n        chart: podinfo\n        version: 6.7.1\n    values: |\n      ingress:\n        enabled: true\n        className: {{ .Parameters.ingressClassName }}\n        hosts:\n          - host: {{ .Parameters.fqdn }}\n            paths:\n              - path: /\n                pathType: ImplementationSpecific\n</code></pre> <p>A KuboCD Package is NOT a native Kubernetes resource.</p> <p>Tips</p> <p>You will find most on the samples used in this documentation at the following location</p> <p>Description of the sample Package attributes:</p> <ul> <li><code>apiVersion</code> (Required): Defines the version of the KuboCD Package format. The only supported value currently is <code>v1alpha1</code>.</li> <li><code>type</code>: Specifies the resource type. It must be <code>Package</code>, which is also the default and can be omitted.</li> <li><code>name</code>: The name of the package. This will be used as the OCI image name.</li> <li><code>tag</code> (Required): Specifies the version tag of the OCI image. While technically flexible, we will use the following convention:<ul> <li>Use the Helm chart version of the main module as a base, followed by <code>-pXX</code> where <code>XX</code> denotes the packaging revision (e.g. different configurations for the same chart).</li> </ul> </li> <li><code>schema.parameters</code>: Defines input parameters for the package, using a standard OpenAPI/JSON Schema. This enables validation and documentation of parameters at deployment time.<ul> <li>If not defined, the release will not accept parameters.</li> </ul> </li> <li><code>modules</code> (Required): A package contains one or more Helm charts, each represented as a module.<ul> <li><code>modules[X].name</code> (Required): A unique name for the module. In this example, there's only one module, called <code>main</code>.</li> <li><code>modules[X].source</code> (Required): Defines where to find the Helm chart. In this example, it's in a Helm repository, but it could also come from an OCI registry, Git repository, or local chart.</li> <li><code>values</code>: This is a template rendered into a <code>values.yaml</code> for Helm. <ul> <li>The templating engine is the same as Helm\u2019s.</li> <li>The data model, however, differs. It includes a <code>.Parameters</code> object containing the values provided during deployment (via the <code>Release</code> object).</li> <li>Though it appears as YAML, it is actually a string, allowing full templating flexibility.</li> </ul> </li> </ul> </li> </ul> <p>Required Fields</p> <p>Any attribute marked with (Required) must be specified for the package to be valid.</p> <p>Tip</p> <p>More attributes and advanced features will be introduced later in the documentation.</p>"},{"location":"user-guide/130-a-first-deployment/#package-build","title":"Package Build","text":"<p>Now that the package definition is complete, it\u2019s time to generate the corresponding OCI image.</p> <p>As mentioned earlier, KuboCD uses an OCI-compatible container registry to store and distribute packages. You'll need access to one with permission to push images.</p> <p>Tested registry</p> <ul> <li><code>quay.io</code> (Red Hat)</li> <li><code>ghcr.io</code> (GitHub)</li> <li>distribution registry</li> </ul> <p>Others should works. Except <code>Docker Hub</code> which is not supported at the moment.</p> <p>Make sure you're authenticated with the registry, e.g.:</p> <pre><code>docker login quay.io\n</code></pre> <p>or</p> <pre><code>docker login ghcr.io\n</code></pre> <p>Tips</p> <p>If you encounter issues authenticating with a registry, KuboCD provides an alternative method. You can supply your credentials through two environment variables: <code>KCD_OCI_USER</code> and <code>KCD_OCI_SECRET</code>.</p> <p>This method is also useful in CI/CD pipelines or scripts, where interactive authentication is not possible.</p> <p>Be sure to handle these variables securely, especially when used in shared environments.</p> <p>Depending on the registry, the image may be pushed under an organization or namespace. For this example, we'll use <code>quay.io/kubodoc</code>.</p> <p>To build and push the package image:</p> <pre><code>kubocd package packages/podinfo-p01.yaml --ociRepoPrefix quay.io/kubodoc/packages\n</code></pre> <p>Note</p> <p>Adjust <code>--ociRepoPrefix</code> to your own registry setup.The <code>packages</code> suffix is arbitrary. You can use any subpath or omit it.</p> <p>The resulting repository and tag are determined from the package manifest:</p> <ul> <li>Repository = <code>--ociRepoPrefix</code> + package <code>name</code></li> <li>Tag = package <code>tag</code></li> </ul> <p>Expected Output:</p> <pre><code>====================================== Packaging package 'podinfo-p01.yaml'\n--- Handling module 'main':\nFetching chart podinfo:6.7.1...\nChart: podinfo:6.7.1\n--- Packaging\nGenerating index file\nWrap all in assembly.tgz\n--- push OCI image: quay.io/kubodoc/packages/podinfo:6.7.1-p01\nSuccessfully pushed\n</code></pre> <p>You can also set the repository prefix globally via an environment variable:</p> <pre><code>export OCI_REPO_PREFIX=quay.io/kubodoc/packages\n</code></pre> <p>Or for other registries:</p> <pre><code>export OCI_REPO_PREFIX=ghcr.io/kubodoc/packages\n</code></pre> <pre><code>export OCI_REPO_PREFIX=localhost:5000/packages\n</code></pre> <p>Then: </p> <pre><code>kubocd package packages/podinfo-p01.yaml\n</code></pre> <p>Warning</p> <p>By default, pushed images may be private. To make them accessible for deployment, ensure the image is set to public.  If you prefer to keep the image private, you will need to provide authentication credentials in the <code>Release</code> configuration. This will be explained later in the documentation.</p>"},{"location":"user-guide/130-a-first-deployment/#releasing-the-application","title":"Releasing the Application","text":"<p>To deploy the application, define a KuboCD <code>Release</code> custom resource:</p> podinfo1-basic.yaml <pre><code>---\napiVersion: kubocd.kubotal.io/v1alpha1\nkind: Release\nmetadata:\n  name: podinfo1\n  namespace: default\nspec:\n  description: A first sample release of podinfo\n  package:\n    repository: quay.io/kubodoc/packages/podinfo\n    tag: 6.7.1-p01\n    interval: 30m\n  parameters:\n    fqdn: podinfo1.ingress.kubodoc.local\n</code></pre> <p>Explanation of attributes:</p> <ul> <li><code>description</code>: (Optional) A short description of this release.</li> <li><code>package.repository</code>: The OCI image repository that contains the package. This should match the registry used during package build.</li> <li><code>package.tag</code>: The image tag, which should match the one defined in the package manifest.</li> <li><code>package.interval</code>: Specifies how frequently KuboCD checks the registry for updates to the image.</li> <li><code>parameters</code>: The values required by the package schema. In this example, only a single parameter (<code>fqdn</code>) is needed.</li> </ul> <p>Deploying the Application:</p> <ol> <li>Adjust the repository and parameters (if needed) to match your environment.</li> <li>Apply the Release:</li> </ol> <pre><code>kubectl apply -f releases/podinfo1-basic.yaml\n</code></pre> <p>Once deployed, monitor the status:</p> <pre><code>kubectl get releases\n</code></pre> <pre><code>NAME       REPOSITORY                         TAG         CONTEXTS   STATUS   READY   WAIT   PRT   AGE     DESCRIPTION\npodinfo1   quay.io/kubodoc/packages/podinfo   6.7.1-p01              READY    1/1            -     6m40s   A first sample release of podinfo\n</code></pre> <p>You can also verify the pod:</p> <pre><code>kubectl get pods\n</code></pre> <pre><code>NAME                             READY   STATUS    RESTARTS   AGE\npodinfo1-main-779b6b9fd4-zbgbx   1/1     Running   0          8h\n</code></pre>"},{"location":"user-guide/140-under-the-hood/","title":"Under the Hood (If Things Go Wrong)","text":"<p>Behind the scenes, KuboCD creates several Flux resources to manage the deployment.</p> <p>You can inspect these resources to debug problems or understand the internals.</p> <p>Check the events bound to the <code>Release</code> which was previously created:</p> <pre><code>kubectl describe release podinfo1\n</code></pre> <p>There are <code>Events</code> for each Flux resources create:</p> <pre><code>......\nEvents:\n  Type    Reason                 Age   From     Message\n  ----    ------                 ----  ----     -------\n  Normal  OCIRepositoryCreated   49s   release  Created OCIRepository \"kcd-podinfo1\"\n  Normal  HelmRepositoryCreated  45s   release  Created HelmRepository \"kcd-podinfo1\"\n  Normal  HelmReleaseCreated     44s   release  Created HelmRelease \"podinfo1-main\"\n</code></pre> <p>All of these resources are created in the same namespace as the <code>Release</code> object (<code>default</code> in this sample).</p>"},{"location":"user-guide/140-under-the-hood/#the-ocirepository","title":"The OCIRepository","text":"<p>This Flux resource pulls the KuboCD package image:</p> <pre><code>kubectl get OCIRepository\n</code></pre> <pre><code>NAME           URL                                      READY   STATUS                                                                                                           AGE\nkcd-podinfo1   oci://quay.io/kubodoc/packages/podinfo   True    stored artifact for digest '6.7.1-p01@sha256:985e4e2f89a4b17bd5cc2936a0b305df914ae479e0b8c96e61cb22725b61cd24'   9m1s\n</code></pre> <p>Tip</p> <p>If the release is stuck in the <code>WAIT_OCI</code> state, check this resource and its events. Common issues include:</p> <ul> <li>Incorrect URL</li> <li>Image still private (set to public or provide authentication)</li> </ul> <p>You can manually delete this resource to trigger a refresh:</p> <pre><code>kubectl delete ocirepository kcd-podinfo1\n</code></pre> <p>KuboCD will recreate it.</p> <p>This can be useful to force a reload of a modified OCI image, without waiting for the sync period.</p>"},{"location":"user-guide/140-under-the-hood/#the-helmrepository","title":"The HelmRepository","text":"<p>As the <code>podinfo</code> Helm the chart is embedded in the package, it must be served to Flux via an internal Helm repository.</p> <p>KuboCD creates a <code>HelmRepository</code> resource pointing to its internal server:</p> <pre><code>kubectl get HelmRepository\n</code></pre> <pre><code>NAME           URL                                                                            AGE    READY   STATUS\nkcd-podinfo1   http://kubocd-ctrl-controller-helm-repository.kubocd.svc/hr/default/podinfo1   105m   True    stored artifact: revision 'sha256:d8db03cf45ecd75064c2a2582812dc4df5cd624d0e295b24ff79569bf46a070b'\n</code></pre> <p>This step rarely causes errors unless the internal controller is unreachable.</p>"},{"location":"user-guide/140-under-the-hood/#the-helmrelease","title":"The HelmRelease","text":"<p>This Flux resource handles the actual Helm chart deployment.</p> <pre><code>kubectl get HelmRelease\n</code></pre> <pre><code>NAME                AGE     READY   STATUS\npodinfo1-main   7m29s   True    Helm install succeeded for release default/kcd-podinfo1-main.v1 with chart podinfo@6.7.1\n</code></pre> <p>Note</p> <p>There will be one <code>HelmRelease</code> per module in the package.</p> <p>If the release is stuck in <code>WAIT_HREL</code>, inspect this resource:</p> <pre><code>kubectl describe helmrelease podinfo1-main\n</code></pre> <pre><code>.....\nEvents:\n  Type    Reason            Age    From             Message\n  ----    ------            ----   ----             -------\n  Normal  HelmChartCreated  4m38s  helm-controller  Created HelmChart/default/default-podinfo1-main with SourceRef 'HelmRepository/default/kcd-podinfo1'\n  Normal  InstallSucceeded  4m37s  helm-controller  Helm install succeeded for release default/podinfo1-main.v1 with chart podinfo@6.7.1\n</code></pre> <p>One of the point to check in case of problem is the generated <code>values</code> for the Helm chart deployment.</p> <p>Note</p> <p>You will need to install the yq command.</p> <pre><code>kubectl get HelmRelease podinfo1-main -o yaml | yq '.spec.values'\n</code></pre> <pre><code>ingress:\n  className: nginx\n  enabled: true\n  hosts:\n    - host: podinfo1.ingress.kubodoc.local\n      paths:\n        - path: /\n          pathType: ImplementationSpecific\n</code></pre> <p>Note</p> <p>If deployment fails, you may need to wait for the Helm timeout to expire (default: 2 minutes) to have the failure reason.  You can configure this value in the <code>Package</code> or in the <code>Release</code>.</p>"},{"location":"user-guide/150-ingress-controller/","title":"Setting Up the Ingress Controller","text":"<p>Warning</p> <p>If you're using an existing cluster, there's likely already an ingress controller installed. Do not install another one. However, you should still read this section as several new features are described.</p> <p>If you're following the local <code>kind</code> cluster setup, you\u2019ll need to install an ingress controller to make use of the deployed <code>Ingress</code> object.</p> <p>Check the current <code>Ingress</code> object created by the <code>podinfo</code> deployment:</p> <pre><code>kubectl get ingresses\n</code></pre> <pre><code>NAME            CLASS   HOSTS                            ADDRESS   PORTS   AGE\npodinfo1-main   nginx   podinfo1.ingress.kubodoc.local             80      6m33s\n</code></pre> <p>At this point, the ingress is inactive since no ingress controller is installed.</p>"},{"location":"user-guide/150-ingress-controller/#build-the-ingress-nginx-package","title":"Build the ingress-nginx package:","text":"<p>Here is a sample package definition for the <code>ingress-nginx</code> controller:</p> <p>Warning</p> <p>This first version is dedicated to the configuration we set up the cluster, using the kind <code>portMapping</code> and <code>NodePorts</code>.</p> ingress-nginx-p01.yaml <pre><code>apiVersion: v1alpha1\nname: ingress-nginx\ntag: 4.12.1-p01\nprotected: true\nmodules:\n  - name: main\n    timeout: 4m\n    source:\n      helmRepository:\n        url: https://kubernetes.github.io/ingress-nginx\n        chart: ingress-nginx\n        version: 4.12.1\n    values:\n      controller:\n        extraArgs:\n          enable-ssl-passthrough: true\n        service:\n          type: NodePort\n          nodePorts:\n            http: \"30080\"\n            https: \"30443\"\nroles:\n  - ingress\n</code></pre> <p>New key points compared to the <code>podinfo</code> Package:</p> <ul> <li><code>protected: true</code>: Prevents accidental deletion of the release. (Currently not enforced unless KuboCD webhook is installed.)</li> <li><code>timeout: 4m</code>: Overrides the default deployment timeout (<code>2m</code>) because this Helm chart may take some time to deploy.</li> <li><code>values</code>: This section is in proper YAML format (no '|': not a templated string), since it does not include any templating.</li> <li><code>roles</code>: Assigns the package to the <code>ingress</code> role. This is used for dependency management between releases.    This will be described later in this documentation</li> </ul> <p>Build the package:</p> <pre><code>kubocd pack packages/ingress-nginx-p01.yaml\n</code></pre> <pre><code>====================================== Packaging package 'ingress-nginx.yaml'\n--- Handling module 'main':\nFetching chart ingress-nginx:4.12.1...\nChart: ingress-nginx:4.12.1\n--- Packaging\nGenerating index file\nWrap all in assembly.tgz\n--- push OCI image: quay.io/kubodoc/packages/ingress-nginx:4.12.1-p01\nSuccessfully pushed\n</code></pre>"},{"location":"user-guide/150-ingress-controller/#deploy-the-package","title":"Deploy the package","text":"<p>Then define the <code>Release</code> resource:</p> ingress-nginx.yaml <pre><code>---\napiVersion: kubocd.kubotal.io/v1alpha1\nkind: Release\nmetadata:\n  name: ingress-nginx\n  namespace: kubocd\nspec:\n  description: The Ingress controller\n  protected: false\n  package:\n    repository: quay.io/kubodoc/packages/ingress-nginx\n    tag: 4.12.1-p01\n    interval: 30m\n  targetNamespace: ingress-nginx\n  createNamespace: true\n</code></pre> <p>Key points:</p> <ul> <li><code>metadata.namespace: kubocd</code>: As it is a system components, deploy in a restricted namespace.</li> <li><code>spec.protected: false</code>: Just to demonstrates that the package-level <code>protected</code> flag can be overridden at the release level.</li> <li><code>spec.targetNamespace: ingress-nginx</code>: Installs the ingress controller in its own namespace.</li> <li><code>spec.createNamespace: true</code>: Automatically creates the target namespace if it doesn't exist.</li> </ul> <p>Apply the release:</p> <pre><code>kubectl apply -f releases/ingress-nginx.yaml\n</code></pre> <p>Check the release status:</p> <pre><code>kubectl -n kubocd get release\n</code></pre> <pre><code>NAME            REPOSITORY                               TAG          CONTEXTS   STATUS   READY   WAIT   PRT   AGE   DESCRIPTION\ningress-nginx   quay.io/kubodoc/packages/ingress-nginx   4.12.1-p01              READY    1/1            -     86s   The Ingress controller\n</code></pre>"},{"location":"user-guide/150-ingress-controller/#configure-the-dns-entry","title":"Configure the DNS entry","text":"<p>To access the <code>podinfo</code> application, you'll need to define a DNS entry matching the <code>fqdn</code> parameter.</p> <p>The simplest way in our case is to use the <code>/etc/hosts</code> file:</p> <pre><code>127.0.0.1 localhost podinfo1.ingress.kubodoc.local\n</code></pre> <p>Make sure the fqdn matches exactly what was provided in the podinfo <code>Release</code> parameters.</p> <p>You should now be able to access the 'podinfo` web server:</p> <p>\ud83d\udc49 http://podinfo1.ingress.kubodoc.local.</p> <p>Of course, since we are using a CA that is not trusted by your workstation, you will need to bypass some security warnings.</p>"},{"location":"user-guide/160-the-context/","title":"The Context","text":"<p>One of the key features of KuboCD is its ability to generate Helm deployment values files from a small set of high-level input parameters, using a templating mechanism.</p> <p>This mechanism combines a template with a data model.</p> <p>Our first example uses only the <code>.Parameters</code> element of the data model:</p> podinfo-p01.yaml <pre><code>apiVersion: v1alpha1\ntype: Package\nname: podinfo\n...\nmodules:\n  - name: main\n    ...\n    values: |\n      ingress:\n        enabled: true\n        className: {{ .Parameters.ingressClassName }}\n        hosts:\n          - host: {{ .Parameters.fqdn }}\n            paths:\n              - path: /\n                pathType: ImplementationSpecific\n</code></pre> <p>Actually, the data model includes the following top-level elements:</p> <ul> <li><code>.Parameters</code>: The parameters provided in the <code>Release</code> custom resource.</li> <li><code>.Release</code>: The release object itself.</li> <li><code>.Context</code>: The deployment context.</li> </ul> <p>The context is a YAML object with a flexible structure, designed to hold shared configuration data relevant to all deployments.</p> <p>For example, the <code>podinfo</code> package includes a parameter <code>ingressClassName</code> with a default value (<code>nginx</code>). If a cluster uses a different ingress controller, this value would need to be overridden for all relevant <code>Release</code> objects.</p> <p>This type of shared configuration is best defined in a global cluster-level context.</p> <p>Similarly, if all application ingress URLs share a common root domain, that too should be centralized.</p> <p>Here's an initial example of how this logic can be implemented.</p>"},{"location":"user-guide/160-the-context/#context-creation","title":"Context Creation","text":"<p>A <code>Context</code> is a KuboCD resource:</p> cluster.yaml <pre><code>apiVersion: kubocd.kubotal.io/v1alpha1\nkind: Context\nmetadata:\n  namespace: contexts\n  name: cluster\nspec:\n  description: Global context for the kubodoc cluster\n  protected: true\n  context:\n    ingress:\n      className: nginx\n      domain: ingress.kubodoc.local\n    storageClass: \n      data: standard\n      workspace: standard\n    certificateIssuer:\n      public: cluster-self\n      internal: cluster-self\n</code></pre> <p>Key attributes:</p> <ul> <li><code>description</code>: A short description.</li> <li><code>protected</code>: Prevents deletion of this object. Requires KuboCD's webhook feature.</li> <li><code>context</code>: A tree of values that is injected into the data model for the templating of the <code>values</code> section. This section:<ul> <li>Must be valid YAML.</li> <li>Has a flexible structure, but should align with what the <code>Package</code> templates expect.</li> </ul> </li> </ul> <p>In this example, the context includes:</p> <ul> <li><code>ingress.className</code>: The ingress controller type.</li> <li><code>ingress.domain</code>: The suffix used for building ingress URLs.</li> <li><code>storageClass</code>: Two Kubernetes <code>StorageClass</code> definitions for different application profiles. For our <code>kind</code> based    cluster, there is only one available option: <code>standard</code>.</li> <li><code>certificateIssuer</code>: Two certificate issuers, one to use internally and one intended for endpoints exposed to external    world. As configuring a CA (Certificate Authority) is out of the scope of this documentation, we will set-up only a    self-signed CA. This will be performed later with the chapter on cert-manager deployment </li> </ul> <p>Cluster-wide contexts should be placed in a dedicated namespace:</p> <pre><code>kubectl create ns contexts\n</code></pre> <pre><code>kubectl apply -f contexts/cluster.yaml\n</code></pre> <p>Note</p> <p>Since the context is shared among most of all applications, its structure must be carefully designed and well documented.</p>"},{"location":"user-guide/160-the-context/#package-modification","title":"Package modification","text":"<p>Our initial <code>podinfo</code> package did not account for the context concept. Here is an updated version:</p> podinfo-p02.yaml <pre><code>apiVersion: v1alpha1\ntype: Package\nname: podinfo\ntag: 6.7.1-p02\nschema:\n  parameters:\n    $schema: http://json-schema.org/schema#\n    type: object\n    additionalProperties: false\n    properties:\n      host: { type: string }\n    required:\n      - host\n  context:\n    $schema: http://json-schema.org/schema#\n    additionalProperties: true\n    type: object\n    properties:\n      ingress:\n        type: object\n        additionalProperties: true\n        properties:\n          className: { type: string }\n          domain: { type: string }\n        required:\n          - domain\n          - className\n    required:\n      - ingress\nmodules:\n  - name: main\n    source:\n      helmRepository:\n        url: https://stefanprodan.github.io/podinfo\n        chart: podinfo\n        version: 6.7.1\n    values: |\n      ingress:\n        enabled: true\n        className: {{ .Context.ingress.className  }}\n        hosts:\n          - host: {{ .Parameters.host }}.{{ .Context.ingress.domain }}\n            paths:\n              - path: /\n                pathType: ImplementationSpecific\n</code></pre> <p>Key points:</p> <ul> <li>The <code>tag</code> was updated to generate a new version.</li> <li>The <code>fqdn</code> parameter was replaced with <code>host</code> to represent only the hostname (excluding the domain).</li> <li>The <code>modules[X].values</code> section now uses the context.</li> <li>A <code>schema.context</code> section has been added to define and validate the expected context structure.</li> </ul> <p>This new version must be packaged:</p> <pre><code>kubocd pack packages/podinfo-p02.yaml\n</code></pre> <pre><code>====================================== Packaging package 'podinfo-p02.yaml'\n--- Handling module 'main':\n    Fetching chart podinfo:6.7.1...\n    Chart: podinfo:6.7.1\n--- Packaging\n    Generating index file\n    Wrap all in assembly.tgz\n--- push OCI image: quay.io/kubodoc/packages/podinfo:6.7.1-p02\n    Successfully pushed\n</code></pre>"},{"location":"user-guide/160-the-context/#deployment","title":"Deployment","text":"<p>Here is the corresponding <code>Release</code> manifest:</p> podinfo2-ctx.yaml <pre><code>---\napiVersion: kubocd.kubotal.io/v1alpha1\nkind: Release\nmetadata:\n  name: podinfo2\n  namespace: default\nspec:\n  description: A first sample release of podinfo\n  package:\n    repository: quay.io/kubodoc/packages/podinfo\n    tag: 6.7.1-p02\n    interval: 30m\n  parameters:\n    host: podinfo2\n  contexts:\n    - namespace: contexts\n      name: cluster\n</code></pre> <p>Key points:</p> <ul> <li>The <code>fqdn</code> parameter was replaced with <code>host</code>.</li> <li>A new <code>spec.contexts</code> section lists the contexts to merge into a single object passed to the template engine.</li> </ul> <p>Warning</p> <p>Referencing a non-existent context results in an error.</p> <p>Once <code>spec.repository</code> is set according to your repository, apply the deployment:</p> <pre><code>kubectl apply -f releases/podinfo2-ctx.yaml\n</code></pre> <p>Check that the new <code>Release</code> reaches the <code>READY</code> state:</p> <pre><code>kubectl get releases podinfo2\n</code></pre> <pre><code>NAME       REPOSITORY                         TAG         CONTEXTS           STATUS   READY   WAIT   PRT   AGE   DESCRIPTION\npodinfo2   quay.io/kubodoc/packages/podinfo   6.7.1-p02   contexts:cluster   READY    1/1            -     17m   A first sample release of podinfo\n</code></pre> <p>And check the corresponding <code>\u00ecngress</code> has been configured properly:</p> <pre><code>kubectl get ingresses podinfo2-main\n</code></pre> <pre><code>NAME            CLASS   HOSTS                            ADDRESS      PORTS   AGE\npodinfo2-main   nginx   podinfo2.ingress.kubodoc.local   10.96.59.9   80      120m\n</code></pre> <p>Notes</p> <p>If you want to test access through this ingress, don't forget to update your <code>/etc/host</code> or your DNS.</p>"},{"location":"user-guide/160-the-context/#context-aggregation","title":"Context Aggregation","text":"<p>An application's effective context may result from the aggregation of multiple context objects.</p> <p>For instance, a project-level context can be created to share variables across all applications within a project. This will be merged with the global cluster context.</p> <p>In the following examples, each deployed project has its own namespace and context.</p>"},{"location":"user-guide/160-the-context/#example-1-context-merge","title":"Example 1: Context merge","text":"<p>Create the namespace:</p> <pre><code>kubectl create namespace project01\n</code></pre> <p>Then create the project context:</p> project01.yaml <pre><code>apiVersion: kubocd.kubotal.io/v1alpha1\nkind: Context\nmetadata:\n  name: project01\nspec:\n  description: Context for project 1\n  context:\n    project:\n      id: p01\n      subdomain: prj01\n</code></pre> <p>Note that the <code>namespace</code> is not specified in the manifest. It will be set via the command line:</p> <pre><code>kubectl -n project01 apply -f contexts/project01.yaml\n</code></pre> <p>List all defined contexts:</p> <pre><code>kubectl get --all-namespaces contexts.kubocd.kubotal.io\n</code></pre> <pre><code>NAMESPACE   NAME        DESCRIPTION                          PARENTS   STATUS   AGE\ncontexts    cluster     Global context for the kubodoc cluster          READY    2d2h\nproject01   project01   Context for project 1                           READY    2m35s\n</code></pre> <p>This example requires modifying the package to include the new variable <code>project.subdomain</code> in the <code>values</code> template and in the <code>schema.context</code> section:</p> podinfo-p03.yaml <pre><code>apiVersion: v1alpha1\ntype: Package\nname: podinfo\ntag: 6.7.1-p03\nschema:\n  parameters:\n    $schema: http://json-schema.org/schema#\n    type: object\n    additionalProperties: false\n    properties:\n      host: { type: string }\n    required:\n      - host\n  context:\n    $schema: http://json-schema.org/schema#\n    additionalProperties: true\n    type: object\n    properties:\n      ingress:\n        type: object\n        additionalProperties: true\n        properties:\n          className: { type: string }\n          domain: { type: string }\n        required:\n          - domain\n          - className\n      project:\n        type: object\n        additionalProperties: true\n        properties:\n          subdomain: { type: string }\n        required:\n          - subdomain\n    required:\n      - ingress\n      - project\nmodules:\n  - name: main\n    source:\n      helmRepository:\n        url: https://stefanprodan.github.io/podinfo\n        chart: podinfo\n        version: 6.7.1\n    values: |\n      ingress:\n        enabled: true\n        className: {{ .Context.ingress.className  }}\n        hosts:\n          - host: {{ .Parameters.host }}.{{ .Context.project.subdomain }}.{{ .Context.ingress.domain }}\n            paths:\n              - path: /\n                pathType: ImplementationSpecific\n</code></pre> <p>Package it:</p> <pre><code>kubocd pack packages/podinfo-p03.yaml\n</code></pre> <p>Create a new <code>Release</code> for deployment:</p> podinfo-prj01.yaml <pre><code>---\napiVersion: kubocd.kubotal.io/v1alpha1\nkind: Release\nmetadata:\n  name: podinfo\nspec:\n  description: A release of podinfo on project01\n  package:\n    repository: quay.io/kubodoc/packages/podinfo\n    tag: 6.7.1-p03\n    interval: 30m\n  parameters:\n    host: podinfo\n  contexts:\n    - namespace: contexts\n      name: cluster\n    - name: project01\n  debug:\n    dumpContext: true\n    dumpParameters: true\n</code></pre> <p>Notes:</p> <ul> <li><code>metadata.namespace</code> is not defined; it will be set via command line.</li> <li><code>metadata.name</code> is simply <code>podinfo</code>, assuming only one instance per namespace.</li> <li><code>spec.contexts</code> includes now two entries, with the second referencing the project context. As the namespace is not defined, it will be set to the <code>Release</code> one.</li> <li>A <code>debug</code> section is added to include the resulting <code>context</code> and <code>parameters</code> in the <code>Release</code> status.</li> </ul> <p>Deploy the release:</p> <pre><code>kubectl -n project01 apply -f releases/podinfo-prj01.yaml\n</code></pre> <p>Verify both contexts are listed:</p> <pre><code>kubectl -n project01 get releases podinfo\n</code></pre> <pre><code>NAME      REPOSITORY                         TAG         CONTEXTS                               STATUS   READY   WAIT   PRT   AGE     DESCRIPTION\npodinfo   quay.io/kubodoc/packages/podinfo   6.7.1-p03   contexts:cluster,project01:project01   READY    1/1            -     8m31s   A release of podinfo on project01\n</code></pre> <p>Check the resulting ingress object:</p> <pre><code>kubectl get --all-namespaces ingress\n</code></pre> <pre><code>NAMESPACE   NAME            CLASS   HOSTS                                 ADDRESS        PORTS   AGE\ndefault     podinfo1-main   nginx   podinfo1.ingress.kubodoc.local        10.96.207.51   80      4h46m\ndefault     podinfo2-main   nginx   podinfo2.ingress.kubodoc.local        10.96.207.51   80      4h6m\nproject01   podinfo-main    nginx   podinfo.prj01.ingress.kubodoc.local   10.96.207.51   80      4h\n</code></pre> <p>Inspect the <code>Release</code> status:</p> <pre><code>kubectl -n project01 get release podinfo -o yaml\n</code></pre> <pre><code>apiVersion: kubocd.kubotal.io/v1alpha1\nkind: Release\nmetadata:\n  ....\nspec:\n  ....\nstatus:\n  context:\n    ingress:\n      className: nginx\n      domain: ingress.kubodoc.local\n    project:\n      id: p01\n      subdomain: prj01\n    storageClass:\n      data: standard\n      workspace: standard\n  ....      \n  parameters:\n    host: podinfo2\n  ....\n</code></pre> <p>The merged context includes values from both the cluster and project contexts.</p> <p>Warning</p> <p>In real-world scenarios, the context may become quite large. Use this debug mode sparingly.</p>"},{"location":"user-guide/160-the-context/#example-2-context-override","title":"Example 2: Context override","text":"<p>In this second example, the objective remains the same (adding a subdomain to the ingress), but we use the initial version of the <code>Package</code>, which does not handle <code>project.subdomain</code> context value.</p> <p>Create a dedicated namespace:</p> <pre><code>kubectl create ns project02\n</code></pre> <p>Create a project context in that namespace:</p> project02.yaml <pre><code>apiVersion: kubocd.kubotal.io/v1alpha1\nkind: Context\nmetadata:\n  name: project02\nspec:\n  description: Context for project 2\n  context:\n    project:\n      id: p02\n    ingress:\n      domain: prj02.ingress.kubodoc.local\n</code></pre> <pre><code>kubectl -n project02 apply -f contexts/project02.yaml\n</code></pre> <p>Note that the same <code>spec.context.ingress.domain</code> path exists in both the project and cluster contexts.  When contexts are merged in a <code>Release</code>, later contexts in the list override earlier ones. Thus, the project\u2019s value takes precedence.</p> <p>Create and deploy a new <code>Release</code> object:</p> podinfo-prj02.yaml <pre><code>---\napiVersion: kubocd.kubotal.io/v1alpha1\nkind: Release\nmetadata:\n  name: podinfo\nspec:\n  description: A release of podinfo on project02\n  package:\n    repository: quay.io/kubodoc/packages/podinfo\n    tag: 6.7.1-p02\n    interval: 30m\n  parameters:\n    host: podinfo\n  contexts:\n    - namespace: contexts\n      name: cluster\n    - name: project02\n  debug:\n    dumpContext: true\n    dumpParameters: true\n</code></pre> <pre><code>kubectl -n project02 apply -f releases/podinfo-prj02.yaml\n</code></pre> <p>Check the resulting context in the <code>Release</code> object:</p> <pre><code>kubectl -n project02 get release podinfo -o yaml\n</code></pre> <pre><code>apiVersion: kubocd.kubotal.io/v1alpha1\nkind: Release\nmetadata:\n    ....\nspec:\n    ....\nstatus:\n  context:\n    ingress:\n      className: nginx\n      domain: prj02.ingress.kubodoc.local\n    project:\n      id: p02\n    storageClass:\n      data: standard\n      workspace: standard\n  ....\n</code></pre> <p>Ensure the correct ingress host is used:</p> <pre><code>kubectl get --all-namespaces ingress\n</code></pre> <pre><code>NAMESPACE   NAME            CLASS   HOSTS                                 ADDRESS        PORTS   AGE\ndefault     podinfo1-main   nginx   podinfo1.ingress.kubodoc.local        10.96.218.98   80      2d20h\ndefault     podinfo2-main   nginx   podinfo2.ingress.kubodoc.local        10.96.218.98   80      110m\nproject01   podinfo-main    nginx   podinfo.prj01.ingress.kubodoc.local   10.96.218.98   80      26m\nproject02   podinfo-main    nginx   podinfo.prj02.ingress.kubodoc.local   10.96.218.98   80      2m52s\n</code></pre>"},{"location":"user-guide/160-the-context/#context-change","title":"Context Change","text":"<p>Any change to a context is automatically applied to all associated <code>Release</code> objects. However, only the deployments that are actually affected will be updated.</p> <p>Notes</p> <p>Technically, KuboCD patches the corresponding Flux <code>helmRelease</code> objects, which triggers a <code>helm upgrade</code>. This should only update the resources that are truly impacted.</p> <p>For example, modify the context for <code>project01</code>:</p> <pre><code>kubectl -n project01 patch context.kubocd.kubotal.io project01 --type='json' -p='[{\"op\": \"replace\", \"path\": \"/spec/context/project/subdomain\", \"value\": \"project01\" }]'\n</code></pre> <p>Observe that the ingress is quickly updated accordingly:</p> <pre><code>kubectl get --all-namespaces ingress\n</code></pre> <pre><code>NAMESPACE   NAME            CLASS   HOSTS                                     ADDRESS        PORTS   AGE\ndefault     podinfo1-main   nginx   podinfo1.ingress.kubodoc.local            10.96.218.98   80      3d3h\ndefault     podinfo2-main   nginx   podinfo2.ingress.kubodoc.local            10.96.218.98   80      8h\nproject01   podinfo-main    nginx   podinfo.project01.ingress.kubodoc.local   10.96.218.98   80      7h13m\nproject02   podinfo-main    nginx   podinfo.prj02.ingress.kubodoc.local       10.96.218.98   80      6h49m\n</code></pre> <p>To restore the original value:</p> <pre><code>kubectl -n project01 patch context.kubocd.kubotal.io project01 --type='json' -p='[{\"op\": \"replace\", \"path\": \"/spec/context/project/subdomain\", \"value\": \"prj01\" }]'\n</code></pre>"},{"location":"user-guide/170-context-and-config/","title":"Context and Configuration","text":""},{"location":"user-guide/170-context-and-config/#default-context","title":"Default Context","text":"<p>Following the logic from the previous chapter, it becomes clear that the cluster\u2019s global context should be included in every <code>Release</code>.  From there, the idea of defining a default context naturally follows.</p> <p>Unlike most Kubernetes applications that store configuration in a <code>ConfigMap</code>, KuboCD uses a dedicated Custom Resource for this purpose:</p> <pre><code>kubectl -n kubocd get Config.kubocd.kubotal.io\n</code></pre> <p>Only one instance of this resource exists (it was created during deployment via the Helm chart)</p> <pre><code>NAME     AGE\nconf01   5d21h\n</code></pre> <p>Let's inspect its content:</p> <pre><code>kubectl -n kubocd get Config.kubocd.kubotal.io conf01 -o yaml\n</code></pre> <pre><code>apiVersion: kubocd.kubotal.io/v1alpha1\nkind: Config\nmetadata:\n  annotations:\n    meta.helm.sh/release-name: kubocd-ctrl\n    meta.helm.sh/release-namespace: kubocd\n  creationTimestamp: \"2025-04-16T12:29:27Z\"\n  generation: 1\n  labels:\n    app.kubernetes.io/managed-by: Helm\n  name: conf01\n  namespace: kubocd\n  resourceVersion: \"5191\"\n  uid: 84ff9a8a-83ee-48e7-984d-c95a6a665d5b\nspec:\n  clusterRoles: []\n  defaultContexts: []\n  defaultNamespaceContexts: []\n  imageRedirects: []\n  packageRedirects: []\n</code></pre> <p>At this stage, the configuration is empty</p> <p>Notes</p> <p>Using a Kubernetes resource for configuration has the following advantages:</p> <ul> <li>Structural errors result in immediate rejection without impacting the running service.</li> <li>The resource can be watched. KuboCD will therefore instantly apply any configuration changes.</li> </ul> <p>Here is a new configuration manifest:</p> conf01-b.yaml <pre><code>---\napiVersion: kubocd.kubotal.io/v1alpha1\nkind: Config\nmetadata:\n  name: conf01\n  namespace: kubocd\nspec:\n  defaultContexts:\n    - namespace: contexts\n      name: cluster\n</code></pre> <p>It defines a list of default contexts, which here includes only the cluster context created earlier.</p> <p>Apply it:</p> <pre><code>kubectl apply -f configs/conf01-b.yaml \n</code></pre> <p>Don't worry about any warning messages</p> <p>Note</p> <p>For KuboCD to recognize the <code>Config</code> object, it must reside in the controller\u2019s namespace (<code>kubocd</code>). However, its name does not matter.</p> <p>We can now create a new <code>Release</code> of the <code>podinfo</code> application using the context-enabled version, without explicitly specifying the context:</p> podinfo3-ctx-def.yaml <pre><code>---\napiVersion: kubocd.kubotal.io/v1alpha1\nkind: Release\nmetadata:\n  name: podinfo3\n  namespace: default\nspec:\n  description: A first sample release of podinfo\n  package:\n    repository: quay.io/kubodoc/packages/podinfo\n    tag: 6.7.1-p02\n    interval: 30m\n  parameters:\n    host: podinfo3\n</code></pre> <pre><code>kubectl apply -f releases/podinfo3-ctx-def.yaml \n</code></pre> <p>We can verify that the <code>Release</code> does pick up the context:</p> <pre><code>kubectl get release podinfo3\n</code></pre> <pre><code>NAME       REPOSITORY                         TAG         CONTEXTS           STATUS   READY   WAIT   PRT   AGE   DESCRIPTION\npodinfo3   quay.io/kubodoc/packages/podinfo   6.7.1-p02   contexts:cluster   READY    1/1            -     31m   A first sample release of podinfo\n</code></pre> <p>Which results in a correct <code>domain</code> in the ingress:</p> <pre><code>kubectl get ingress podinfo3-main\n</code></pre> <pre><code>NAME            CLASS   HOSTS                            ADDRESS        PORTS   AGE\npodinfo3-main   nginx   podinfo3.ingress.kubodoc.local   10.96.218.98   80      84s\n</code></pre>"},{"location":"user-guide/170-context-and-config/#namespaced-default-context","title":"Namespaced Default Context","text":"<p>KuboCD also supports defining a default context per namespace.</p> <p>We modify our configuration resource again:</p> conf01-c.yaml <pre><code>---\napiVersion: kubocd.kubotal.io/v1alpha1\nkind: Config\nmetadata:\n  name: conf01\n  namespace: kubocd\nspec:\n  defaultContexts:\n    - namespace: contexts\n      name: cluster\n  defaultNamespaceContexts: \n    - project\n</code></pre> <pre><code>kubectl apply -f configs/conf01-c.yaml \n</code></pre> <p>Thanks to this setup, every <code>Release</code> will attempt to load a context named <code>project</code> from its own namespace, and use it if it exists.</p> <p>Create a new namespace <code>project03</code>:</p> <pre><code>kubectl create ns project03\n</code></pre> <p>Create A project-specific context there, using the generic name <code>project</code>:</p> project03.yaml <pre><code>apiVersion: kubocd.kubotal.io/v1alpha1\nkind: Context\nmetadata:\n  name: project\nspec:\n  description: Context For projet 3\n  context:\n    project:\n      id: p03\n    ingress:\n      domain: prj03.ingress.kubodoc.local\n</code></pre> <pre><code>kubectl -n project03 apply -f contexts/project03.yaml \n</code></pre> <p>We now create a new <code>Release</code> without explicitly specifying which context to use:</p> podinfo-prj03.yaml <pre><code>---\napiVersion: kubocd.kubotal.io/v1alpha1\nkind: Release\nmetadata:\n  name: podinfo\nspec:\n  description: A release of podinfo on project03\n  package:\n    repository: quay.io/kubodoc/packages/podinfo\n    tag: 6.7.1-p02\n    interval: 30m\n  parameters:\n    host: podinfo\n  debug:\n    dumpContext: true\n    dumpParameters: true\n</code></pre> <pre><code>kubectl -n project03 apply -f releases/podinfo-prj03.yaml\n</code></pre> <p>We can confirm both default contexts are applied:</p> <pre><code>kubectl -n project03 get release podinfo\n</code></pre> <pre><code>NAME      REPOSITORY                         TAG         CONTEXTS                             STATUS   READY   WAIT   PRT   AGE   DESCRIPTION\npodinfo   quay.io/kubodoc/packages/podinfo   6.7.1-p02   contexts:cluster,project03:project   READY    1/1            -     10m   A release of podinfo on project03\n</code></pre> <p>And verify that the ingress domain is correctly resolved:</p> <pre><code>kubectl -n project03 get ingress\n</code></pre> <pre><code>NAME           CLASS   HOSTS                                 ADDRESS        PORTS   AGE\npodinfo-main   nginx   podinfo.prj03.ingress.kubodoc.local   10.96.218.98   80      11m\n</code></pre>"},{"location":"user-guide/170-context-and-config/#context-ordering","title":"Context Ordering","text":"<p>As mentioned earlier, the order in which contexts are merged for a <code>Release</code> can be important.</p> <p>The order is:</p> <ul> <li>Global default context, in the order of the list defined in the configuration.</li> <li>Namespace default context, if it exists.</li> <li>Context defined in the <code>Release</code>object, in list order</li> </ul> <p>Last ones will take precedence.</p> <p>Warning</p> <p>Referencing a non-existent context results in an error, except for the namespace-level default context.</p> <p>If you've followed the full guide, your setup should look something like this:</p> <pre><code>kubectl get --all-namespaces releases\n</code></pre> <pre><code>NAMESPACE   NAME            REPOSITORY                               TAG          CONTEXTS                                                STATUS   READY   WAIT   PRT   AGE     DESCRIPTION\ndefault     podinfo1        quay.io/kubodoc/packages/podinfo         6.7.1-p01    contexts:cluster                                        READY    1/1            -     3d20h   A first sample release of podinfo\ndefault     podinfo2        quay.io/kubodoc/packages/podinfo         6.7.1-p02    contexts:cluster,contexts:cluster                       READY    1/1            -     25h     A first sample release of podinfo\ndefault     podinfo3        quay.io/kubodoc/packages/podinfo         6.7.1-p02    contexts:cluster                                        READY    1/1            -     27m     A first sample release of podinfo\nkubocd      ingress-nginx   quay.io/kubodoc/packages/ingress-nginx   4.12.1-p01   contexts:cluster                                        READY    1/1            -     3d23h   The Ingress controller\nproject01   podinfo         quay.io/kubodoc/packages/podinfo         6.7.1-p03    contexts:cluster,contexts:cluster,project01:project01   READY    1/1            -     24h     A release of podinfo on project01\nproject02   podinfo         quay.io/kubodoc/packages/podinfo         6.7.1-p02    contexts:cluster,contexts:cluster,project02:project02   READY    1/1            -     24h     A release of podinfo on project02\nproject03   podinfo         quay.io/kubodoc/packages/podinfo         6.7.1-p02    contexts:cluster,project03:project                      READY    1/1            -     5m55s   A release of podinfo on project03\n</code></pre> <p>You might see cases where the same context is listed twice in a <code>Release</code>, both as a default and explicitly. This has no adverse effects.</p> <p>Tip</p> <p>If for any reason you want to disable default context merging for a specific <code>Release</code>, you can use the <code>skipDefaultContext: true</code> flag in the <code>Release</code> specification.</p>"},{"location":"user-guide/170-context-and-config/#kubocd-helm-chart","title":"KuboCD Helm Chart","text":"<p>These configuration values can be integrated during the KuboCD installation by passing them as Helm <code>values</code>.</p> <p>For example, by creating the following file:</p> values1-ctrl.yaml <pre><code>config:\n  defaultContexts:\n    - name: cluster\n      namespace: contexts\n  defaultNamespaceContext: \n    - project\nextraNamespaces:\n  - name: contexts\ncontexts:\n  - name: cluster\n    namespace: contexts\n    protected: true\n    description: Context specific to the cluster 'kubodoc'\n    context:\n      ingress:\n        className: nginx\n        domain: ingress.kubodoc.local\n      storageClass:\n        data: standard\n        workspace: standard\n</code></pre> <ul> <li> <ul> <li>The <code>config</code> section is injected directly into the <code>Config</code> resource\u2019s <code>spec</code>.</li> </ul> </li> <li> <ul> <li>The <code>extraNamespaces</code> list creates additional namespaces via the Helm chart.</li> </ul> </li> <li> <ul> <li>The <code>contexts</code> section defines context objects created automatically by the Helm chart.</li> </ul> </li> </ul> <p>To upgrade the KuboCD deployment:</p> <pre><code>helm -n kubocd upgrade kubocd-ctrl oci://quay.io/kubocd/charts/kubocd-ctrl:v0.2.2 --values helm-values/values1-ctrl.yaml\n</code></pre> <p>Warning</p> <p>If you've followed the steps in this chapter, an error will be raised \u2014 Helm refuses to manage objects it did not originally create.</p> <p>In that case, delete the <code>contexts</code> namespace and its associated objects first:</p> <pre><code>kubectl -n contexts delete context.kubocd.kubotal.io cluster\n</code></pre> <pre><code>kubectl delete ns contexts\n</code></pre> <p>Then re-run the <code>helm upgrade</code> command.</p> <p>While performing this operation, <code>Releases</code> may temporarily enter the <code>ERROR</code> state before returning to <code>READY</code> once the context is recreated. However, the applications themselves (pods and ingress for <code>podinfo</code>, etc.) will remain unaffected.</p>"},{"location":"user-guide/180-kubocd-cli/","title":"The KuboCD CLI","text":""},{"location":"user-guide/180-kubocd-cli/#kubocd-pack","title":"kubocd pack","text":"<p>Creates a KuboCD package from a manifest and stores it in an OCI image repository.</p> <p>See the A First Deployment / Package Build section for a usage example.</p> <pre><code>Assemble a KuboCd Package from a manifest to an OCI image\n\nUsage:\n  kubocd package &lt;Package manifest&gt; [flags]\n\nAliases:\n  package, pack, build\n\nExamples:\n    Build and push a package:\n    $ kubocd package podinfo-p01.yaml --ociRepoPrefix quay.io/kubodoc/packages\n\n    or\n    $ export OCI_REPO_PREFIX=quay.io/kubodoc/packages\n    $ kubocd package podinfo-p01.yaml\n\nFlags:\n  -h, --help                   help for package\n  -r, --ociRepoPrefix string   OCI repository prefix (i.e 'quay.io/your-organization/packages'). Can also be specified with OCI_REPO_PREFIX environment variable\n  -p, --plainHTTP              Use plain HTTP instead of HTTPS when pushing image\n  -w, --workDir string         Working directory. Default to $HOME/.kubocd\n</code></pre>"},{"location":"user-guide/180-kubocd-cli/#kubocd-dump-package","title":"kubocd dump package","text":"<p>Displays the contents of a KuboCD package.</p> <pre><code>Dump KuboCD Package\n\nUsage:\n  kubocd dump package &lt;package.yaml|oci://repo:version&gt; [flags]\n\nAliases:\n  package, pck, Package, Pck, pack, Pack\n\nExamples:\n    Dump package content from an OCI image repository\n    $ kubocd dump package oci://quay.io/kubodoc/packages/podinfo:6.7.1-p01\n\n    Dump package content from a manifest\n    $ kubocd dump package podinfo-p01.yaml\n\n    Dump package content from a manifest and fetch Helm charts\n    $ kubocd dump package podinfo-p01.yaml --charts\n\nFlags:\n  -a, --anonymous       Connect anonymously to the registry. To check 'public' image status\n  -c, --charts          unpack charts in output directory\n  -h, --help            help for package\n  -i, --insecure        insecure (use HTTP, not HTTPS)\n  -o, --output string   Output dump directory (default \"./.dump\")\n\nGlobal Flags:\n  -w, --workDir string   working directory. Default to $HOME/.kubocd\n</code></pre> <p>Example:</p> <pre><code>kubocd dump package oci://quay.io/kubodoc/packages/podinfo:6.7.1-p01\n</code></pre> <p>or:</p> <pre><code>kubocd dump package packages/podinfo-p01.yaml\n</code></pre> <pre><code>Create .dump/podinfo/status.yaml\nCreate .dump/podinfo/original.yaml\nCreate .dump/podinfo/groomed.yaml\nCreate .dump/podinfo/default-parameters.yaml\nCreate .dump/podinfo/default-context.yaml\n</code></pre> <p>This command creates a <code>.dump</code> directory in the local folder, containing:</p> <ul> <li><code>.dump/podinfo/original.yaml</code>: The original manifest as provided during packaging.</li> <li><code>.dump/podinfo/groomed.yaml</code>: The groomed version of the manifest, including default values and normalized parameter/context schemas.</li> <li><code>.dump/podinfo/default-parameters.yaml</code>: Default parameter values, extracted from the parameter schema.</li> <li><code>.dump/podinfo/default-context.yaml</code>: Default context values, extracted from the context schema.</li> </ul> <p>Optionally, you can extract the Helm charts of the modules embedded in the package:</p> <pre><code>kubocd dump package packages/podinfo-p01.yaml --charts\n</code></pre> <pre><code>--- Handling module 'main':\n    Fetching chart podinfo:6.7.1...\n    Chart: podinfo:6.7.1\nExpand chart podinfo\nCreate .dump/podinfo/status.yaml\nCreate .dump/podinfo/original.yaml\nCreate .dump/podinfo/groomed.yaml\nCreate .dump/podinfo/default-parameters.yaml\nCreate .dump/podinfo/default-context.yaml\n</code></pre> <p>The Helm chart for <code>podinfo</code> is available in <code>.dump/podinfo/charts/main</code>.</p>"},{"location":"user-guide/180-kubocd-cli/#kubocd-dump-helmrepository","title":"kubocd dump helmRepository","text":"<p>This command allows you to explore the contents of a remote Helm repository.</p> <pre><code>Dump helm chart\n\nUsage:\n  kubocd dump helmRepository repoUrl [chartName [version]] [flags]\n\nAliases:\n  helmRepository, hr, HelmRepository, helmrepository, helmRepo, HelmRepo, helmrepo\n\nExamples:\n    List charts from helm repositories\n    $ kubocd dump helmRepository https://stefanprodan.github.io/podinfo\n\n    List all versions for a chart\n    $ kubocd dump helmRepository https://stefanprodan.github.io/podinfo podinfo\n\n    View chart information\n    $ kubocd dump helmRepository https://stefanprodan.github.io/podinfo podinfo 6.8.0\n\n    Download locally the chart\n    $ kubocd dump helmRepository https://stefanprodan.github.io/podinfo podinfo 6.8.0 --chart\n\nFlags:\n  -c, --chart           unpack charts in output directory\n  -h, --help            help for helmRepository\n  -o, --output string   Output chart directory (default \"./.charts\")\n\nGlobal Flags:\n  -w, --workDir string   working directory. Default to $HOME/.kubocd\n</code></pre> <p>Examples:</p>"},{"location":"user-guide/180-kubocd-cli/#list-charts","title":"List charts","text":"<pre><code>kubocd dump helmRepository https://stefanprodan.github.io/podinfo\n</code></pre> <pre><code>---------------Chart in repo 'https://stefanprodan.github.io/podinfo':\npodinfo\n</code></pre>"},{"location":"user-guide/180-kubocd-cli/#list-versions","title":"List versions","text":"<pre><code>kubocd dump helmRepository https://stefanprodan.github.io/podinfo podinfo\n</code></pre> <pre><code>---------- Versions for 'podinfo':\n6.8.0\n6.7.1\n6.7.0\n........\n</code></pre>"},{"location":"user-guide/180-kubocd-cli/#view-contents-of-a-specific-version","title":"View contents of a specific version","text":"<pre><code>kubocd dump helmRepository https://stefanprodan.github.io/podinfo podinfo 6.8.0\n</code></pre> <pre><code>Fetching chart podinfo:6.8.0...\n\nChart: podinfo:6.8.0\n\n---------------------- Chart.yaml:\napiVersion: v1\nappVersion: 6.8.0\ndescription: Podinfo Helm chart for Kubernetes\nhome: https://github.com/stefanprodan/podinfo\nkubeVersion: '&gt;=1.23.0-0'\nmaintainers:\n- email: stefanprodan@users.noreply.github.com\n  name: stefanprodan\nname: podinfo\nsources:\n- https://github.com/stefanprodan/podinfo\nversion: 6.8.0\n\n\n-------------------- content:\npodinfo/Chart.yaml\npodinfo/values.yaml\npodinfo/templates/NOTES.txt\npodinfo/templates/_helpers.tpl\npodinfo/templates/certificate.\n.........\n</code></pre>"},{"location":"user-guide/180-kubocd-cli/#download-a-chart","title":"Download a chart","text":"<p>Use the <code>--chart</code> flag to download the chart into the local <code>.charts</code> directory:</p> <pre><code>kubocd dump helmRepository https://stefanprodan.github.io/podinfo podinfo 6.8.0 --chart\n</code></pre> <pre><code>Fetching chart podinfo:6.8.0...\n\nChart: podinfo:6.8.0\n\n---------------------- Chart.yaml:\napiVersion: v1\n........\n\n-------------------- content:\npodinfo/Chart.yaml\npodinfo/values.yaml\n.......\n\n---------------------- Extract chart podinfo (6.8.0) to ./.charts/podinfo-6.8.0\n</code></pre>"},{"location":"user-guide/180-kubocd-cli/#kubocd-dump-context","title":"kubocd dump context","text":"<p>This command displays the application context as perceived by KuboCD. It requires access to the Kubernetes cluster.</p> <pre><code>Dump KuboCD context\n\nUsage:\n  kubocd dump context [flags]\n\nAliases:\n  context, ctx, Context, Ctx\n\nExamples:\n    Display the context for an application in the default namespace:\n    $ kubocd dump context\n\n    Display the context for an application in the project03 namespace:\n    $ kubocd dump context --namespace project03\n\n    Aggregate specific contexts:\n    $ kubocd dump context --skipDefaultContext --context contexts:cluster --context project01:project01\n\nFlags:\n  -c, --context stringArray      context as 'namespace:name'. May be repeated.\n  -h, --help                     help for context\n      --kubocdNamespace string   The namespace where the kubocd controller is installed in (To fetch configs resources) (default \"kubocd\")\n  -n, --namespace string         namespace (default \"default\")\n      --skipDefaultContext       Don't use default context\n\nGlobal Flags:\n  -w, --workDir string   working directory. Default to $HOME/.kubocd\n</code></pre> <p>Examples:</p> <p>Display the context for an application in the <code>default</code> namespace:</p> <pre><code>kubocd dump context\n</code></pre> <pre><code>---\ningress:\n  className: nginx\n  domain: ingress.kubodoc.local\nstorageClass:\n  data: standard\n  workspace: standard\n</code></pre> <p>Display the context for an application in the <code>project03</code> namespace:</p> <p>It is assumed than this namespace has a default context, as described in previous chapters</p> <pre><code>kubocd dump context --namespace project03\n</code></pre> <pre><code>---\ningress:\n  className: nginx\n  domain: prj03.ingress.kubodoc.local\nproject:\n  id: p03\nstorageClass:\n  data: standard\n  workspace: standard\n</code></pre> <p>Aggregate specific contexts:</p> <pre><code>kubocd dump context --skipDefaultContext --context contexts:cluster --context project01:project01\n</code></pre> <pre><code>---\ningress:\n  className: nginx\n  domain: ingress.kubodoc.local\nproject:\n  id: p01\n  subdomain: prj01\nstorageClass:\n  data: standard\n  workspace: standard\n</code></pre>"},{"location":"user-guide/180-kubocd-cli/#kubocd-render","title":"kubocd render","text":"<p>This command previews all the resources that will be deployed as part of a <code>Release</code>.</p> <p>It is also a good validation of a new <code>Package</code> and/or <code>Release</code> before deployment.</p> <p>It accesses the current Kubernetes cluster (mainly to retrieve <code>Contexts</code>).</p> <pre><code>Render a KuboCD release\n\nUsage:\n  kubocd render &lt;Release manifest&gt; [&lt;package manifest&gt;] [flags]\n\nExamples:\n    Preview a Release.\n    $ render releases/podinfo2-ctx.yaml\n\n    Preview a Release using an alternate package manifest.\n    $ kubocd render releases/podinfo1.yaml packages/podinfo-p01.yaml\n\nFlags:\n  -h, --help                     help for render\n      --kubocdNamespace string   The namespace where the kubocd controller is installed in (To fetch configs resources) (default \"kubocd\")\n  -n, --namespace string         Value to set if release.metadata.namespace is empty (default \"default\")\n  -o, --output string            Output directory (default \"./.render\")\n  -w, --workDir string           working directory. Default to $HOME/.kubocd\n</code></pre> <p>Example:</p> <pre><code>kubocd render releases/podinfo2-ctx.yaml\n</code></pre> <pre><code>Create .render/podinfo2/release.yaml\nCreate .render/podinfo2/configs.yaml\n# Pulling image 'quay.io/kubodoc/packages/podinfo:6.7.1-p02'\nExpand chart podinfo\nCreate .render/podinfo2/package.yaml\nCreate .render/podinfo2/default-parameters.yaml\nCreate .render/podinfo2/default-context.yaml\nCreate .render/podinfo2/status.yaml\nCreate .render/podinfo2/context.yaml\nCreate .render/podinfo2/parameters.yaml\nCreate .render/podinfo2/model.yaml\nCreate .render/podinfo2/roles.yaml\nCreate .render/podinfo2/dependencies.yaml\nCreate .render/podinfo2/ociRepository.yaml\nCreate .render/podinfo2/usage.txt\nCreate .render/podinfo2/helmRepository.yaml\nCreate .render/podinfo2/modules/main/helmRelease.yaml\nCreate .render/podinfo2/modules/main/values.yaml\nCreate .render/podinfo2/modules/main/manifests.yaml\nContexts: contexts:cluster,contexts:cluster\n</code></pre> <p>Key output files:</p> FILES DESCRIPTION release.yaml Final <code>Release</code> manifest with defaults added package.yaml Processed package manifest with normalized parameter and context schemas default-parameters.yaml Default parameter values extracted from the parameter schema default-context.yaml Default context values extracted from the context schema context.yaml Resulting context after processing parameters.yaml Parameters provided for templating model.yaml Complete data model used for templating values and other properties roles.yaml List of roles fulfilled by this deployment dependencies.yaml List of deployment dependencies ociRepository.yaml Flux <code>OCIRepository</code> object to be created usage.txt Templated result of the package usage helmRepository.yaml Flux <code>HelmRepository</code> object to be created modules/main/helmRelease.yaml Flux <code>HelmRelease</code> object for the main module modules/main/values.yaml Templated Helm values for the main module modules/main/manifests.yaml Result of <code>helm template --debug ...</code> for the main module <p>Tips</p> <p>It is of good practice to check a <code>Release</code> with this <code>kubocd render</code> command before deployment on the cluster.</p>"},{"location":"user-guide/190-alternate-schema-format/","title":"Alternate KuboCD Schema Format","text":"<p>In our previous examples, we defined <code>schema.parameters</code> and <code>schema.context</code> using a standard OpenAPI/JSON schema.  While fully supported, it can be quite verbose.</p> <p>KuboCD also supports a more concise schema syntax, specifically designed for this use case.</p> <p>Here is one of our <code>podinfo</code> <code>Package</code> example from a previous chapter (Only the <code>schema</code> section) </p> podinfo-p02.yaml <pre><code>apiVersion: v1alpha1\n........\nschema:\n  parameters:\n    $schema: http://json-schema.org/schema#\n    type: object\n    additionalProperties: false\n    properties:\n      host: { type: string }\n    required:\n      - host\n  context:\n    $schema: http://json-schema.org/schema#\n    additionalProperties: true\n    type: object\n    properties:\n      ingress:\n        type: object\n        additionalProperties: true\n        properties:\n          className: { type: string }\n          domain: { type: string }\n        required:\n          - domain\n          - className\n    required:\n      - ingress\nmodules:\n.........\n</code></pre> <p>Here\u2019s an identical version of this <code>Package</code> using the simplified KuboCD schema format:</p> podinfo-p02-alt.yaml <pre><code>apiVersion: v1alpha1\n......\nschema:\n  parameters:\n    properties:\n      host: { type: string, required: true }\n  context:\n    properties:\n      ingress:\n        required: true\n        properties:\n          className: { type: string, required: true }\n          domain: { type: string, required: true }\nmodules:\n.......\n</code></pre> <p>As you can see, the format is significantly more compact.</p> <p>Info</p> <p>This schema format is NOT standard OpenAPI</p> <p>The presence or absence of the <code>$schema:</code> key is what KuboCD uses to distinguish between standard and KuboCD schema formats.</p> <p>The difference are the following:</p> <ul> <li>No <code>$schema:</code> key for the KuboCD format</li> <li>The <code>required</code> fields are not in an array anymore, but are now an attribute of the node.</li> <li>The flag <code>additionalProperties: false</code> is set on all object and sub-object of a <code>parameters</code> schema.</li> <li>The flag <code>additionalProperties: true</code> is set on all object and sub-object of a <code>context</code> schema.</li> <li>the <code>type: object</code> is now optional. It is deduced from the presence of the <code>properties</code> attribute.</li> <li>the <code>type: array</code> is now optional. It is deduced from the presence of the <code>items</code> attribute.</li> <li>All others attributes (<code>default</code>, <code>enums</code>, <code>pattern</code>, ....) are left unchanged.</li> </ul> <p>When a <code>Package</code> is build using this form, both schemas are converted to their standard OpenAPI/JSON and stored in this last form. </p> <p>This normalized version will be accessible using <code>kubocd dump package...</code> or <code>kubocd render....</code> CLI tools.</p> <p>Warning</p> <p>If you still use the standard form, setting <code>additionalProperties: false</code> on all objects of <code>schema.parameters</code> is important.  If not, any typo in a variable name will not be trapped and may lead tricky errors.</p> <p>For the remaining of this manuel, we will use the KuboCD schema. </p>"},{"location":"user-guide/200-redis/","title":"Advanced features: Redis sample","text":"<p>We will use another example to demonstrate some of KuboCD\u2019s more advanced features.</p> redis-p01.yaml <pre><code>apiVersion: v1alpha1\nname: redis\ntag: 20.6.1-p01\ndescription: Redis and a front UI\nschema:\n  parameters:\n    properties:\n      redis:\n        properties:\n          password: { type: string, default: redis123 }\n          replicaCount: { type: integer, default: 1, description: \"The number of replicas\"}\n      ui:\n        required: true\n        properties:\n          enabled: { type: boolean, default: true }\n          host: { type: string, required: true }\n  context:\n    properties:\n      ingress:\n        required: true\n        properties:\n          className: { type: string, default: \"nginx\"}\n          domain: { type: string, required: true }\nmodules:\n  - name: redis\n    timeout: 4m\n    source:\n      oci:\n        repository: registry-1.docker.io/bitnamicharts/redis\n        tag: 20.6.1\n    values: |\n      fullnameOverride: {{ .Release.metadata.name }}-main\n      global:\n        redis:\n          password: {{ .Parameters.redis.password }}\n        security:\n          allowInsecureImages: true\n      master:\n        persistence:\n          enabled: false\n      replica:\n        persistence:\n          enabled: false\n        replicaCount: {{ .Parameters.redis.replicaCount }}\n  - name: ui\n    enabled: \"{{ .Parameters.ui.enabled }}\"\n    source:\n      git:\n        url: https://github.com/joeferner/redis-commander.git\n        path: ././k8s/helm-chart/redis-commander\n        branch: master\n    values: |\n      fullnameOverride: {{ .Release.metadata.name }}-ui\n      redis:\n        # host is &lt;fullnameOverride&gt;-&lt;moduleName&gt;-master\n        host: {{ printf \"%s-master\" .Release.metadata.name }}\n        password: {{ .Parameters.redis.password }}\n      ingress:\n        enabled: true\n        className: {{ .Context.ingress.className }}\n        hosts:\n          - host: {{ .Parameters.ui.host }}.{{.Context.ingress.domain}}\n            paths:\n              - \"/\"\n    dependsOn:\n      - redis\nroles: |\n  - redis\n  {{ if .Parameters.ui.enabled }}\n  - redis-ui\n  {{ end }}\ndependencies: |\n  {{ if .Parameters.ui.enabled }}\n  - ingress\n  {{ end }}\n</code></pre> <p>We will now explore the new features used in this package.</p>"},{"location":"user-guide/200-redis/#integrate-multiple-modules","title":"Integrate Multiple Modules","text":"<p>This package integrates two modules: the Redis server itself, and Commander, a Redis UI front end.</p> <p>There is a single data model used by both modules, which allows variables to be shared easily.</p> <p>Consequently, the <code>schema.parameters</code> and <code>schema.context</code> are also global.</p> <p>Regarding the related Flux objects, there will be one <code>OCIRepository</code>, one <code>HelmRepository</code>, and two <code>HelmReleases</code>.</p>"},{"location":"user-guide/200-redis/#configure-different-source-types","title":"Configure Different Source Types","text":"<p>Redis publishes its Helm chart as an OCI image. Therefore, in the source section of the first module, the chart is  referenced in this form.</p> <p>Redis Commander, on the other hand, provides its chart only through its GitHub repository. Thus, it is referenced in the source section of the second module accordingly.</p>"},{"location":"user-guide/200-redis/#control-module-deployment","title":"Control Module Deployment","text":"<p>The <code>ui</code> module includes a <code>disabled</code> attribute, which can be templated. This allows the deployment of this module to be  conditionally triggered based on a choice made during deployment, using a parameter passed to the <code>Release</code> resource.</p>"},{"location":"user-guide/200-redis/#manage-dependencies","title":"Manage Dependencies","text":"<p>Usually, in the Kubernetes ecosystem, it is possible to ignore dependencies between applications, as they are typically  well-designed and operate with retry logic until they eventually reach a stable state.</p> <p>However, this approach has its limitations. To address them, KuboCD introduces a structured dependency system between  deployments.</p> <p>KuboCD manages dependencies:</p> <ul> <li>Between modules within the same package</li> <li>Between different packages</li> </ul> <p>These two types of dependencies rely on different mechanisms.</p>"},{"location":"user-guide/200-redis/#module-dependencies","title":"Module Dependencies","text":"<p>From the sample above:</p> <pre><code>apiVersion: v1alpha1\nname: redis\n......\nmodules:\n  - name: redis\n    ........\n  - name: ui\n    ..........\n    dependsOn:\n      - redis\n</code></pre> <p>The <code>dependsOn</code> attribute lists other module names that the current module depends on. These modules must belong to the same <code>Package</code></p> <p>In this example, it ensures that the deployment of the <code>ui</code> module will wait until the deployment of the <code>redis</code> module is complete.</p> <p>This mechanism results in adding the <code>dependsOn</code> attribute to the Flux <code>HelmRelease</code> resource corresponding to the <code>ui</code> module.</p>"},{"location":"user-guide/200-redis/#release-dependencies-and-roles","title":"Release Dependencies and Roles","text":"<p>For cross-Release dependencies, KuboCD introduces an abstraction: the concept of roles.</p> <p>A <code>Release</code> can fulfill one (or more) roles, and similarly, it can depend on one (or more) roles.</p> <p>This abstraction offers much greater flexibility. For example, an application that exposes a web service outside the  cluster depends on the presence of an ingress controller. It would therefore depend on a role named <code>ingress</code>,  regardless of whether the controller is implemented by NGINX, Traefik, Kong, or another solution.</p> <p>Roles can be defined at the <code>Package</code> level, as in this example, or directly at the <code>Release</code> level, using the <code>spec.roles</code> attribute.</p> <p>Similarly, dependencies can be defined at either the <code>Package</code> level or the <code>Release</code> level, using the <code>spec.dependencies</code> attribute.</p> <p>Note:     During rendering, both roles and dependencies defined at the Package and Release levels are concatenated.     This ensures that the final dependency graph combines all relevant definitions from both scopes.</p>"},{"location":"user-guide/200-redis/#cluster-roles","title":"Cluster roles","text":"<p>The deployment of a package is conditioned on the availability of the roles it depends on, meaning that at least one  application fulfilling each required role must be successfully deployed.</p> <p>In some cases, a role may already be fulfilled by an application that was not deployed by KuboCD. For example, if you're using a cluster that already includes an Ingress controller and a Load Balancer, you need  to inform KuboCD that these roles are already satisfied externally.</p> <p>Such roles are called <code>ClusterRoles</code>, and their list is defined in the global KuboCD configuration resource: <code>Config</code>.</p>"},{"location":"user-guide/200-redis/#deployment","title":"Deployment","text":""},{"location":"user-guide/200-redis/#packaging","title":"Packaging","text":"<p>This new application must be packaged:</p> <pre><code>kubocd pack packages/redis-p01.yaml \n</code></pre> <pre><code>====================================== Packaging package 'packages/redis-p01.yaml'\n--- Handling module 'redis':\n    Pulling image 'registry-1.docker.io/bitnamicharts/redis:20.6.1'\n    Chart: redis:20.6.1\n--- Handling module 'ui':\n    Cloning git repository 'https://github.com/joeferner/redis-commander.git'\n    Chart: redis-commander:0.6.0\n--- Packaging\n    Generating index file\n    Wrap all in assembly.tgz\n--- push OCI image: quay.io/kubodoc/packages/redis:20.6.1-p01\n    Successfully pushed\n</code></pre>"},{"location":"user-guide/200-redis/#full-deployment","title":"Full deployment","text":"<p>A first deployment, including the front end:</p> redis1-basic.yaml <pre><code>---\napiVersion: kubocd.kubotal.io/v1alpha1\nkind: Release\nmetadata:\n  name: redis1\n  namespace: default\nspec:\n  package:\n    repository: quay.io/kubodoc/packages/redis\n    tag: 20.6.1-p01\n    interval: 30m\n  parameters:\n    ui:\n      host: redis1\n</code></pre> <pre><code>kubectl apply -f releases/redis1-basic.yaml \n</code></pre> <p>You can now check the status of the deployment. Note that this may take some time, as the Redis deployment can be quite slow.</p> <pre><code>kubectl get release redis1\n</code></pre> <pre><code>NAME     REPOSITORY                       TAG          CONTEXTS           STATUS   READY   WAIT   PRT   AGE     DESCRIPTION\nredis1   quay.io/kubodoc/packages/redis   20.6.1-p01   contexts:cluster   READY    2/2            -     3m19s   Redis and a front UI\n</code></pre> <p>Notice the 2/2 under the READY column, which corresponds to the two modules.</p> <p>You can also inspect the status of the corresponding Flux <code>HelmRelease</code> resources:</p> <pre><code>kubectl get helmReleases \n</code></pre> <pre><code>NAME            AGE     READY   STATUS\n........\nredis1-redis    2m31s   True    Helm install succeeded for release default/redis1-redis.v1 with chart redis@20.6.1\nredis1-ui       2m31s   True    Helm install succeeded for release default/redis1-ui.v1 with chart redis-commander@0.6.0\n.......\n</code></pre> <p>And related <code>pods</code>:</p> <pre><code>kubectl get pods\n</code></pre> <pre><code>NAME                                                     READY   STATUS    RESTARTS   AGE\n.......\nredis1-main-master-0                                     1/1     Running   0          12m\nredis1-main-replicas-0                                   1/1     Running   0          12m\nredis1-ui-855cb8d656-rlqqh                               1/1     Running   0          11m\n.......\n</code></pre> <p>And related ingress resource:</p> <pre><code>kubectl get ingresses redis1-ui\n</code></pre> <pre><code>NAME        CLASS   HOSTS                          ADDRESS      PORTS   AGE\nredis1-ui   nginx   redis1.ingress.kubodoc.local   10.96.59.9   80      3m40s\n</code></pre>"},{"location":"user-guide/200-redis/#redis-only-deployment","title":"Redis only deployment","text":"<p>In this other deployment, only the Redis server is deployed.</p> <p>To satisfy the <code>schema.Parameters</code>, a dummy value must be provided for <code>ui.host</code>.</p> redis2-basic.yaml <pre><code>---\napiVersion: kubocd.kubotal.io/v1alpha1\nkind: Release\nmetadata:\n  name: redis2\n  namespace: default\nspec:\n  package:\n    repository: quay.io/kubodoc/packages/redis\n    tag: 20.6.1-p01\n    interval: 30m\n  parameters:\n    ui:\n      enabled: false\n      host: dummy\n</code></pre> <p>Then:</p> <pre><code>kubectl apply -f releases/redis2-basic.yaml \n</code></pre> <pre><code>kubectl get helmReleases \n</code></pre> <pre><code>.......\nredis1-redis    10m     True    Helm install succeeded for release default/redis1-redis.v1 with chart redis@20.6.1\nredis1-ui       10m     True    Helm install succeeded for release default/redis1-ui.v1 with chart redis-commander@0.6.0\nredis2-redis    2m45s   True    Helm install succeeded for release default/redis2-redis.v1 with chart redis@20.6.1\n.......\n</code></pre> <pre><code>kubectl get pods\n</code></pre> <pre><code>NAME                                                     READY   STATUS    RESTARTS   AGE\n.......\nredis1-main-master-0                                     1/1     Running   0          12m\nredis1-main-replicas-0                                   1/1     Running   0          12m\nredis1-ui-855cb8d656-rlqqh                               1/1     Running   0          11m\nredis2-main-master-0                                     1/1     Running   0          4m51s\nredis2-main-replicas-0                                   1/1     Running   0          4m51s\n.......\n</code></pre> <p>Tip</p> <p>It is possible to define a more precise schema, without the <code>host: dummy</code> constraint, by using the normalized syntax. You can find an implementation here.</p>"},{"location":"user-guide/210-cert-manager/","title":"Cert-manager setup","text":"<p>Warning</p> <p>If you're using an existing cluster, there's likely already a cert-manager installed. Do not install another one. However, you should still read this section as several new features are described.</p> <p>If you're following the local <code>kind</code> cluster setup, you can safely proceed with this installation.</p>"},{"location":"user-guide/210-cert-manager/#cert-and-trust-manager","title":"Cert and Trust manager","text":"<p>To enable secure communication within the cluster and with external services, we will deploy both cert-manager and trust-manager.</p> <ul> <li>cert-manager will handle the automated issuance and renewal of TLS certificates</li> <li>while trust-manager will manage the distribution of trusted CA certificates across the cluster.</li> </ul> <p>After deploying cert-manager and trust-manager, the next steps involve setting up a self-signed Certificate Authority  (CA) and creating trust bundles:</p> <ul> <li> <p>Create a Self-Signed Certificate Authority (CA):</p> <p>We will create a private, self-signed CA within the cluster. cert-manager will issue and maintain a self-signed certificate that acts as the root CA,  which will be used to sign internal service certificates.</p> </li> <li> <p>Create a Trust Bundle:</p> <p>Once the self-signed CA is available, we will create a trust bundle using trust-manager. A trust bundle collects and distributes trusted CA certificates (including our self-signed CA) to applications  across the cluster, ensuring that services can trust certificates issued by this CA.</p> </li> </ul>"},{"location":"user-guide/210-cert-manager/#the-kubocd-package","title":"The KuboCD package","text":"<p>All of these components will be grouped into a single package, composed of three modules:</p> <ul> <li><code>main</code>, which handles the deployment of the cert-manager Helm chart</li> <li><code>trust</code>, which handles the deployment of the trust-manager Helm chart</li> <li><code>issuer</code>, which handles the deployment of an ad hoc Helm chart that creates the self-signed CA and the Trust Bundle</li> </ul> cert-manager-p01.yaml <pre><code>---\napiVersion: v1alpha1\nname: redis\ntag: 20.6.1-p01\ndescription: Redis and a front UI\nschema:\n  parameters:\n    $schema: http://json-schema.org/schema#\n    type: object\n    additionalProperties: false\n    description: Redis stack\n    required:\n      - ui\n    properties:\n      redis:\n        type: object\n        additionalProperties: false\n        properties:\n          password:\n            default: redis123\n            type: string\n          replicaCount:\n            default: 1\n            description: The number of replicas\n            type: integer\n        required: []\n      ui:\n        type: object\n        additionalProperties: false\n        properties:\n          enabled:\n            default: true\n            type: boolean\n          host:\n            type: string\n        anyOf:\n          - properties:\n              enabled: { const: true }\n            required:\n              - host\n          - properties:\n              enabled: { const: false }\n            required: []\n  context:\n    properties:\n      ingress:\n        required: true\n        properties:\n          className: { type: string, default: \"nginx\"}\n          domain: { type: string, required: true }\nmodules:\n  - name: redis\n    timeout: 4m\n    source:\n      oci:\n        repository: registry-1.docker.io/bitnamicharts/redis\n        tag: 20.6.1\n    values: |\n      fullnameOverride: {{ .Release.metadata.name }}-main\n      global:\n        redis:\n          password: {{ .Parameters.redis.password }}\n        security:\n          allowInsecureImages: true\n      master:\n        persistence:\n          enabled: false\n      replica:\n        persistence:\n          enabled: false\n        replicaCount: {{ .Parameters.redis.replicaCount }}\n  - name: ui\n    enabled: \"{{ .Parameters.ui.enabled }}\"\n    source:\n      git:\n        url: https://github.com/joeferner/redis-commander.git\n        path: ././k8s/helm-chart/redis-commander\n        branch: master\n    values: |\n      fullnameOverride: {{ .Release.metadata.name }}-ui\n      redis:\n        # host is &lt;fullnameOverride&gt;-&lt;moduleName&gt;-master\n        host: {{ printf \"%s-master\" .Release.metadata.name }}\n        password: {{ .Parameters.redis.password }}\n      ingress:\n        enabled: true\n        className: {{ .Context.ingress.className }}\n        hosts:\n          - host: {{ .Parameters.ui.host }}.{{.Context.ingress.domain}}\n            paths:\n              - \"/\"\n    dependsOn:\n      - redis\nroles: |\n  - redis\n  {{ if .Parameters.ui.enabled }}\n  - redis-ui\n  {{ end }}\ndependencies: |\n  {{ if .Parameters.ui.enabled }}\n  - ingress\n  {{ end }}\n</code></pre> <p>Notes</p> <p>More detailed explanations about the usage, configuration, and associated Helm charts of cert-manager and trust-manager are out of scope for this manual. Please refer to their official documentation for further information.</p>"},{"location":"user-guide/210-cert-manager/#local-helm-chart","title":"Local Helm Chart","text":"<p>In addition to demonstrating KuboCD\u2019s ability to deploy a relatively complex application stack, this example also  introduces a new type of source for Helm charts.</p> <p>As mentioned earlier, the deployment of the self-signed CA and the Trust Bundle is handled by a small ad hoc Helm chart. This chart is stored alongside the manifest and is referenced via <code>modules[3].source.local.path</code>, where the path is  relative to the location of the manifest.</p> <p>Like the other modules, this chart will be embedded into the OCI image during packaging.</p>"},{"location":"user-guide/210-cert-manager/#deployment","title":"Deployment","text":"<p>As usual, a package must be built:</p> <pre><code>kubocd pack packages/cert-manager-p01.yaml\n</code></pre> <pre><code>====================================== Packaging package 'packages/cert-manager-p01.yaml'\n--- Handling module 'main':\n    Fetching chart cert-manager:v1.17.1...\n    Chart: cert-manager:v1.17.1\n--- Handling module 'trust':\n    Fetching chart trust-manager:v0.16.0...\n    Chart: trust-manager:v0.16.0\n--- Handling module 'issuers':\n    Fetching chart from '/Users/sa/dev/d1/git/kubocd-doc/samples/charts/cert-issuers/0.1.0'\n    Chart: cert-issuers:0.1.0\n--- Packaging\n    Generating index file\n    Wrap all in assembly.tgz\n--- push OCI image: quay.io/kubodoc/packages/cert-manager:1.17.1-p01\n    Successfully pushed\n</code></pre> <p>And deployed by creating a <code>Release</code> resource:</p> cert-manager-p01.yaml <pre><code>---\napiVersion: kubocd.kubotal.io/v1alpha1\nkind: Release\nmetadata:\n  name: cert-manager\n  namespace: kubocd\nspec:\n  description: The certificate manager\n  package:\n    repository: quay.io/kubodoc/packages/cert-manager\n    tag: 1.17.1-p01\n    interval: 30m\n  parameters:\n    issuers:\n      selfSignedClusterIssuers:\n        - name: cluster-self\n    trust:\n      enabled: true\n      bundle:\n        target:\n          configMap:\n            enabled: true\n          secret:\n            enabled: true\n  targetNamespace: cert-manager\n  createNamespace: true \n</code></pre> <p>Like the ingress controller, the <code>Release</code> resource is deployed in the system namespace <code>kubocd</code>, while the deployment  itself takes place in the <code>cert-manager</code> namespace, which is created automatically.</p> <p>Apply the <code>Release</code> manifest:</p> <pre><code>kubectl apply -f releases/cert-manager.yaml\n</code></pre> <p>We can check the <code>Release</code> state:</p> <pre><code>kubectl -n kubocd get releases cert-manager\n</code></pre> <pre><code>NAME           REPOSITORY                              TAG          CONTEXTS           STATUS   READY   WAIT   PRT   AGE    DESCRIPTION\ncert-manager   quay.io/kubodoc/packages/cert-manager   1.17.1-p01   contexts:cluster   READY    3/3            X     3m5s   The certificate manager\n</code></pre> <p>It may take a couple of minutes to reach the <code>READY 3/3</code> state.</p> <p>We can also check cert-manager and trust-manager pods are up and running:</p> <pre><code>kubectl -n cert-manager get pods\n</code></pre> <pre><code>NAME                                           READY   STATUS    RESTARTS   AGE\ncert-manager-main-6c8f6bf7bf-zwftl             1/1     Running   0          12m\ncert-manager-main-cainjector-ff8b5d695-hdv7z   1/1     Running   0          12m\ncert-manager-main-webhook-7d776cf7b8-6b5gh     1/1     Running   0          12m\ntrust-manager-54d8c969b5-xjjbz                 1/1     Running   0          10m\n</code></pre> <p>As mentioned earlier, the role of trust-manager is to distribute, across the various namespaces of the cluster, the  certificates needed to validate the CAs used by cert-manager.</p> <p>This certificate can be provided either as a Secret and/or a ConfigMap. In our example, both forms are enabled  (<code>.spec.parameters.trust.bundle.target.configMap.enabled: true</code> and <code>.spec.parameters.trust.bundle.target.secret.enabled: true</code> in the Release object).</p> <p>The name of this object is a parameter, with its default value defined in the <code>Package</code> parameter schema as <code>certs-bundle</code>: (<code>schema.parameters.properties.trust.properties.bundle.properties.name.default: certs-bundle</code>).</p> <p>Using both a Secret and a ConfigMap allows compatibility with different workloads. The Secret provides better security for sensitive data, while the ConfigMap can be used by applications that don't require strict secret handling.</p> <p>So, let's display this:</p> <pre><code>kubectl get --all-namespaces secrets | grep certs-bundle\n</code></pre> <pre><code>cert-manager         certs-bundle                                 Opaque               3      11m\ncontexts             certs-bundle                                 Opaque               3      11m\ndefault              certs-bundle                                 Opaque               3      11m\nflux-system          certs-bundle                                 Opaque               3      11m\ningress-nginx        certs-bundle                                 Opaque               3      11m\nkube-node-lease      certs-bundle                                 Opaque               3      11m\nkube-public          certs-bundle                                 Opaque               3      11m\nkube-system          certs-bundle                                 Opaque               3      11m\nkubocd               certs-bundle                                 Opaque               3      11m\nlocal-path-storage   certs-bundle                                 Opaque               3      11m\nproject01            certs-bundle                                 Opaque               3      11m\nproject02            certs-bundle                                 Opaque               3      11m\nproject03            certs-bundle                                 Opaque               3      11m\n</code></pre> <pre><code>kubectl get --all-namespaces configMap | grep certs-bundle\n</code></pre> <pre><code>cert-manager         certs-bundle                                           3      62m\ncontexts             certs-bundle                                           3      62m\ndefault              certs-bundle                                           3      62m\nflux-system          certs-bundle                                           3      62m\ningress-nginx        certs-bundle                                           3      62m\nkube-node-lease      certs-bundle                                           3      62m\nkube-public          certs-bundle                                           3      62m\nkube-system          certs-bundle                                           3      62m\nkubocd               certs-bundle                                           3      62m\nlocal-path-storage   certs-bundle                                           3      62m\nproject01            certs-bundle                                           3      62m\nproject02            certs-bundle                                           3      62m\nproject03            certs-bundle                                           3      62m\n</code></pre> <p>Of course, the <code>trust-manager</code> controller watches new namespace creation to populate them with these resources.</p>"},{"location":"user-guide/210-cert-manager/#secure-podinfo","title":"Secure podinfo","text":"<p>Now it\u2019s time to use this deployment to secure our <code>podinfo</code> application.</p> <p>The following is an improved version of the package, which optionally adds TLS encryption to the ingress controller:</p> podinfo-p04.yaml <pre><code>apiVersion: v1alpha1\ntype: Package\nname: podinfo\ntag: 6.7.1-p04\nschema:\n  parameters:\n    properties:\n      host: { type: string, required: true }\n      tls: { type: boolean, default: false }\n  context:\n    properties:\n      ingress:\n        required: true\n        properties:\n          className: { type: string, required: true }\n          domain: { type: string, required: true }\nmodules:\n  - name: main\n    source:\n      helmRepository:\n        url: https://stefanprodan.github.io/podinfo\n        chart: podinfo\n        version: 6.7.1\n    values: |\n      ingress:\n        enabled: true\n        className: {{ .Context.ingress.className  }}\n        {{- if .Parameters.tls }}\n        annotations:\n          cert-manager.io/cluster-issuer: {{ required \".Context.certificateIssuer.public must be defined if tls: true\" .Context.certificateIssuer.public }}\n        {{- end }}\n        hosts:\n          - host: {{ .Parameters.host }}.{{ .Context.ingress.domain }}\n            paths:\n              - path: /\n                pathType: ImplementationSpecific\n        {{- if .Parameters.tls }}\n        tls:\n          - secretName: {{ .Release.metadata.name }}-tls\n            hosts:\n              - {{  .Parameters.host }}.{{ .Context.ingress.domain }}\n        {{- end }}\n</code></pre> <p>As usual, this need to be packaged:</p> <pre><code>kubocd pack packages/podinfo-p04.yaml\n</code></pre> <pre><code>====================================== Packaging package 'packages/podinfo-p04.yaml'\n--- Handling module 'main':\n    Fetching chart podinfo:6.7.1...\n    Chart: podinfo:6.7.1\n--- Packaging\n    Generating index file\n    Wrap all in assembly.tgz\n--- push OCI image: quay.io/kubodoc/packages/podinfo:6.7.1-p04\n    Successfully pushed\n</code></pre> <p>Here is the new version of the related <code>Release</code> resource:</p> podinfo4-tls.yaml <pre><code>---\napiVersion: kubocd.kubotal.io/v1alpha1\nkind: Release\nmetadata:\n  name: podinfo4\n  namespace: default\nspec:\n  description: A secured release of podinfo\n  package:\n    repository: quay.io/kubodoc/packages/podinfo\n    tag: 6.7.1-p04\n    interval: 30m\n  parameters:\n    tls: true\n    host: podinfo4\n</code></pre> <p>Deploy it:</p> <pre><code>kubectl apply -f releases/podinfo4-tls.yaml\n</code></pre> <p>And configure the DNS entry (Here if you use <code>/etc/hosts</code>)</p> <pre><code>127.0.0.1 localhost host.docker.internal podinfo1.ingress.kubodoc.local podinfo2.ingress.kubodoc.local podinfo4.ingress.kubodoc.local\n</code></pre> <p>You should now be able to access the secures 'podinfo` web server:</p> <p>\ud83d\udc49 http://podinfo4.ingress.kubodoc.local.</p>"}]}