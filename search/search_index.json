{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"KuboCD","text":""},{"location":"#why-kubocd","title":"Why KuboCD ?","text":"<p>Most applications that can be deployed on Kubernetes come with a Helm chart. Moreover, this Helm chart is generally highly flexible, designed to accommodate as many contexts as possible. This can make its configuration quite complex.</p> <p>Furthermore, deploying an application on Kubernetes using an Helm Chart requires a deep understanding of the Kubernetes ecosystem. As a result, application deployment is typically the responsibility of platform administrators or platform engineers.</p> <p>And even for experienced administrators, the verbosity of Helm configurations, especially the repetition of variables, can quickly become tedious and error-prone. Therefore, industrializing these configurations is crucial to improve efficiency and reliability.</p> <p>KuboCD is a tool that enables Platform Engineers to package applications in a way that simplifies deployment for other  technical users (such as Developers, AppOps, etc.) by abstracting most of the underlying infrastructure and environment complexities.</p> <p>In addition to user applications, KuboCD can also provision core system components (e.g., ingress controllers,  load balancers, Kubernetes operators, etc.), enabling fully automated bootstrapping of a production-ready cluster  from the ground up.</p>"},{"location":"#when-to-use-kubocd","title":"When to Use KuboCD","text":"<p>KuboCD is particularly useful when:</p> <ul> <li>You want to standardize application deployment workflows across teams and environments, without requiring everyone to master Helm or Kubernetes internals.</li> <li>You are already using GitOps tools like FluxCD or ArgoCD, and need a structured way to package and manage applications as versioned, portable artifacts.</li> <li>You want to encapsulate application configuration and logic into reusable, declarative units (Packages), decoupled from cluster-specific deployment scripts.</li> <li>You need to simplify access to existing Helm charts for developers, while enforcing consistency and best practices through curated Releases.</li> <li>You want to bootstrap entire environments (including base system components like ingress controllers, operators, etc.) in a fully automated way.</li> </ul>"},{"location":"#main-concepts","title":"Main concepts","text":"<p>KuboCD introduces two core concepts that form the foundation of its deployment model:</p> <ul> <li> <p>Package:   A Package is an OCI-compliant container image that bundles an application descriptor along with one or more Helm charts.    It serves as the standardized unit of deployment, encapsulating everything needed to describe and install an application.</p> </li> <li> <p>Release   A Release is a custom Kubernetes resource that represents the deployment of a specific Package within a Kubernetes cluster.    It defines how and where the application is deployed, and manages the lifecycle of that deployment.</p> </li> </ul>"},{"location":"#kubocd-flux-helm-and-gitops","title":"KuboCD, Flux, Helm and GitOps","text":"<p>KuboCD is designed to seamlessly integrate with Flux, enabling a fully automated GitOps workflow.  While Flux handles the continuous delivery aspect (tracking changes in Git and applying them to the cluster),  KuboCD simplifies application packaging and deployment logic, making the overall delivery pipeline more modular, maintainable, and user-friendly.</p> <p>KuboCD is not a replacement for Helm. It is quite the opposite. It builds on top of Helm\u2019s proven capabilities and  leverages the rich ecosystem of existing Helm charts.</p> <p>Most production-grade applications already provide an official or community-maintained Helm chart.  KuboCD makes these charts more accessible by abstracting the complexity of Helm-based deployments.</p> <p>By encapsulating Helm charts within standardized Packages and managing them via declarative Releases,  KuboCD allows a broader audience (including less Helm-savvy users) to safely and efficiently deploy applications to Kubernetes.</p>"},{"location":"#feature-comparison-kubocd-vs-helm-vs-fluxcd","title":"Feature Comparison: KuboCD vs Helm vs FluxCD","text":"Feature / Tool KuboCD Helm FluxCD Primary Role Application packaging &amp; deployment abstraction Templating and deploying Kubernetes manifests GitOps continuous delivery User Audience Platform Engineers, AppOps, Developers DevOps, Kubernetes Experts DevOps, SREs Ease of Use High (abstracts deployment logic) Medium (requires Helm knowledge) Medium (requires GitOps understanding) Supports GitOps \u2705 (via integration with FluxCD) \u26a0\ufe0f (manual integration needed) \u2705 (native GitOps controller) Uses Helm charts \u2705 (packages &amp; manages them) \u2705 (core functionality) \u2705 (can deploy HelmReleases) Custom Resources Release, Context None (CLI and chart format) HelmRelease, Kustomization, etc. Deployment Abstraction \u2705 (encapsulates values, logic) \u274c (user-defined values needed at deploy) \u274c (relies on raw manifests or Helm) OCI Image Support \u2705 (Packages are OCI images) \u2705 (since Helm v3.8+) \u2705 (via Helm OCI support) Ideal Use Case Standardizing deployments across teams Managing complex app deployments manually Automating deployments from Git"},{"location":"getting-started/","title":"Getting started","text":""},{"location":"getting-started/#how-this-manual-is-structured","title":"How This Manual Is Structured","text":"<p>The User Guide is organized as a step-by-step tutorial, designed to gradually introduce the various features of KuboCD.</p> <p>It is complemented by a 'Reference' section.</p> <p>As a starting point, we recommend installing KuboCD:</p> <ul> <li>If you have a test cluster available: Installing KuboCD on an Existing Cluster.</li> <li>If you prefer to test locally on your workstation: Installing KuboCD on a Local Kind Cluster</li> </ul> <p>Then continue with A First Deployment.</p>"},{"location":"tips-and-tricks/","title":"Tips and Tricks","text":""},{"location":"tips-and-tricks/#create-a-private-certificate-authority","title":"Create a private Certificate authority","text":""},{"location":"tips-and-tricks/#use-dnsmasq","title":"Use dnsmasq","text":""},{"location":"tips-and-tricks/#use-docker-mac-net-connect-and-metallb","title":"Use docker mac net connect and metallb","text":"<p>https://github.com/chipmk/docker-mac-net-connect https://medium.com/@tylerauerbeck/making-your-docker-network-reachable-in-osx-e68f998f8249</p>"},{"location":"user-guide/110-kind/","title":"Installing KuboCD on a Local Kind Cluster","text":"<p>This section walks you through setting up a local Kubernetes cluster using Docker and Kind, then installing FluxCD and KuboCD on top of it.</p> <p>Tip</p> <p>Already have a Kubernetes cluster? You can skip the cluster creation and follow the instructions in Installation on an existing cluster.</p>"},{"location":"user-guide/110-kind/#prerequisites","title":"Prerequisites","text":"<p>Ensure the following tools are installed on your workstation:</p> <ul> <li>Docker.</li> <li>kubectl.</li> <li>Helm.</li> <li>Kind.</li> <li>Flux CLI.</li> </ul> <p>Make sure:</p> <ul> <li>Docker is running</li> <li>You have an active internet connection</li> <li>Ports 80 and 443 are available on your local machine</li> </ul> <p>You also need an access to an OCI-compatible container registry with permissions to push images. This is will be necessary for uploading and storing KuboCD Packages as OCI artifacts.</p>"},{"location":"user-guide/110-kind/#create-the-kind-cluster","title":"Create the Kind Cluster","text":"<p>Create a configuration file with ingress-compatible port mappings:</p> <pre><code>cat &gt;/tmp/kubodoc-config.yaml &lt;&lt;EOF\nkind: Cluster\napiVersion: kind.x-k8s.io/v1alpha4\nname: kubodoc\nnodes:\n- role: control-plane\n  extraPortMappings:\n  - containerPort: 30080\n    hostPort: 80\n    protocol: TCP\n  - containerPort: 30443\n    hostPort: 443\n    protocol: TCP\nEOF\n</code></pre> <p>Note</p> <p>The <code>extraPortMappings</code> allow direct access to services like the ingress controller from your local machine.</p> <p>Then create the cluster:</p> <pre><code>kind create cluster --config /tmp/kubodoc-config.yaml\n</code></pre> <p>This will create a single-node cluster acting as both control plane and worker node.</p> <p>Example output:</p> <pre><code>Creating cluster \"kubodoc\" ...\n \u2713 Ensuring node image (kindest/node:v1.32.2)\n \u2713 Preparing nodes\n \u2713 Writing configuration\n \u2713 Starting control-plane\n \u2713 Installing CNI\n \u2713 Installing StorageClass\nSet kubectl context to \"kind-kubodoc\"\nYou can now use your cluster with:\n\nkubectl cluster-info --context kind-kubodoc\n</code></pre> <p>Verify everything is running:</p> <pre><code>kubectl get pods -A\n\nNAMESPACE            NAME                                            READY   STATUS    RESTARTS   AGE\nkube-system          coredns-668d6bf9bc-nwzqj                        1/1     Running   0          52s\nkube-system          coredns-668d6bf9bc-xgv9f                        1/1     Running   0          52s\nkube-system          etcd-kubodoc-control-plane                      1/1     Running   0          59s\nkube-system          kindnet-xwfp8                                   1/1     Running   0          52s\nkube-system          kube-apiserver-kubodoc-control-plane            1/1     Running   0          59s\nkube-system          kube-controller-manager-kubodoc-control-plane   1/1     Running   0          58s\nkube-system          kube-proxy-6hv6w                                1/1     Running   0          52s\nkube-system          kube-scheduler-kubodoc-control-plane            1/1     Running   0          59s\nlocal-path-storage   local-path-provisioner-7dc846544d-k8bhb         1/1     Running   0          52s\n</code></pre>"},{"location":"user-guide/110-kind/#install-flux","title":"Install Flux","text":""},{"location":"user-guide/110-kind/#install-the-flux-cli","title":"Install the Flux CLI","text":"<p>If not already installed, follow the Flux CLI installation guide..</p>"},{"location":"user-guide/110-kind/#deploy-flux-basic-mode","title":"Deploy Flux (Basic Mode)","text":"<p>We\u2019ll begin with a basic installation of Flux (no Git repository linked for now):</p> <p>Note</p> <p>A full GitOps deployment will be described later in this documentation.</p> <pre><code>flux install\n</code></pre> <pre><code>\u271a generating manifests\n\u2714 manifests build completed\n\u25ba installing components in flux-system namespace\n...\n\u2714 notification-controller: deployment ready\n\u2714 source-controller: deployment ready\n\u2714 install finished\n</code></pre> <p>Verify deployment:</p> <pre><code>kubectl -n flux-system get pods\n</code></pre> <pre><code>NAME                                       READY   STATUS    RESTARTS   AGE\nhelm-controller-b6767d66-q27gd             1/1     Running   0          14m\nkustomize-controller-5b56686fbc-hpkhl      1/1     Running   0          14m\nnotification-controller-58ffd586f7-bbvwv   1/1     Running   0          14m\nsource-controller-6ff87cb475-hnmxv         1/1     Running   0          14m\n</code></pre> <p>Tip</p> <p>\ud83d\udca1 Want a minimal install? You can limit Flux to the required components for KuboCD: <code>flux install --components source-controller,helm-controller</code></p>"},{"location":"user-guide/110-kind/#install-kubocd","title":"Install KuboCD","text":"<p>Deploy KuboCD using Helm:</p> <pre><code>helm -n kubocd install kubocd-ctrl --create-namespace oci://quay.io/kubocd/charts/kubocd-ctrl:v0.2.0\n</code></pre>"},{"location":"user-guide/110-kind/#install-the-kubocd-cli","title":"Install the KuboCD CLI","text":"<p>Download the KuboCD CLI from the GitHub releases page.. and rename it to <code>kubocd</code>. Then make it executable and move it to your path:</p> <pre><code>mv kubocd_*_* kubocd\nchmod +x kubocd\nsudo mv kubocd /usr/local/bin/\n</code></pre> <p>Verify the installation:</p> <pre><code>kubocd version\n</code></pre> <p>You can now move to your first deployment with KuboCD</p>"},{"location":"user-guide/120-existing-cluster/","title":"Installing KuboCD on an existing cluster.","text":"<p>If you have an existing cluster, you can use it to test KuboCD</p> <p>Tip</p> <p>If you don't have one, you can use a Kind cluster on your local workstation</p>"},{"location":"user-guide/120-existing-cluster/#prerequisites","title":"Prerequisites","text":"<p>Ensure the following tools are installed on your workstation:</p> <ul> <li>Docker.</li> <li>kubectl.</li> <li>Helm.</li> <li>Flux CLI.</li> </ul> <p>Make sure:</p> <ul> <li>Docker is running</li> <li>You have an active internet connection</li> <li>You have full admin rights on the target cluster.</li> </ul> <p>You also need an access to an OCI-compatible container registry with permissions to push images. This is will be necessary for uploading and storing KuboCD Packages as OCI artifacts.</p>"},{"location":"user-guide/120-existing-cluster/#install-flux","title":"Install Flux","text":""},{"location":"user-guide/120-existing-cluster/#install-the-flux-cli","title":"Install the Flux CLI","text":"<p>If not already installed, follow the Flux CLI installation guide..</p>"},{"location":"user-guide/120-existing-cluster/#deploy-flux-basic-mode","title":"Deploy Flux (Basic Mode)","text":"<p>If Flux is not already installed on your cluster, we\u2019ll begin with a basic installation (no Git repository linked for now):</p> <pre><code>flux install\n</code></pre> <pre><code>\u271a generating manifests\n\u2714 manifests build completed\n\u25ba installing components in flux-system namespace\n...\n\u2714 notification-controller: deployment ready\n\u2714 source-controller: deployment ready\n\u2714 install finished\n</code></pre> <p>Verify deployment:</p> <pre><code>kubectl -n flux-system get pods\n</code></pre> <pre><code>NAME                                       READY   STATUS    RESTARTS   AGE\nhelm-controller-b6767d66-q27gd             1/1     Running   0          14m\nkustomize-controller-5b56686fbc-hpkhl      1/1     Running   0          14m\nnotification-controller-58ffd586f7-bbvwv   1/1     Running   0          14m\nsource-controller-6ff87cb475-hnmxv         1/1     Running   0          14m\n</code></pre> <p>Tip</p> <p>\ud83d\udca1 Want a minimal install? You can limit Flux to the required components for KuboCD: <code>flux install --components source-controller,helm-controller</code></p>"},{"location":"user-guide/120-existing-cluster/#install-kubocd","title":"Install KuboCD","text":"<p>Deploy the KuboCD controller using Helm:</p> <pre><code>helm -n kubocd install kubocd-ctrl --create-namespace oci://quay.io/kubocd/charts/kubocd-ctrl:v0.2.0\n</code></pre>"},{"location":"user-guide/120-existing-cluster/#enabling-webhook-based-features","title":"Enabling Webhook-Based Features","text":"<p>Some advanced features in KuboCD such as Release protection rely on a Kubernetes validating webhook.</p> <p>To enable these features, you need to deploy a webhook component alongside the controller. This webhook requires  cert-manager. to be installed in your cluster to handle TLS certificate provisioning.</p> <p>If you already have <code>cert-manager</code> installed, you can deploy the webhook with the following command:</p> <pre><code>helm -n kubocd install kubocd-wh oci://quay.io/kubocd/charts/kubocd-wh:v0.2.0\n</code></pre> <p>Note</p> <p>Don\u2019t have <code>cert-manager</code> yet? No problem ! We\u2019ll show you how to package and install it with KuboCD in a later section.</p>"},{"location":"user-guide/120-existing-cluster/#install-the-kubocd-cli","title":"Install the KuboCD CLI","text":"<p>Download the KuboCD CLI from the GitHub releases page.. and rename it to <code>kubocd</code>. Then make it executable and move it to your path:</p> <pre><code>mv kubocd_*_* kubocd\nchmod +x kubocd\nsudo mv kubocd /usr/local/bin/\n</code></pre> <p>Verify the installation:</p> <pre><code>kubocd version\n</code></pre> <p>You can now move to your first deployment with KuboCD</p>"},{"location":"user-guide/130-a-first-deployment/","title":"A First Deployment with KuboCD","text":""},{"location":"user-guide/130-a-first-deployment/#package-definition","title":"Package Definition","text":"<p>For this initial deployment, we\u2019ll use a simple and illustrative example: a tiny web application called podinfo.</p> <p>A Package in KuboCD is defined using a YAML manifest. Below is an example that wraps the <code>podinfo</code> application:</p> podinfo-p01.yaml <pre><code>apiVersion: v1alpha1\ntype: Package\nname: podinfo\ntag: 6.7.1-p01\nschema:\n  parameters:\n    $schema: http://json-schema.org/schema#\n    additionalProperties: false\n    properties:\n      fqdn:\n        type: string\n      ingressClassName:\n        default: nginx\n        type: string\n    required:\n      - fqdn\n    type: object\nmodules:\n  - name: main\n    specPatch:\n      timeout: 2m\n    source:\n      helmRepository:\n        url: https://stefanprodan.github.io/podinfo\n        chart: podinfo\n        version: 6.7.1\n    values: |\n      ingress:\n        enabled: true\n        className: {{ .Parameters.ingressClassName }}\n        hosts:\n          - host: {{ .Parameters.fqdn }}\n            paths:\n              - path: /\n                pathType: ImplementationSpecific\n</code></pre> <p>A KuboCD Package is NOT a native Kubernetes resource.</p> <p>Tips</p> <p>You will find most on the samples used in this documentation at the following location</p> <p>Description of the sample Package attributes:</p> <ul> <li><code>apiVersion</code> (Required): Defines the version of the KuboCD Package format. The only supported value currently is <code>v1alpha1</code>.</li> <li><code>type</code>: Specifies the resource type. It must be <code>Package</code>, which is also the default and can be omitted.</li> <li><code>name</code>: The name of the package. This will be used as the OCI image name.</li> <li><code>tag</code> (Required): Specifies the version tag of the OCI image. While technically flexible, we will use the following convention:<ul> <li>Use the Helm chart version of the main module as a base, followed by <code>-pXX</code> where <code>XX</code> denotes the packaging revision (e.g. different configurations for the same chart).</li> </ul> </li> <li><code>schema.parameters</code>: Defines input parameters for the package, using a standard OpenAPI/JSON Schema. This enables validation and documentation of parameters at deployment time.<ul> <li>If not defined, the release will not accept parameters.</li> </ul> </li> <li><code>modules</code> (Required): A package contains one or more Helm charts, each represented as a module.<ul> <li><code>modules[X].name</code> (Required): A unique name for the module. In this example, there's only one module, called <code>main</code>.</li> <li><code>modules[X].source</code> (Required): Defines where to find the Helm chart. In this example, it's in a Helm repository, but it could also come from an OCI registry, Git repository, or local chart.</li> <li><code>values</code>: This is a template rendered into a <code>values.yaml</code> for Helm. <ul> <li>The templating engine is the same as Helm\u2019s.</li> <li>The data model, however, differs. It includes a <code>.Parameters</code> object containing the values provided during deployment (via the <code>Release</code> object).</li> <li>Though it appears as YAML, it is actually a string, allowing full templating flexibility.</li> </ul> </li> </ul> </li> </ul> <p>Required Fields</p> <p>Any attribute marked with (Required) must be specified for the package to be valid.</p> <p>Tip</p> <p>More attributes and advanced features will be introduced later in the documentation.</p>"},{"location":"user-guide/130-a-first-deployment/#package-build","title":"Package Build","text":"<p>Now that the package definition is complete, it\u2019s time to generate the corresponding OCI image.</p> <p>As mentioned earlier, KuboCD uses an OCI-compatible container registry to store and distribute packages. You'll need access to one with permission to push images.</p> <p>Tested registry</p> <ul> <li><code>quay.io</code> (Red Hat)</li> <li><code>ghcr.io</code> (GitHub)</li> <li>distribution registry</li> </ul> <p>Others should works. Except <code>Docker Hub</code> which is not supported at the moment.</p> <p>Make sure you're authenticated with the registry, e.g.:</p> <pre><code>docker login quay.io\n</code></pre> <p>Depending on the registry, the image may need to be pushed under an organization or namespace. For this example, we'll use <code>quay.io/kubodoc</code>.</p> <p>To build and push the package image:</p> <pre><code>kubocd package podinfo-p01.yaml --ociRepoPrefix quay.io/kubodoc/packages\n</code></pre> <p>Note</p> <p>Adjust <code>--ociRepoPrefix</code> to your own registry setup.The <code>packages</code> suffix is arbitrary. You can use any subpath or omit it.</p> <p>The resulting repository and tag are determined from the package manifest:</p> <ul> <li>Repository = <code>--ociRepoPrefix</code> + package <code>name</code></li> <li>Tag = package <code>tag</code></li> </ul> <p>Expected Output:</p> <pre><code>====================================== Packaging package 'podinfo-p01.yaml'\n--- Handling module 'main':\nFetching chart podinfo:6.7.1...\nChart: podinfo:6.7.1\n--- Packaging\nGenerating index file\nWrap all in assembly.tgz\n--- push OCI image: quay.io/kubodoc/packages/podinfo:6.7.1-p01\nSuccessfully pushed\n</code></pre> <p>You can also set the repository prefix globally via an environment variable:</p> <pre><code>export OCI_REPO_PREFIX=quay.io/kubodoc/packages\n</code></pre> <p>Or for other registries:</p> <pre><code>export OCI_REPO_PREFIX=ghcr.io/kubodoc/packages\n\nexport OCI_REPO_PREFIX=localhost:5000/packages\n</code></pre> <p>Warning</p> <p>By default, pushed images may be private. To make them accessible for deployment, ensure the image is set to public.  If you prefer to keep the image private, you will need to provide authentication credentials in the <code>Release</code> configuration. This will be explained later in the documentation.</p>"},{"location":"user-guide/130-a-first-deployment/#releasing-the-application","title":"Releasing the Application","text":"<p>To deploy the application, define a KuboCD <code>Release</code> custom resource:</p> podinfo1-basic.yaml <pre><code>---\napiVersion: kubocd.kubotal.io/v1alpha1\nkind: Release\nmetadata:\n  name: podinfo1\n  namespace: default\nspec:\n  description: A first sample release of podinfo\n  package:\n    repository: quay.io/kubodoc/packages/podinfo\n    tag: 6.7.1-p01\n    interval: 30m\n  parameters:\n    fqdn: podinfo1.ingress.kubodoc.local\n</code></pre> <p>Explanation of attributes:</p> <ul> <li><code>description</code>: (Optional) A short description of this release.</li> <li><code>package.repository</code>: The OCI image repository that contains the package. This should match the registry used during package build.</li> <li><code>package.tag</code>: The image tag, which should match the one defined in the package manifest.</li> <li><code>package.interval</code>: Specifies how frequently KuboCD checks the registry for updates to the image.</li> <li><code>parameters</code>: The values required by the package schema. In this example, only a single parameter (<code>fqdn</code>) is needed.</li> </ul> <p>Deploying the Application:</p> <ol> <li>Adjust the repository and parameters (if needed) to match your environment.</li> <li>Apply the Release:</li> </ol> <pre><code>kubectl apply -f podinfo1-basic.yaml\n</code></pre> <p>Once deployed, monitor the status:</p> <pre><code>kubectl get releases\n</code></pre> <pre><code>NAME       REPOSITORY                         TAG         CONTEXTS   STATUS   READY   WAIT   PRT   AGE     DESCRIPTION\npodinfo1   quay.io/kubodoc/packages/podinfo   6.7.1-p01              READY    1/1            -     6m40s   A first sample release of podinfo\n</code></pre> <p>You can also verify the pod:</p> <pre><code>kubectl get pods\n</code></pre> <pre><code>NAME                             READY   STATUS    RESTARTS   AGE\npodinfo1-main-779b6b9fd4-zbgbx   1/1     Running   0          8h\n</code></pre>"},{"location":"user-guide/140-under-the-hood/","title":"Under the Hood (If Things Go Wrong)","text":"<p>Behind the scenes, KuboCD creates several FluxCD resources to manage the deployment.</p> <p>You can inspect these resources to debug problems or understand the internals.</p> <p>Check the events bound to the <code>Release</code> which was previously created:</p> <pre><code>kubectl describe release podinfo1\n</code></pre> <pre><code>......\nEvents:\nType    Reason                 Age   From     Message\n----    ------                 ----  ----     -------\nNormal  OCIRepositoryCreated   12s   release  Created OCIRepository \"kcd-podinfo1\"\nNormal  HelmRepositoryCreated  10s   release  Created HelmRepository \"kcd-podinfo1\"\nNormal  HelmReleaseCreated     8s    release  Created HelmRelease \"podinfo1-main\"\n</code></pre> <p>All of these resources are created in the same namespace as the <code>Release</code> object (e.g. <code>default</code>).</p>"},{"location":"user-guide/140-under-the-hood/#the-ocirepository","title":"The OCIRepository","text":"<p>This Flux resource pulls the KuboCD package image:</p> <pre><code>kubectl get OCIRepository\n</code></pre> <pre><code>NAME           URL                                      READY   STATUS                                                                                                           AGE\nkcd-podinfo1   oci://quay.io/kubodoc/packages/podinfo   True    stored artifact for digest '6.7.1-p01@sha256:985e4e2f89a4b17bd5cc2936a0b305df914ae479e0b8c96e61cb22725b61cd24'   9m1s\n</code></pre> <p>Tip</p> <p>If the release is stuck in the <code>WAIT_OCI</code> state, check this resource and its events. Common issues include:</p> <ul> <li>Incorrect URL</li> <li>Image still private (set to public or provide authentication)</li> </ul> <p>You can manually delete this resource to trigger a refresh:</p> <pre><code>kubectl delete ocirepository kcd-podinfo1\n</code></pre> <p>KuboCD will recreate it.</p> <p>This can be useful to force a reload of a modified OCI image, without waiting for the sync period.</p>"},{"location":"user-guide/140-under-the-hood/#the-helmrepository","title":"The HelmRepository","text":"<p>As the <code>podinfo</code> Helm the chart is embedded in the package, it must be served to Flux via an internal Helm repository.</p> <p>KuboCD creates a <code>HelmRepository</code> resource pointing to its internal server:</p> <pre><code>kubectl get HelmRepository\n</code></pre> <pre><code>NAME           URL                                                                            AGE    READY   STATUS\nkcd-podinfo1   http://kubocd-ctrl-controller-helm-repository.kubocd.svc/hr/default/podinfo1   105m   True    stored artifact: revision 'sha256:d8db03cf45ecd75064c2a2582812dc4df5cd624d0e295b24ff79569bf46a070b'\n</code></pre> <p>This step rarely causes errors unless the internal controller is unreachable.</p>"},{"location":"user-guide/140-under-the-hood/#the-helmrelease","title":"The HelmRelease","text":"<p>This Flux resource handles the actual Helm chart deployment.</p> <pre><code>kubectl get HelmRelease\n</code></pre> <pre><code>NAME            AGE     READY   STATUS\npodinfo1-main   7m59s   True    Helm install succeeded for release default/podinfo1-main.v1 with chart podinfo@6.7.1\n</code></pre> <p>Note</p> <p>There will be one HelmRelease per module in the package.</p> <p>If the release is stuck in <code>WAIT_HREL</code>, inspect this resource:</p> <pre><code>kubectl describe helmrelease podinfo1-main\n</code></pre> <pre><code>.....\nEvents:\n  Type    Reason            Age    From             Message\n  ----    ------            ----   ----             -------\n  Normal  HelmChartCreated  5m42s  helm-controller  Created HelmChart/default/default-podinfo1-main with SourceRef 'HelmRepository/default/kcd-podinfo1'\n  Normal  InstallSucceeded  5m39s  helm-controller  Helm install succeeded for release default/podinfo1-main.v1 with chart podinfo@6.7.1\n</code></pre> <p>One of the point to check if the generated <code>values</code> for the Helm chart deployment.</p> <p>Note</p> <p>You will need to unstall the yq command.</p> <pre><code>kubectl get HelmRelease podinfo1-main -o yaml | yq '.spec.values'\n</code></pre> <pre><code>ingress:\n  className: nginx\n  enabled: true\n  hosts:\n    - host: podinfo1.ingress.kubodoc.local\n      paths:\n        - path: /\n          pathType: ImplementationSpecific\n</code></pre> <p>Note</p> <p>If deployment fails, you may need to wait for the Helm timeout to expire (default: 2 minutes) to have failure reason.  You can configure this value in the <code>Package</code> or in the <code>Release</code>.</p>"},{"location":"user-guide/150-ingress-controller/","title":"Setting Up the Ingress Controller","text":"<p>Warning</p> <p>If you're using an existing cluster, there's likely already an ingress controller installed. Do not install another one. However, you should still read this section as several new features are described.</p> <p>If you're following the local <code>kind</code> cluster setup, you\u2019ll need to install an ingress controller to make use of the deployed <code>Ingress</code> object.</p> <p>Check the current <code>Ingress</code> object created by the <code>podinfo</code> deployment:</p> <pre><code>kubectl get ingresses\n\nNAME            CLASS   HOSTS                            ADDRESS   PORTS   AGE\npodinfo1-main   nginx   podinfo1.ingress.kubodoc.local             80      6m33s\n</code></pre> <p>At this point, the ingress is inactive since no ingress controller is installed.</p>"},{"location":"user-guide/150-ingress-controller/#build-the-ingress-nginx-package","title":"Build the ingress-nginx package:","text":"<p>Here is a sample package definition for deploying the <code>ingress-nginx</code> controller:</p> <p>Warning</p> <p>This first version is dedicated to the way we setup the cluster, using the kind portMapping and NodePorts</p> ingress-nginx-p01.yaml <pre><code>apiVersion: v1alpha1\nname: ingress-nginx\ntag: 4.12.1-p01\nprotected: true\nmodules:\n  - name: main\n    specPatch:\n      timeout: 4m\n    source:\n      helmRepository:\n        url: https://kubernetes.github.io/ingress-nginx\n        chart: ingress-nginx\n        version: 4.12.1\n    values:\n      controller:\n        extraArgs:\n          enable-ssl-passthrough: true\n        service:\n          type: NodePort\n          nodePorts:\n            http: \"30080\"\n            https: \"30443\"\nroles:\n  - ingress\n</code></pre> <p>New key points compared to the <code>podinfo</code> Package:</p> <ul> <li><code>protected: true</code>: Prevents accidental deletion of the release. (Currently not enforced unless KuboCD webhook is installed.)</li> <li><code>timeout: 4m</code>: Overrides the default deployment timeout (<code>2m</code>) because this Helm chart may take some time to deploy.</li> <li><code>values</code>: This section is in proper YAML format (no '|': not a templated string), since it does not include any templating.</li> <li><code>roles</code>: Assigns the package to the <code>ingress</code> role. This is used for dependency management between releases.</li> </ul> <p>Build the package:</p> <pre><code>kubocd pack ingress-nginx-p01.yaml\n</code></pre> <pre><code>====================================== Packaging package 'ingress-nginx.yaml'\n--- Handling module 'main':\nFetching chart ingress-nginx:4.12.1...\nChart: ingress-nginx:4.12.1\n--- Packaging\nGenerating index file\nWrap all in assembly.tgz\n--- push OCI image: quay.io/kubodoc/packages/ingress-nginx:4.12.1-p01\nSuccessfully pushed\n</code></pre>"},{"location":"user-guide/150-ingress-controller/#deploy-the-package","title":"Deploy the package","text":"<p>Then define the <code>Release</code> resource:</p> ingress-nginx.yaml <pre><code>---\napiVersion: kubocd.kubotal.io/v1alpha1\nkind: Release\nmetadata:\n  name: ingress-nginx\n  namespace: kubocd\nspec:\n  description: The Ingress controller\n  protected: false\n  package:\n    repository: quay.io/kubodoc/packages/ingress-nginx\n    tag: 4.12.1-p01\n    interval: 30m\n  targetNamespace: ingress-nginx\n  createNamespace: true\n</code></pre> <p>Key points:</p> <ul> <li><code>metadata.namespace: kubocd</code>: As it is a system components, deploy in a restricted namespace.</li> <li><code>spec.protected: false</code>: Just to demonstrates that the package-level <code>protected</code> flag can be overridden at the release level.</li> <li><code>spec.targetNamespace: ingress-nginx</code>: Installs the ingress controller in its own namespace.</li> <li><code>spec.createNamespace: true</code>: Automatically creates the target namespace if it doesn't exist.</li> </ul> <p>Apply the release:</p> <pre><code>kubectl apply -f ingress-nginx.yaml\n</code></pre> <p>Check the release status:</p> <pre><code>kubectl -n kubocd get release\n</code></pre> <pre><code>NAME            REPOSITORY                               TAG          CONTEXTS   STATUS   READY   WAIT   PRT   AGE   DESCRIPTION\ningress-nginx   quay.io/kubodoc/packages/ingress-nginx   4.12.1-p01              READY    1/1            -     86s   The Ingress controller\n</code></pre>"},{"location":"user-guide/150-ingress-controller/#configure-the-dns-entry","title":"Configure the DNS entry","text":"<p>To access the <code>podinfo</code> application, you'll need to define a DNS entry matching the <code>fqdn</code> parameter.</p> <p>The simplest way in our case is to use the <code>/etc/hosts</code> file:</p> <pre><code>127.0.0.1 localhost podinfo1.ingress.kubodoc.local\n</code></pre> <p>Make sure the hostname matches exactly what was provided in the Release parameters.</p> <p>You should now be able to access the 'podinfo` web server:</p> <p>\ud83d\udc49 http://podinfo1.ingress.kubodoc.local</p>"},{"location":"user-guide/160-the-context/","title":"The Context","text":"<p>One of the key features of KuboCD is its ability to generate Helm deployment values files from a small set of high-level input parameters, using a templating mechanism.</p> <p>This mechanism combines a template with a data model.</p> <p>Our first example uses only the <code>.Parameters</code> element of the data model:</p> podinfo-p01.yaml <pre><code>apiVersion: v1alpha1\ntype: Package\nname: podinfo\n...\nmodules:\n  - name: main\n    ...\n    values: |\n      ingress:\n        enabled: true\n        className: {{ .Parameters.ingressClassName }}\n        hosts:\n          - host: {{ .Parameters.fqdn }}\n            paths:\n              - path: /\n                pathType: ImplementationSpecific\n</code></pre> <p>In fact, the data model includes the following top-level elements:</p> <ul> <li><code>.Parameters</code>: The parameters provided in the <code>Release</code> custom resource.</li> <li><code>.Release</code>: The release object itself.</li> <li><code>.Context</code>: The deployment context.</li> </ul> <p>The context is a YAML object with a flexible structure, designed to hold shared configuration data relevant to all deployments.</p> <p>For example, the <code>podinfo</code> package includes a parameter <code>ingressClassName</code> with a default value (<code>nginx</code>). If a cluster uses a different ingress controller, this value would need to be overridden for all relevant <code>Release</code> objects.</p> <p>This type of shared configuration is best defined in a global cluster-level context.</p> <p>Similarly, if all application ingress URLs share a common root domain, that too should be centralized.</p> <p>Here's an initial example of how this logic can be implemented.</p>"},{"location":"user-guide/160-the-context/#context-creation","title":"Context Creation","text":"<p>A <code>Context</code> is a KuboCD resource:</p> cluster.yaml <pre><code>apiVersion: kubocd.kubotal.io/v1alpha1\nkind: Context\nmetadata:\n  namespace: contexts\n  name: cluster\nspec:\n  description: Global context for the kubodoc cluster\n  protected: true\n  context:\n    ingress:\n      className: nginx\n      domain: ingress.kubodoc.local\n    storageClass: \n      data: standard\n      workspace: standard\n</code></pre> <p>Key attributes:</p> <ul> <li><code>description</code>: A short description.</li> <li><code>protected</code>: Prevents deletion of this object. Requires KuboCD's webhook feature.</li> <li><code>context</code>: A tree of values that is injected into the data model for the templating of the <code>values</code> section. This section:<ul> <li>Must be valid YAML.</li> <li>Has a flexible structure, but should align with what the package templates expect.</li> </ul> </li> </ul> <p>In this example, the context includes:</p> <ul> <li><code>ingress.className</code>: The ingress controller type.</li> <li><code>ingress.domain</code>: The suffix used for building ingress URLs.</li> <li><code>storageClass</code>: Two Kubernetes <code>StorageClass</code> definitions for different application profiles. For our <code>kind</code> based cluster, there is only one available option: <code>standard</code>.</li> </ul> <p>Contexts should be placed in a dedicated namespace:</p> <pre><code>kubectl create ns contexts\n</code></pre> <pre><code>kubectl apply -f cluster.yaml\n</code></pre> <p>Note</p> <p>Since the context is shared among most of all applications, its structure must be carefully designed and well documented.</p>"},{"location":"user-guide/160-the-context/#package-modification","title":"Package modification","text":"<p>Our initial <code>podinfo</code> package did not account for the context concept. Here is an updated version:</p> podinfo-p02.yaml <pre><code>apiVersion: v1alpha1\ntype: Package\nname: podinfo\ntag: 6.7.1-p02\nschema:\n  parameters:\n    $schema: http://json-schema.org/schema#\n    type: object\n    additionalProperties: false\n    properties:\n      host: { type: string }\n    required:\n      - host\n  context:\n    $schema: http://json-schema.org/schema#\n    additionalProperties: true\n    type: object\n    properties:\n      ingress:\n        type: object\n        additionalProperties: true\n        properties:\n          className: { type: string }\n          domain: { type: string }\n        required:\n          - domain\n          - className\n    required:\n      - ingress\nmodules:\n  - name: main\n    specPatch:\n      timeout: 2m\n    source:\n      helmRepository:\n        url: https://stefanprodan.github.io/podinfo\n        chart: podinfo\n        version: 6.7.1\n    values: |\n      ingress:\n        enabled: true\n        className: {{ .Context.ingress.className  }}\n        hosts:\n          - host: {{ .Parameters.host }}.{{ .Context.ingress.domain }}\n            paths:\n              - path: /\n                pathType: ImplementationSpecific\n</code></pre> <p>Key points:</p> <ul> <li>The <code>tag</code> was updated to generate a new version.</li> <li>The <code>fqdn</code> parameter was replaced with <code>host</code> to represent only the hostname (excluding the domain).</li> <li>The <code>modules[X].values</code> section now uses the context.</li> <li>A <code>schema.context</code> section has been added to define and validate the expected context structure.</li> </ul> <p>This new version must be packaged:</p> <pre><code>kubocd pack podinfo-p02.yaml\n</code></pre> <pre><code>====================================== Packaging package 'podinfo-p02.yaml'\n--- Handling module 'main':\n    Fetching chart podinfo:6.7.1...\n    Chart: podinfo:6.7.1\n--- Packaging\n    Generating index file\n    Wrap all in assembly.tgz\n--- push OCI image: quay.io/kubodoc/packages/podinfo:6.7.1-p02\n    Successfully pushed\n</code></pre>"},{"location":"user-guide/160-the-context/#deployment","title":"Deployment","text":"<p>Here is the corresponding <code>Release</code> manifest:</p> podinfo2-ctx.yaml <pre><code>---\napiVersion: kubocd.kubotal.io/v1alpha1\nkind: Release\nmetadata:\n  name: podinfo2\n  namespace: default\nspec:\n  description: A first sample release of podinfo\n  package:\n    repository: quay.io/kubodoc/packages/podinfo\n    tag: 6.7.1-p02\n    interval: 30m\n  parameters:\n    host: podinfo2\n  contexts:\n    - namespace: contexts\n      name: cluster\n</code></pre> <p>Key points:</p> <ul> <li>The <code>fqdn</code> parameter was replaced with <code>host</code>.</li> <li>A new <code>spec.contexts</code> section lists the contexts to merge into a single object passed to the template engine.</li> </ul> <p>Warning</p> <p>Referencing a non-existent context results in an error.</p> <p>Once <code>spec.repository</code> is set according to your repository, apply the deployment:</p> <pre><code>kubectl apply -f podinfo2-ctx.yaml\n</code></pre> <p>Check that the new <code>Release</code> reaches the <code>READY</code> state:</p> <pre><code>kubectl get releases podinfo2\n\nNAME       REPOSITORY                         TAG         CONTEXTS           STATUS   READY   WAIT   PRT   AGE   DESCRIPTION\npodinfo2   quay.io/kubodoc/packages/podinfo   6.7.1-p02   contexts:cluster   READY    1/1            -     17m   A first sample release of podinfo\n</code></pre>"},{"location":"user-guide/160-the-context/#context-aggregation","title":"Context Aggregation","text":"<p>An application's effective context may result from the aggregation of multiple context objects.</p> <p>For instance, a project-level context can be created to share variables across all applications within a project. This will be merged with the global cluster context.</p> <p>In the following examples, each deployed project has its own namespace and context.</p>"},{"location":"user-guide/160-the-context/#example-1-context-addition","title":"Example 1: Context addition","text":"<p>Create the namespace:</p> <pre><code>kubectl apply namespace project01\n</code></pre> <p>Then create the project context:</p> project01.yaml <pre><code>apiVersion: kubocd.kubotal.io/v1alpha1\nkind: Context\nmetadata:\n  name: project01\nspec:\n  description: Context for project 1\n  context:\n    project:\n      id: p01\n      subdomain: prj01\n</code></pre> <p>Note that the <code>namespace</code> is not specified in the manifest. It will be set via the command line:</p> <pre><code>kubectl -n project01 create -f project01.yaml\n</code></pre> <p>List all defined contexts:</p> <pre><code>kubectl get --all-namespaces contexts.kubocd.kubotal.io\n</code></pre> <pre><code>NAMESPACE   NAME        DESCRIPTION                          PARENTS   STATUS   AGE\ncontexts    cluster     Global context for the kubodoc cluster          READY    2d2h\nproject01   project01   Context for project 1                           READY    2m35s\n</code></pre> <p>This example requires modifying the package to include the new variable <code>project.subdomain</code> in the <code>values</code> template and in the <code>schema.context</code> section:</p> podinfo-p03.yaml <pre><code>apiVersion: v1alpha1\ntype: Package\nname: podinfo\ntag: 6.7.1-p03\nschema:\n  parameters:\n    $schema: http://json-schema.org/schema#\n    type: object\n    additionalProperties: false\n    properties:\n      host: { type: string }\n    required:\n      - host\n  context:\n    $schema: http://json-schema.org/schema#\n    additionalProperties: true\n    type: object\n    properties:\n      ingress:\n        type: object\n        additionalProperties: true\n        properties:\n          className: { type: string }\n          domain: { type: string }\n        required:\n          - domain\n          - className\n      project:\n        type: object\n        additionalProperties: true\n        properties:\n          subdomain: { type: string }\n        required:\n          - subdomain\n    required:\n      - ingress\n      - project\nmodules:\n  - name: main\n    specPatch:\n      timeout: 2m\n    source:\n      helmRepository:\n        url: https://stefanprodan.github.io/podinfo\n        chart: podinfo\n        version: 6.7.1\n    values: |\n      ingress:\n        enabled: true\n        className: {{ .Context.ingress.className  }}\n        hosts:\n          - host: {{ .Parameters.host }}.{{ .Context.project.subdomain }}.{{ .Context.ingress.domain }}\n            paths:\n              - path: /\n                pathType: ImplementationSpecific\n</code></pre> <p>Don't forget to package it:</p> <pre><code>kubocd pack podinfo-p03.yaml\n</code></pre> <p>Create a new <code>Release</code> for deployment:</p> podinfo-prj01.yaml <pre><code>---\napiVersion: kubocd.kubotal.io/v1alpha1\nkind: Release\nmetadata:\n  name: podinfo\nspec:\n  description: A release of podinfo on project01\n  package:\n    repository: quay.io/kubodoc/packages/podinfo\n    tag: 6.7.1-p03\n    interval: 30m\n  parameters:\n    host: podinfo\n  contexts:\n    - namespace: contexts\n      name: cluster\n    - name: project01\n  debug:\n    dumpContext: true\n    dumpParameters: true\n</code></pre> <p>Notes:</p> <ul> <li><code>metadata.namespace</code> is not defined; it will be set via command line.</li> <li><code>metadata.name</code> is simply <code>podinfo</code>, assuming only one instance per namespace.</li> <li><code>spec.contexts</code> includes now two entries, with the second referencing the project context. As the namespace is not defined, it will be set to the <code>Release</code> one.</li> <li>A <code>debug</code> section is added to include the merged context and parameters in the <code>Release</code> status.</li> </ul> <p>Deploy the release:</p> <pre><code>kubectl -n project01 create -f podinfo-prj01.yaml\n</code></pre> <p>Verify both contexts are listed:</p> <pre><code>kubectl -n project01 get releases podinfo\n\nNAME      REPOSITORY                         TAG         CONTEXTS                               STATUS   READY   WAIT   PRT   AGE     DESCRIPTION\npodinfo   quay.io/kubodoc/packages/podinfo   6.7.1-p03   contexts:cluster,project01:project01   READY    1/1            -     8m31s   A release of podinfo on project01\n</code></pre> <p>Check the resulting ingress object:</p> <pre><code>kubectl get --all-namespaces ingress\n</code></pre> <pre><code>NAMESPACE   NAME            CLASS   HOSTS                                  ADDRESS        PORTS   AGE\ndefault     podinfo1-main   nginx   podinfo1.ingress.kubodoc.local         10.96.218.98   80      2d20h\ndefault     podinfo2-main   nginx   podinfo2.ingress.kubodoc.local         10.96.218.98   80      71m\nproject01   podinfo-main    nginx   podinfo.prj01.ingress.kubodoc.local    10.96.218.98   80      13m\n</code></pre> <p>Inspect the <code>Release</code> status:</p> <pre><code>kubectl -n project01 get release podinfo -o yaml\n</code></pre> <pre><code>apiVersion: kubocd.kubotal.io/v1alpha1\nkind: Release\nmetadata:\n  ....\nspec:\n  ....\nstatus:\n  context:\n    ingress:\n      className: nginx\n      domain: ingress.kubodoc.local\n    project:\n      id: p01\n      subdomain: prj01\n    storageClass:\n      data: standard\n      workspace: standard\n  ....      \n  parameters:\n    host: podinfo2\n  ....\n</code></pre> <p>The merged context includes values from both the cluster and project contexts.</p> <p>Warning</p> <p>In real-world scenarios, the context may become quite large. Use this debug mode sparingly.</p>"},{"location":"user-guide/160-the-context/#example-2-context-override","title":"Example 2: Context override","text":"<p>In this second example, the objective remains the same (adding a subdomain to the ingress), but we use the initial version of the package, which does not handle <code>project.subdomain</code> context value.</p> <p>Create a dedicated namespace:</p> <pre><code>kubectl apply ns project02\n</code></pre> <p>Create a project context in that namespace:</p> project02.yaml <pre><code>apiVersion: kubocd.kubotal.io/v1alpha1\nkind: Context\nmetadata:\n  name: project02\nspec:\n  description: Context for project 2\n  context:\n    project:\n      id: p02\n    ingress:\n      domain: prj02.ingress.kubodoc.local\n</code></pre> <pre><code>kubectl -n project02 create -f project02.yaml\n</code></pre> <p>Note that the same <code>spec.context.ingress.domain</code> path exists in both the project and cluster contexts.  When contexts are merged in a <code>Release</code>, later contexts in the list override earlier ones. Thus, the project\u2019s value takes precedence.</p> <p>Create and deploy the <code>Release</code> object:</p> podinfo-prj02.yaml <pre><code>---\napiVersion: kubocd.kubotal.io/v1alpha1\nkind: Release\nmetadata:\n  name: podinfo\nspec:\n  description: A release of podinfo on project02\n  package:\n    repository: quay.io/kubodoc/packages/podinfo\n    tag: 6.7.1-p02\n    interval: 30m\n  parameters:\n    host: podinfo\n  contexts:\n    - namespace: contexts\n      name: cluster\n    - name: project02\n  debug:\n    dumpContext: true\n    dumpParameters: true\n</code></pre> <pre><code>kubectl -n project02 create -f podinfo-prj02.yaml\n</code></pre> <p>Check the resulting context in the <code>Release</code> object:</p> <pre><code>kubectl -n project02 get release podinfo -o yaml\n</code></pre> <pre><code>apiVersion: kubocd.kubotal.io/v1alpha1\nkind: Release\nmetadata:\n    ....\nspec:\n    ....\nstatus:\n  context:\n    ingress:\n      className: nginx\n      domain: prj02.ingress.kubodoc.local\n    project:\n      id: p02\n    storageClass:\n      data: standard\n      workspace: standard\n  ....\n</code></pre> <p>Ensure the correct ingress host is used:</p> <pre><code>kubectl get --all-namespaces ingress\n\nNAMESPACE   NAME            CLASS   HOSTS                                 ADDRESS        PORTS   AGE\ndefault     podinfo1-main   nginx   podinfo1.ingress.kubodoc.local        10.96.218.98   80      2d20h\ndefault     podinfo2-main   nginx   podinfo2.ingress.kubodoc.local        10.96.218.98   80      110m\nproject01   podinfo-main    nginx   podinfo.prj01.ingress.kubodoc.local   10.96.218.98   80      26m\nproject02   podinfo-main    nginx   podinfo.prj02.ingress.kubodoc.local   10.96.218.98   80      2m52s\n</code></pre>"},{"location":"user-guide/160-the-context/#context-change","title":"Context Change","text":"<p>Any change to a context is automatically applied to all associated <code>Release</code> objects. However, only the deployments that are actually affected will be updated.</p> <p>Notes</p> <p>Technically, KuboCD patches the corresponding Flux <code>helmRelease</code> objects, which triggers a <code>helm upgrade</code>. This should only update the resources that are truly impacted.</p> <p>For example, modify the context for <code>project01</code>:</p> <pre><code>kubectl -n project01 patch context.kubocd.kubotal.io project01 --type='json' -p='[{\"op\": \"replace\", \"path\": \"/spec/context/project/subdomain\", \"value\": \"project01\" }]'\n</code></pre> <p>Observe that the ingress is quickly updated accordingly:</p> <pre><code>kubectl get --all-namespaces ingress\n\nNAMESPACE   NAME            CLASS   HOSTS                                     ADDRESS        PORTS   AGE\ndefault     podinfo1-main   nginx   podinfo1.ingress.kubodoc.local            10.96.218.98   80      3d3h\ndefault     podinfo2-main   nginx   podinfo2.ingress.kubodoc.local            10.96.218.98   80      8h\nproject01   podinfo-main    nginx   podinfo.project01.ingress.kubodoc.local   10.96.218.98   80      7h13m\nproject02   podinfo-main    nginx   podinfo.prj02.ingress.kubodoc.local       10.96.218.98   80      6h49m\n</code></pre> <p>To restore the original value:</p> <pre><code>kubectl -n project01 patch context.kubocd.kubotal.io project01 --type='json' -p='[{\"op\": \"replace\", \"path\": \"/spec/context/project/subdomain\", \"value\": \"prj01\" }]'\n</code></pre>"},{"location":"user-guide/170-context-and-config/","title":"Context and Configuration","text":""},{"location":"user-guide/170-context-and-config/#default-context","title":"Default Context","text":"<p>Following the logic from the previous chapter, it becomes clear that the cluster\u2019s global context should be included in every <code>Release</code>.  From there, the idea of defining a default context naturally follows.</p> <p>Unlike most Kubernetes applications that store configuration in a <code>ConfigMap</code>, KuboCD uses a dedicated Custom Resource for this purpose:</p> <pre><code>kubectl -n kubocd get Config.kubocd.kubotal.io\n</code></pre> <p>Only one instance of this resource exists (it was created during deployment via the Helm chart)</p> <pre><code>NAME     AGE\nconf01   5d21h\n</code></pre> <p>Let's inspect its content:</p> <pre><code>kubectl -n kubocd get Config.kubocd.kubotal.io conf01 -o yaml\n</code></pre> <pre><code>apiVersion: kubocd.kubotal.io/v1alpha1\nkind: Config\nmetadata:\n  annotations:\n    meta.helm.sh/release-name: kubocd-ctrl\n    meta.helm.sh/release-namespace: kubocd\n  creationTimestamp: \"2025-04-16T12:29:27Z\"\n  generation: 1\n  labels:\n    app.kubernetes.io/managed-by: Helm\n  name: conf01\n  namespace: kubocd\n  resourceVersion: \"5191\"\n  uid: 84ff9a8a-83ee-48e7-984d-c95a6a665d5b\nspec:\n  clusterRoles: []\n  defaultContexts: []\n  imageRedirects: []\n  packageRedirects: []\n</code></pre> <p>At this stage, the configuration is empty</p> <p>Notes</p> <p>Using a Kubernetes resource for configuration has the following advantages:</p> <ul> <li>Structural errors result in immediate rejection without impacting the running service.</li> <li>The resource can be watched. KuboCD will therefore instantly apply any configuration changes.</li> </ul> <p>Here is a new configuration manifest:</p> conf01-b.yaml <pre><code>---\napiVersion: kubocd.kubotal.io/v1alpha1\nkind: Config\nmetadata:\n  name: conf01\n  namespace: kubocd\nspec:\n  defaultContexts:\n    - namespace: contexts\n      name: cluster\n</code></pre> <p>It defines a list of default contexts, which here includes only the cluster context created earlier.</p> <p>Apply it:</p> <pre><code>kubectl apply -f conf01-b.yaml \n</code></pre> <p>Don't worry about any warning messages</p> <p>Note</p> <p>For KuboCD to recognize the <code>Config</code> object, it must reside in the controller\u2019s namespace (<code>kubocd</code>). However, its name does not matter.</p> <p>We can now create a new <code>Release</code> of the <code>podinfo</code> application using the context-enabled version, without explicitly specifying the context:</p> podinfo3-ctx-def.yaml <pre><code>---\napiVersion: kubocd.kubotal.io/v1alpha1\nkind: Release\nmetadata:\n  name: podinfo3\n  namespace: default\nspec:\n  description: A first sample release of podinfo\n  package:\n    repository: quay.io/kubodoc/packages/podinfo\n    tag: 6.7.1-p02\n    interval: 30m\n  parameters:\n    host: podinfo3\n</code></pre> <pre><code>kubectl apply -f podinfo3-ctx-def.yaml \n</code></pre> <p>We can verify that the <code>Release</code> does pick up the context:</p> <pre><code>kubectl get release podinfo3\n</code></pre> <pre><code>NAME       REPOSITORY                         TAG         CONTEXTS           STATUS   READY   WAIT   PRT   AGE   DESCRIPTION\npodinfo3   quay.io/kubodoc/packages/podinfo   6.7.1-p02   contexts:cluster   READY    1/1            -     31m   A first sample release of podinfo\n</code></pre> <p>Which results in a correct <code>domain</code> in the ingress:</p> <pre><code>kubectl get ingress podinfo3-main\n</code></pre> <pre><code>NAME            CLASS   HOSTS                            ADDRESS        PORTS   AGE\npodinfo3-main   nginx   podinfo3.ingress.kubodoc.local   10.96.218.98   80      84s\n</code></pre>"},{"location":"user-guide/170-context-and-config/#namespaced-default-context","title":"Namespaced Default Context","text":"<p>KuboCD also supports defining a default context per namespace.</p> <p>We modify our configuration resource again:</p> conf01-c.yaml <pre><code>---\napiVersion: kubocd.kubotal.io/v1alpha1\nkind: Config\nmetadata:\n  name: conf01\n  namespace: kubocd\nspec:\n  defaultContexts:\n    - namespace: contexts\n      name: cluster\n  defaultNamespaceContext: project\n</code></pre> <pre><code>kubectl apply -f conf01-c.yaml \n</code></pre> <p>Thanks to this setup, every <code>Release</code> will attempt to load a context named <code>project</code> from its own namespace, and use it if it exists.</p> <p>A new namespace <code>project03</code> is created:</p> <pre><code>kubectl create ns project03\n</code></pre> <p>A project-specific context is created there, using the generic name <code>project</code>:</p> project03.yaml <pre><code>apiVersion: kubocd.kubotal.io/v1alpha1\nkind: Context\nmetadata:\n  name: project\nspec:\n  description: Context For projet 3\n  context:\n    project:\n      id: p03\n    ingress:\n      domain: prj03.ingress.kubodoc.local\n</code></pre> <pre><code>kubectl -n project03 apply -f project03.yaml \n</code></pre> <p>We now create a new <code>Release</code> without explicitly specifying which context to use:</p> podinfo-prj03.yaml <pre><code>---\napiVersion: kubocd.kubotal.io/v1alpha1\nkind: Release\nmetadata:\n  name: podinfo\nspec:\n  description: A release of podinfo on project03\n  package:\n    repository: quay.io/kubodoc/packages/podinfo\n    tag: 6.7.1-p02\n    interval: 30m\n  parameters:\n    host: podinfo\n  debug:\n    dumpContext: true\n    dumpParameters: true\n</code></pre> <pre><code>kubectl -n project03 apply -f podinfo-prj03.yaml\n</code></pre> <p>We can confirm both default contexts are applied:</p> <pre><code>kubectl -n project03 get release podinfo\n</code></pre> <pre><code>NAME      REPOSITORY                         TAG         CONTEXTS                             STATUS   READY   WAIT   PRT   AGE   DESCRIPTION\npodinfo   quay.io/kubodoc/packages/podinfo   6.7.1-p02   contexts:cluster,project03:project   READY    1/1            -     10m   A release of podinfo on project03\n</code></pre> <p>And verify that the ingress domain is correctly resolved:</p> <pre><code>kubectl -n project03 get ingress\n</code></pre> <pre><code>NAME           CLASS   HOSTS                                 ADDRESS        PORTS   AGE\npodinfo-main   nginx   podinfo.prj03.ingress.kubodoc.local   10.96.218.98   80      11m\n</code></pre>"},{"location":"user-guide/170-context-and-config/#context-ordering","title":"Context Ordering","text":"<p>As mentioned earlier, the order in which contexts are merged for a <code>Release</code> can be important.</p> <p>The order is:</p> <ul> <li>Global default context, in the order of the list defined in the configuration.</li> <li>Namespace default context, if it exists.</li> <li>Context defined in the <code>Release</code>object, in list order</li> </ul> <p>Last ones will take precedence.</p> <p>Warning</p> <p>Referencing a non-existent context results in an error, except for the namespace-level default context.</p> <p>If you've followed the full guide, your setup should look something like this:</p> <pre><code>kubectl get --all-namespaces releases\n</code></pre> <pre><code>NAMESPACE   NAME            REPOSITORY                               TAG          CONTEXTS                                                STATUS   READY   WAIT   PRT   AGE     DESCRIPTION\ndefault     podinfo1        quay.io/kubodoc/packages/podinfo         6.7.1-p01    contexts:cluster                                        READY    1/1            -     3d20h   A first sample release of podinfo\ndefault     podinfo2        quay.io/kubodoc/packages/podinfo         6.7.1-p02    contexts:cluster,contexts:cluster                       READY    1/1            -     25h     A first sample release of podinfo\ndefault     podinfo3        quay.io/kubodoc/packages/podinfo         6.7.1-p02    contexts:cluster                                        READY    1/1            -     27m     A first sample release of podinfo\nkubocd      ingress-nginx   quay.io/kubodoc/packages/ingress-nginx   4.12.1-p01   contexts:cluster                                        READY    1/1            -     3d23h   The Ingress controller\nproject01   podinfo         quay.io/kubodoc/packages/podinfo         6.7.1-p03    contexts:cluster,contexts:cluster,project01:project01   READY    1/1            -     24h     A release of podinfo on project01\nproject02   podinfo         quay.io/kubodoc/packages/podinfo         6.7.1-p02    contexts:cluster,contexts:cluster,project02:project02   READY    1/1            -     24h     A release of podinfo on project02\nproject03   podinfo         quay.io/kubodoc/packages/podinfo         6.7.1-p02    contexts:cluster,project03:project                      READY    1/1            -     5m55s   A release of podinfo on project03\n</code></pre> <p>You might see cases where the same context is listed twice in a <code>Release</code>, both as a default and explicitly. This has no adverse effects.</p> <p>Tip</p> <p>If for any reason you want to disable default context merging for a specific <code>Release</code>, you can use the <code>skipDefaultContext: true</code> flag in the <code>Release</code> specification.</p>"},{"location":"user-guide/170-context-and-config/#kubocd-helm-chart","title":"KuboCD Helm Chart","text":"<p>These configuration values can be integrated during the KuboCD installation by passing them as Helm <code>values</code>.</p> <p>For example, by creating the following file:</p> values1-ctrl.yaml <pre><code>config:\n  defaultContexts:\n    - name: cluster\n      namespace: contexts\n  defaultNamespaceContext: project\nextraNamespaces:\n  - name: contexts\ncontexts:\n  - name: cluster\n    namespace: contexts\n    protected: true\n    description: Context specific to the cluster 'kubodoc'\n    context:\n      ingress:\n        className: nginx\n        domain: ingress.kubodoc.local\n      storageClass:\n        data: standard\n        workspace: standard\n</code></pre> <ul> <li> <ul> <li>The <code>config</code> section is injected directly into the <code>Config</code> resource\u2019s <code>spec</code>.</li> </ul> </li> <li> <ul> <li>The <code>extraNamespaces</code> list creates additional namespaces via the Helm chart.</li> </ul> </li> <li> <ul> <li>The <code>contexts</code> section defines context objects created automatically by the Helm chart.</li> </ul> </li> </ul> <p>To upgrade the KuboCD deployment:</p> <pre><code>helm -n kubocd upgrade kubocd-ctrl oci://quay.io/kubocd/charts/kubocd-ctrl:v0.2.0 --values values1-ctrl.yaml\n</code></pre> <p>Warning</p> <p>If you've followed the steps in this chapter, an error will be raised \u2014 Helm refuses to manage objects it did not originally create.</p> <p>In that case, delete the <code>contexts</code> namespace and its associated objects first:</p> <pre><code>kubectl -n contexts delete context.kubocd.kubotal.io cluster\n</code></pre> <pre><code>kubectl delete ns contexts\n</code></pre> <p>Then re-run the <code>helm upgrade</code> command.</p> <p>While performing this operation, <code>Releases</code> may temporarily enter the <code>ERROR</code> state before returning to <code>READY</code> once the context is recreated. However, the applications themselves (pods and ingress for <code>podinfo</code>, etc.) will remain unaffected.</p>"},{"location":"user-guide/180-kubocd-cli/","title":"The KuboCD CLI","text":""},{"location":"user-guide/180-kubocd-cli/#kubocd-pack","title":"kubocd pack","text":"<p>Creates a KuboCD package from a manifest and stores it in an OCI image repository.</p> <p>See the A First Deployment / Package Build section for a usage example.</p> <pre><code>Usage:\n  kubocd package &lt;Package manifest&gt; [flags]\n\nAliases:\n  package, pack, build\n\nFlags:\n  -h, --help                   help for package\n  -r, --ociRepoPrefix string   OCI repository prefix (e.g., 'quay.io/your-organization/packages'). \n                               Can also be specified via the OCI_REPO_PREFIX environment variable\n  -p, --plainHTTP              Use plain HTTP instead of HTTPS when pushing the image\n  -w, --workDir string         Working directory. Defaults to $HOME/.kubocd\n</code></pre>"},{"location":"user-guide/180-kubocd-cli/#kubocd-dump-package","title":"kubocd dump package","text":"<p>Displays the contents of a KuboCD package.</p> <pre><code>Usage:\n  kubocd dump package &lt;package.yaml|oci://repo:version&gt; [flags]\n\nAliases:\n  package, pck, Package, Pck, pack, Pack\n\nFlags:\n  -a, --anonymous       Connect anonymously to the registry (useful for checking 'public' image status)\n  -c, --charts          Unpack charts in the output directory\n  -h, --help            help for package\n  -i, --insecure        Insecure (use HTTP instead of HTTPS)\n  -o, --output string   Output dump directory (default \"./.dump\")\n\nGlobal Flags:\n  -w, --workDir string   Working directory. Defaults to $HOME/.kubocd\n</code></pre> <p>Example:</p> <pre><code>kubocd dump package oci://quay.io/kubodoc/packages/podinfo:6.7.1-p01\n</code></pre> <p>or:</p> <pre><code>kubocd dump package podinfo-p01.yaml\n</code></pre> <pre><code>Create .dump/podinfo/status.yaml\nCreate .dump/podinfo/original.yaml\nCreate .dump/podinfo/groomed.yaml\nCreate .dump/podinfo/default-parameters.yaml\nCreate .dump/podinfo/default-context.yaml\n</code></pre> <p>This command creates a <code>.dump</code> directory in the local folder, containing:</p> <ul> <li><code>.dump/podinfo/original.yaml</code>: The original manifest as provided during packaging.</li> <li><code>.dump/podinfo/groomed.yaml</code>: The groomed version of the manifest, including default values and normalized parameter/context schemas.</li> <li><code>.dump/podinfo/default-parameters.yaml</code>: Default parameter values, extracted from the parameter schema.</li> <li><code>.dump/podinfo/default-context.yaml</code>: Default context values, extracted from the context schema.</li> </ul> <p>Optionally, you can extract the Helm charts of the modules embedded in the package:</p> <pre><code>kubocd dump package podinfo-p01.yaml --charts\n</code></pre> <pre><code>--- Handling module 'main':\n    Fetching chart podinfo:6.7.1...\n    Chart: podinfo:6.7.1\nExpand chart podinfo\nCreate .dump/podinfo/status.yaml\nCreate .dump/podinfo/original.yaml\nCreate .dump/podinfo/groomed.yaml\nCreate .dump/podinfo/default-parameters.yaml\nCreate .dump/podinfo/default-context.yaml\n</code></pre> <p>The Helm chart for <code>podinfo</code> is available in <code>.dump/podinfo/charts/main</code>.</p>"},{"location":"user-guide/180-kubocd-cli/#kubocd-dump-helmrepository","title":"kubocd dump helmRepository","text":"<p>This command allows you to explore the contents of a remote Helm repository.</p> <pre><code>Usage:\n  kubocd dump helmRepository repoUrl [chartName [version]] [flags]\n\nAliases:\n  helmRepository, hr, HelmRepository, helmrepository, helmRepo, HelmRepo, helmrepo\n\nFlags:\n  -c, --chart           Unpack charts into the output directory\n  -h, --help            help for helmRepository\n  -o, --output string   Output chart directory (default \"./.charts\")\n\nGlobal Flags:\n  -w, --workDir string   Working directory. Defaults to $HOME/.kubocd\n</code></pre> <p>Examples:</p>"},{"location":"user-guide/180-kubocd-cli/#list-charts","title":"List charts","text":"<pre><code>kubocd dump helmRepository https://stefanprodan.github.io/podinfo\n</code></pre> <pre><code>---------------Chart in repo 'https://stefanprodan.github.io/podinfo':\npodinfo\n</code></pre>"},{"location":"user-guide/180-kubocd-cli/#list-versions","title":"List versions","text":"<pre><code>kubocd dump helmRepository https://stefanprodan.github.io/podinfo podinfo\n</code></pre> <pre><code>---------- Versions for 'podinfo':\n6.8.0\n6.7.1\n6.7.0\n........\n</code></pre>"},{"location":"user-guide/180-kubocd-cli/#view-contents-of-a-specific-version","title":"View contents of a specific version","text":"<pre><code>kubocd dump helmRepository https://stefanprodan.github.io/podinfo podinfo 6.8.0\n</code></pre> <pre><code>Fetching chart podinfo:6.8.0...\n\nChart: podinfo:6.8.0\n\n---------------------- Chart.yaml:\napiVersion: v1\nappVersion: 6.8.0\ndescription: Podinfo Helm chart for Kubernetes\nhome: https://github.com/stefanprodan/podinfo\nkubeVersion: '&gt;=1.23.0-0'\nmaintainers:\n- email: stefanprodan@users.noreply.github.com\n  name: stefanprodan\nname: podinfo\nsources:\n- https://github.com/stefanprodan/podinfo\nversion: 6.8.0\n\n\n-------------------- content:\npodinfo/Chart.yaml\npodinfo/values.yaml\npodinfo/templates/NOTES.txt\npodinfo/templates/_helpers.tpl\npodinfo/templates/certificate.\n.........\n</code></pre>"},{"location":"user-guide/180-kubocd-cli/#download-a-chart","title":"Download a chart","text":"<p>Use the <code>--chart</code> flag to download the chart into the local <code>.charts</code> directory:</p> <pre><code>kubocd dump helmRepository https://stefanprodan.github.io/podinfo podinfo 6.8.0 --chart\n</code></pre> <pre><code>Fetching chart podinfo:6.8.0...\n\nChart: podinfo:6.8.0\n\n---------------------- Chart.yaml:\napiVersion: v1\n........\n\n-------------------- content:\npodinfo/Chart.yaml\npodinfo/values.yaml\n.......\n\n---------------------- Extract chart podinfo (6.8.0) to ./.charts/podinfo-6.8.0\n</code></pre>"},{"location":"user-guide/180-kubocd-cli/#kubocd-dump-context","title":"kubocd dump context","text":"<p>This command displays the application context as perceived by KuboCD. It requires access to the Kubernetes cluster.</p> <pre><code>Usage:\n  kubocd dump context [flags]\n\nAliases:\n  context, ctx, Context, Ctx\n\nFlags:\n  -c, --context stringArray      Context in the form 'namespace:name'\n  -h, --help                     help for context\n      --kubocdNamespace string   The namespace where the KuboCD controller is installed (To fetch config resources) (default \"kubocd\")\n  -n, --namespace string         Namespace (default \"default\")\n      --skipDefaultContext       Do not use the default context\n\nGlobal Flags:\n  -w, --workDir string   Working directory. Defaults to $HOME/.kubocd\n</code></pre> <p>Examples:</p> <p>Display the context for an application in the <code>default</code> namespace:</p> <pre><code>kubocd dump context\n</code></pre> <pre><code>---\ningress:\n  className: nginx\n  domain: ingress.kubodoc.local\nstorageClass:\n  data: standard\n  workspace: standard\n</code></pre> <p>Display the context for an application in the <code>project03</code> namespace:</p> <p>It is assumed than this namespace has a default context, as described in previous chapters</p> <pre><code>kubocd dump context --namespace project03\n</code></pre> <pre><code>---\ningress:\n  className: nginx\n  domain: prj03.ingress.kubodoc.local\nproject:\n  id: p03\nstorageClass:\n  data: standard\n  workspace: standard\n</code></pre> <p>Aggregate specific contexts:</p> <pre><code>kubocd dump context --skipDefaultContext --context contexts:cluster --context project01:project01\n</code></pre> <pre><code>---\ningress:\n  className: nginx\n  domain: ingress.kubodoc.local\nproject:\n  id: p01\n  subdomain: prj01\nstorageClass:\n  data: standard\n  workspace: standard\n</code></pre>"},{"location":"user-guide/180-kubocd-cli/#kubocd-render","title":"kubocd render","text":"<p>This command previews all the resources that will be deployed as part of a <code>Release</code>.</p> <p>It is also a good validation of a new <code>Package</code> and/or <code>Release</code> before deployment.</p> <p>It accesses the current Kubernetes cluster (mainly to retrieve <code>Contexts</code>).</p> <pre><code>Usage:\n  kubocd render &lt;Release manifest&gt; [&lt;package manifest&gt;] [flags]\n\nFlags:\n  -h, --help                     help for render\n      --kubocdNamespace string   Namespace where the kubocd controller is installed (default \"kubocd\")\n  -n, --namespace string         Namespace to use if release.metadata.namespace is empty (default \"default\")\n  -o, --output string            Output directory (default \"./.render\")\n  -w, --workDir string           Working directory. Defaults to $HOME/.kubocd\n</code></pre> <p>Example:</p> <pre><code>kubocd render podinfo2-ctx.yaml\n</code></pre> <pre><code>Create .render/podinfo2/release.yaml\nCreate .render/podinfo2/configs.yaml\n# Pulling image 'quay.io/kubodoc/packages/podinfo:6.7.1-p02'\nExpand chart podinfo\nCreate .render/podinfo2/package.yaml\nCreate .render/podinfo2/default-parameters.yaml\nCreate .render/podinfo2/default-context.yaml\nCreate .render/podinfo2/status.yaml\nCreate .render/podinfo2/context.yaml\nCreate .render/podinfo2/parameters.yaml\nCreate .render/podinfo2/model.yaml\nCreate .render/podinfo2/roles.yaml\nCreate .render/podinfo2/dependencies.yaml\nCreate .render/podinfo2/ociRepository.yaml\nCreate .render/podinfo2/usage.txt\nCreate .render/podinfo2/helmRepository.yaml\nCreate .render/podinfo2/modules/main/helmRelease.yaml\nCreate .render/podinfo2/modules/main/values.yaml\nCreate .render/podinfo2/modules/main/manifests.yaml\nContexts: contexts:cluster,contexts:cluster\n</code></pre> <p>Key output files:</p> FILES DESCRIPTION release.yaml Final <code>Release</code> manifest with defaults added package.yaml Processed package manifest with normalized parameter and context schemas default-parameters.yaml Default parameter values extracted from the parameter schema default-context.yaml Default context values extracted from the context schema context.yaml Resulting context after processing parameters.yaml Parameters provided for templating model.yaml Complete data model used for templating values and other properties roles.yaml List of roles fulfilled by this deployment dependencies.yaml List of deployment dependencies ociRepository.yaml Flux <code>OCIRepository</code> object to be created usage.txt Templated result of the package usage helmRepository.yaml Flux <code>HelmRepository</code> object to be created modules/main/helmRelease.yaml Flux <code>HelmRelease</code> object for the main module modules/main/values.yaml Templated Helm values for the main module modules/main/manifests.yaml Result of <code>helm template --debug ...</code> for the main module <p>Tips</p> <p>It is of good practice to check a <code>Release</code> with this <code>kubocd render</code> command before deployment on the cluster.</p>"},{"location":"user-guide/190-alternate-schema-format/","title":"Alternate KuboCD Schema Format","text":"<p>In our previous examples, we defined <code>schema.parameters</code> and <code>schema.context</code> using a standard OpenAPI/JSON schema.  While fully supported, it can be quite verbose.</p> <p>KuboCD also supports a more concise schema syntax, specifically designed for this use case.</p> <p>Here is one of our <code>podinfo</code> <code>Package</code> example from a previous chapter (Only the <code>schema</code> section) </p> podinfo-p02.yaml <pre><code>apiVersion: v1alpha1\n........\nschema:\n  parameters:\n    $schema: http://json-schema.org/schema#\n    type: object\n    additionalProperties: false\n    properties:\n      host: { type: string }\n    required:\n      - host\n  context:\n    $schema: http://json-schema.org/schema#\n    additionalProperties: true\n    type: object\n    properties:\n      ingress:\n        type: object\n        additionalProperties: true\n        properties:\n          className: { type: string }\n          domain: { type: string }\n        required:\n          - domain\n          - className\n    required:\n      - ingress\nmodules:\n.........\n</code></pre> <p>Here\u2019s an identical version of this <code>Package</code> using the simplified KuboCD schema format:</p> podinfo-p02-alt.yaml <pre><code>apiVersion: v1alpha1\n......\nschema:\n  parameters:\n    properties:\n      host: { type: string, required: true }\n  context:\n    properties:\n      ingress:\n        required: true\n        properties:\n          className: { type: string, required: true }\n          domain: { type: string, required: true }\nmodules:\n.......\n</code></pre> <p>As you can see, the format is significantly more compact.</p> <p>Info</p> <p>This schema format is NOT standard OpenAPI</p> <p>The presence or absence of the <code>$schema:</code> key is what KuboCD uses to distinguish between standard and KuboCD schema formats.</p> <p>The difference are the following:</p> <ul> <li>No <code>$schema:</code> key for the KuboCD format</li> <li>The <code>required</code> fields are not in an array anymore, but are now an attribute of the node.</li> <li>The flag <code>additionalProperties: false</code> is set on all object and sub-object of a <code>parameters</code> schema.</li> <li>The flag <code>additionalProperties: true</code> is set on all object and sub-object of a <code>context</code> schema.</li> <li>the <code>type: object</code> is now optional. It is deduced from the presence of the <code>properties</code> attribute.</li> <li>the <code>type: array</code> is now optional. It is deduced from the presence of the <code>items</code> attribute.</li> <li>All others attributes (<code>default</code>, <code>enums</code>, <code>pattern</code>, ....) are left unchanged.</li> </ul> <p>When a <code>Package</code> is build, both schemas are converted to their standard OpenAPI/JSON and stored in this form. </p> <p>This normalized version will be accessible using <code>kubocd dump package...</code> or <code>kubocd render....</code> CLI tools.</p> <p>For the remaining of this manuel, we will use the KuboCD schema. </p>"},{"location":"user-guide/200-redis/","title":"Redis: a realistic example.","text":"<p>We will use this sample to demonstrate some more advanced feature of KuboCD.</p> ingress-nginx.yaml <pre><code>kubocd pack redis-p01.yaml \n</code></pre> <pre><code>====================================== Packaging package 'redis-p01.yaml'\n--- Handling module 'redis':\n    Pulling image 'registry-1.docker.io/bitnamicharts/redis:20.6.1'\n    Chart: redis:20.6.1\n--- Handling module 'commander':\n    Cloning git repository 'https://github.com/joeferner/redis-commander.git'\n    Chart: redis-commander:0.6.0\n--- Packaging\n    Generating index file\n    Wrap all in assembly.tgz\n--- push OCI image: quay.io/kubodoc/packages/redis:20.6.1-p01\n    Successfully pushed\n</code></pre>"}]}